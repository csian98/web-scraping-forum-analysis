post_id,title,selftext,author_hash,score,upvote_ratio,num_comments,created_utc,url,permalink,is_self,link_flair_text,domain,subreddit,is_video,over_18
1qzv8yw,"Weekly Entering & Transitioning - Thread 09 Feb, 2026 - 16 Feb, 2026","Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include: * Learning resources (e.g. books, tutorials, videos) * Traditional education (e.g. schools, degrees, electives) * Alternative education (e.g. online courses, bootcamps) * Job search questions (e.g. resumes, applying, career prospects) * Elementary questions (e.g. where to start, what next) While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",user_ac31a110,7,0.75,7,2026-02-08 21:01:37,https://www.reddit.com/r/datascience/comments/1qzv8yw/weekly_entering_transitioning_thread_09_feb_2026/,https://www.reddit.com/r/datascience/comments/1qzv8yw/weekly_entering_transitioning_thread_09_feb_2026/,True,,self.datascience,datascience,False,False
1r40g4p,What differentiates a high impact analytics function from one that just produces dashboards?,"I’m curious to hear from folks who’ve worked inside or alongside analytics teams. In your experience, what actually separates analytics groups that influence business decisions from those that mostly deliver reporting?",user_fbe99468,14,0.89,1,2026-02-13 12:38:23,https://www.reddit.com/r/datascience/comments/1r40g4p/what_differentiates_a_high_impact_analytics/,https://www.reddit.com/r/datascience/comments/1r40g4p/what_differentiates_a_high_impact_analytics/,True,Discussion,self.datascience,datascience,False,False
1r40rd2,Where do you see HR/People Analytics evolving over the next 5 years?,"Curious how practitioners see the field shifting, particularly around: * AI integration * Predictive workforce modeling * Skills-based org design * Ethical boundaries * Data ownership changes * HR decision automation What capabilities do you think will define leading functions going forward?",user_fbe99468,5,1.0,3,2026-02-13 12:50:35,https://www.reddit.com/r/datascience/comments/1r40rd2/where_do_you_see_hrpeople_analytics_evolving_over/,https://www.reddit.com/r/datascience/comments/1r40rd2/where_do_you_see_hrpeople_analytics_evolving_over/,True,Discussion,self.datascience,datascience,False,False
1r3zq14,Mock interviews,Any other platform like prepfully for mock interviews from faang ds? Prepfully charges a lot. Any other place?,user_b2768c9e,1,1.0,1,2026-02-13 12:10:21,https://www.reddit.com/r/datascience/comments/1r3zq14/mock_interviews/,https://www.reddit.com/r/datascience/comments/1r3zq14/mock_interviews/,True,Discussion,self.datascience,datascience,False,False
1r3gi4p,"What would you do with this task, and how long would it take you to do it?","I'm going to describe a situation as specifically as I can. I am curious what people would do in this situation, I worry that I complicate things for myself. I'm describing the whole task as it was described to me and then as I discovered it. Ultimately, I'm here to ask you, **what do you do, and how long does it take you to do it?** I started a new role this month, I am new to advertising modeling methods like mmm, so I am reading a lot about how to apply the methods specific to mmm in R and python, I use VScode, I don't have a github copilot license, I get to use copilot through windows office license. Although this task did not involve modeling, I do want to ask about that kind of task another day if this goes over well. ##### The task 5, excel sheets are to be provided. You are told that this is a clients data that was given to another party for some other analysis and augmentation. This is a quality assurance task. The previous process was as follows; ##### the data * the data structure: 1 workbook per industry for 5 industries * 4 workbooks had 1 tab, 1 workbook had 3 tabs * each tab had a table that had a date column in days, 2 categorical columns advertising_partner, line_of_business and at least 2 numeric columns per work book. * some times data is updated from our side and the partner has to redownload the data and reprocess and share again ##### the process * this is done once per client, per quarter (but it's just this client for now) * open each workbook * navigate to each tab * the data is in a ""controllable"" table | | | | | | ---|---|---| ---|---|---| bing| bing | | | home | home | | | impressions | spend | | partner dropdown| line of business dropdown * where bing and home are controlled with drop down toggles, with a combination of 3-4 categories each. * compare with data that is to be downloaded from a tableau dashboard * end state: the comparison of the metrics in tableau to the excel tables to ensure that ""the numbers are the same"" * the categories presented map 1 to 1 with the data you have downloaded from tableau * aggregate the data in a pivot table, select the matching categories, make sure the values match #### additional info about the file * the summary table is a complicated sumproduct look up table against an extremely wide table hidden to the left. the summary table can start as early as AK and as late as FE. * there are 2 broadly different formats of underlying data in the 5 notebooks, with small structure differences between the group of 3. ###### in the group of 3 * the structure of this wide table is similar to the summary table with categories in the column headers describing the metric below it. but with additional categories like region, which is the same value for every column header. 1 of these tables has 1 more header category than the other 2 * the left most columns have 1 category each, there are 3 date columns for day, quarter. | | | | | | | |---|---|----|----| ---- | ---- | ---- | ---- | | | | | | | REGION | | USA | USA | USA | | PARTNER | | bing | bing | google | | | LOB | | home | home | auto | | | | | impressions | spend | ...etc| | date | quarter| | impressions| spend | ...etc| | 2023-01-01 | q1| | 1| 2 | ...etc | | 2023-01-02 | q1| | 3| 4 | ...etc | ###### in the group of 2 * the left most categories are actually the categorical headers in the group of 3, and the metrics, the values in each category mach * the dates are now the headers of this very wide table * the header labels are separated from the start of the values by 1 column * there is an empty row immediately below the final row for column headers. | | | | | | | | |---|---|----|----| ---- | ---- | ---- | ---- | ---- | | | | | date Label| | 2023-01-01 | 2023-01-02 | | | | | year| | 2023 | 2023 | | | | | quarter| | q1 | q1 | | blank row | | | | | | | | REGION | PARTNER | LOB | measure| | | | | blank row | | | | | | | | US | bing | home | impressions | | 1 | 3| | US | bing | home | spend | | 2 | 4 | | US | google | auto | ...etc | | ...etc | ... etc| The question is, what do you do, and how long does it take you to do it? I am being honest here, I wrote out this explaination basically in the order in which I was introduced to the information and how I discovered it. *(Oh it's easy if it's all the same format even if it's weird, oh there are 2-ish different formatted files)* the meeting of this task ended at 11:00AM. I saw this copy paste manual etl project and I simply didn't want to do it. So I outlined my task by identifying the elements of the table, column name ranges, value ranges, stacked / pivoted column ranges, etc... for an R script to extract that data. by passing the ranges of that content to an argument `make_clean_table(left_columns=""B4:E4"", header_dims=c(..etc))` and functions that extract that convert that excel range into the correct position in the table to extract that element. Then the data was transformed to create a tidy long table. the function gets passed once per notebook extracting the data from each worksheet, building a single table with the columns for the workbook industry, the category in the tab, partner, line of business, spend, impressions, etc... IMO; ideally (if I *have* to check their data in excel that is), I'd like the partner to redo their report so that I received a workbook with the underlying data in a traditionally tabular form and their reporting page to use power query and table references and not cell ranges and formula.",user_3e86536f,3,0.57,6,2026-02-12 21:14:42,https://www.reddit.com/r/datascience/comments/1r3gi4p/what_would_you_do_with_this_task_and_how_long/,https://www.reddit.com/r/datascience/comments/1r3gi4p/what_would_you_do_with_this_task_and_how_long/,True,Analysis,self.datascience,datascience,False,False
1r21ce9,New Study Finds AI May Be Leading to “Workload Creep” in Tech,,user_7f97b18b,361,0.97,40,2026-02-11 08:05:00,https://www.interviewquery.com/p/ai-workload-creep-tech-workers-study,https://www.reddit.com/r/datascience/comments/1r21ce9/new_study_finds_ai_may_be_leading_to_workload/,False,Discussion,interviewquery.com,datascience,False,False
1r2flqg,Meta ds - interview,"I just read on blind that meta is squeezing its ds team and plans to automate it completely in a year. Can anyone, working with meta confirm if true? I have an upcoming interview for product analytics position and I am wondering if I should take it if it is a hire for fire positon?",user_b2768c9e,53,0.83,23,2026-02-11 17:07:26,https://www.reddit.com/r/datascience/comments/1r2flqg/meta_ds_interview/,https://www.reddit.com/r/datascience/comments/1r2flqg/meta_ds_interview/,True,Discussion,self.datascience,datascience,False,False
1r24okt,Rescaling logistic regression predictions for under-sampled data?,"I'm building a predictive model for a large dataset with a binary 0/1 outcome that is heavily imbalanced. I'm under-sampling records from the majority outcome class (the 0s) in order to fit the data into my computer's memory prior to fitting a logistic regression model. Because of the under-sampling, do I need to rescale the model's probability predictions when choosing the optimal threshold or is the scale arbitrary?",user_ab21e1cc,19,0.87,17,2026-02-11 10:05:18,https://www.reddit.com/r/datascience/comments/1r24okt/rescaling_logistic_regression_predictions_for/,https://www.reddit.com/r/datascience/comments/1r24okt/rescaling_logistic_regression_predictions_for/,True,ML,self.datascience,datascience,False,False
1r1qo10,[Advice/Vent] How to coach an insular and combative science team,"My startup was acquired by a legacy enterprise. We were primarily acquired for our technical talent and some high growth ML products they see as a strategic threat. Their ML team is entirely entry-level and struggling badly. They have very poor fundamentals around labeling training data, build systems without strong business cases, and ignore reasonable feedback from engineering partners regarding latency and safe deployment patterns. I am staff level MLE and have been asked to up level this team. I’ve tried the following: \- Being inquisitive and asking them to explain design decisions \- walking them through our systems and discussing the good/bad/ugly \- being vulnerable about past decisions that were suboptimal \- offering to provide feedback before design review with cross functional partners None of this has worked. I am mostly ignored. When I point out something obvious (e.g 12 second latency is unacceptable for live inference) they claim there is no time to fix it. They write dozens of pages of documents that do not have answers to simple questions (what ML algorithms are you using? What data do you need at inference time? What systems rely on your responses). They then claim no one is knowledgeable enough to understand their approach. It seems like when something doesn’t go their way they just stonewall and gaslight. I personally have never dealt with this before. I’m curious if anyone has coached a team to unlearn these behaviors and heal cross functional relationships. My advice right now is to break apart the team and either help them find non-ML roles internally or let them go.",user_8fee96a9,70,0.93,30,2026-02-10 23:12:53,https://www.reddit.com/r/datascience/comments/1r1qo10/advicevent_how_to_coach_an_insular_and_combative/,https://www.reddit.com/r/datascience/comments/1r1qo10/advicevent_how_to_coach_an_insular_and_combative/,True,Discussion,self.datascience,datascience,False,False
1r16y9s,AI isn’t making data science interviews easier.,"I sit in hiring loops for data science/analytics roles, and I see a lot of discussion lately about AI “making interviews obsolete” or “making prep pointless.” From the interviewer side, that’s not what’s happening. There’s a lot of posts about how you can easily generate a SQL query or even a full analysis plan using AI, but it only means we make interviews harder and more intentional, i.e. focusing more on how you think rather than whether you can come up with the correct/perfect answers. Some concrete shifts I’ve seen mainly include SQL interviews getting a lot of follow-ups, like assumptions about the data or how you’d explain query limitations to a PM/the rest of the team. For modeling questions, the focus is more on judgment. So don’t just practice answering which model you’d use, but also think about how to communicate constraints, failure modes, trade-offs, etc. Essentially, don’t just rely on AI to generate answers. You still have to do the explaining and thinking yourself, and that requires deeper practice. I’m curious though how data science/analytics candidates are experiencing this. Has anything changed with your interview experience in light of AI? Have you adapted your interview prep to accommodate this shift (if any)?",user_e6f6eb17,195,0.96,61,2026-02-10 09:23:06,https://www.reddit.com/r/datascience/comments/1r16y9s/ai_isnt_making_data_science_interviews_easier/,https://www.reddit.com/r/datascience/comments/1r16y9s/ai_isnt_making_data_science_interviews_easier/,True,Discussion,self.datascience,datascience,False,False
1r1966a,2026 State of Data Engineering Survey,Site includes the survey data in addition to the results so you can drill in.,user_d1f78b64,7,1.0,0,2026-02-10 10:41:56,https://joereis.github.io/practical_data_data_eng_survey/,https://www.reddit.com/r/datascience/comments/1r1966a/2026_state_of_data_engineering_survey/,False,Discussion,joereis.github.io,datascience,False,False
1r0dvmw,An easy process to make sure your executive team understands the data,"A lot of teams struggle making reports digestible for executive teams. When we report data with all the complexity of the methods, limitations, confounds, and measurements of uncertainty, management tends to respond with a common refrain: **""Keep it simple. The executives can't wrap their minds around all of this.""** But there's a simple, two-step method you can use to make sure your data reports are always understood by the people in charge: 1. Fire the executives 2. Celebrate getting rid of the dead weight You'll find this makes every part of your work faster, better, and more enjoyable.",user_67d6549f,352,0.97,28,2026-02-09 11:28:53,https://www.reddit.com/r/datascience/comments/1r0dvmw/an_easy_process_to_make_sure_your_executive_team/,https://www.reddit.com/r/datascience/comments/1r0dvmw/an_easy_process_to_make_sure_your_executive_team/,True,Monday Meme,self.datascience,datascience,False,False
1r160kr,"[AMA] We’re dbt Labs, ask us anything!",,user_66659ec5,2,0.6,0,2026-02-10 08:49:40,/r/dataengineering/comments/1r0ff3b/ama_were_dbt_labs_ask_us_anything/,https://www.reddit.com/r/datascience/comments/1r160kr/ama_were_dbt_labs_ask_us_anything/,False,Discussion,,datascience,False,False
1r0d6fi,You can select points with a lasso now using matplotlib,"If you want to give it a spin, there's a marimo notebook demo right here: [https://koaning.github.io/wigglystuff/examples/chartselect/](https://koaning.github.io/wigglystuff/examples/chartselect/)",user_310943db,23,0.9,0,2026-02-09 11:04:18,https://youtu.be/c-nasIVbAoM,https://www.reddit.com/r/datascience/comments/1r0d6fi/you_can_select_points_with_a_lasso_now_using/,False,Tools,youtu.be,datascience,False,False
1r09ynb,Memory exhaustion errors (crosspost from snowflake forum),,user_ab21e1cc,1,0.67,4,2026-02-09 09:10:29,/r/snowflake/comments/1r07w5u/memory_exhaustion_errors/,https://www.reddit.com/r/datascience/comments/1r09ynb/memory_exhaustion_errors_crosspost_from_snowflake/,False,Discussion,,datascience,False,False
1qytqug,Thoughts about going from Senior data scientist at company A to Senior Data Analyst at Company B,The senior data analyst at company B is significant higher pay ($50k/year more) and scope seems to be bigger with more ownership What kind of setback (if any) does losing the data scientist title have?,user_152154d1,87,0.91,48,2026-02-07 16:06:27,https://www.reddit.com/r/datascience/comments/1qytqug/thoughts_about_going_from_senior_data_scientist/,https://www.reddit.com/r/datascience/comments/1qytqug/thoughts_about_going_from_senior_data_scientist/,True,Career | US,self.datascience,datascience,False,False
1qy7a89,"How I scraped 5.3 million jobs (including 5,335 data science jobs)","**Background** During my PhD in Data Science at Stanford, I got sick and tired of ghost jobs & 3rd party offshore agencies on LinkedIn & Indeed. So I wrote a script that fetches jobs from 30k+ company websites' career pages and uses GPT4o-mini to extract relevant information (ex salary, remote, etc.) from job descriptions. You can use it here: ([HiringCafe](http://hiring.cafe)). Here is a filter for Data science jobs (5,335 and counting). I scrape every company 3x/day, so the results stay fresh if you check back the next day. You can follow my progress on r/hiringcafe **How I built the HiringCafe (from a DS perspective)** 1. I identified company career pages with active job listings. I used the [Apollo.io](http://apollo.io/) to search for companies across various industries, and get their company URLs. To narrow these down, I wrote a web crawler (using Node.js, and a combination of Cheerio + Puppeteer depending on site complexity) to find the career page of the company. I discovered that I could dump the raw HTML and prompt ChatGPT o1-mini to classify (as a binary classification) whether each page contained a job description or not. I thus compiled a list of verified job page if it contains a job description or not. If it contains a job description, I add it to a list and proceed to step 2 2. Verifying legit companies. This part I had to do manually, but it was crucial that I exclude any recruiting firms, 3rd party offshore agencies, etc. because I wanted only high-quality companies directly hiring for roles at their firm. I manually sorted through the 30,000 company career pages (this took several weeks) and picked the ones that looked legit. At Stanford, we call this technique ""occular regression"" :) It was doable because I only had to verify each company a single time and then I trust it moving forward. 3. Removing ghost jobs. I discovered that a strong predictor of if a job is a ghost job is that if it keeps being reposted. I was able to identify reposting by doing a embedding text similarity search for jobs from the same company. If 2 job descriptions overlap too much, I only show the date posted for the *earliest* listing. This allowed me to weed out most ghost jobs simply by using a date filter (for example, excluding any jobs posted over a month ago). In my anecdotal, experience this means that I get a higher response rate for data science jobs compared to LinkedIn or Indeed. 4. Scraping fresh jobs 3x/day. To ensure that my database is reflective of the company career page, I check each company career page 3x/day. Many career pages do not have rate limits because it is in their best interest to allow web scrapers, which is great. For the few that do, I was able to use a rotating proxy. I use Oxylabs for now, but I've heard good things about ScraperAPI, Crawlera. 5. Building advanced NLP text filters. After playing with GPT4o-mini API, I realized I could can effectively dump raw job descriptions (in HTML) and ask it to give me back formatted information back in JSON (ex salary, yoe, etc). I used this technique to extract a variety of information, including technical keywords, job industry, required licenses & security clearance, if the company sponsors visa, etc. 6. Powerful search. Once I had the structured JSON data (containing salary, years of experience, remote status, job title, company name, location, and other relevant fields) from ChatGPT's extraction process, I needed a robust search engine to allow users to query and filter jobs efficiently. I chose Elasticsearch due to its powerful full-text search capabilities, filtering, and aggregation features. My favorite feature with Elasticsearch is that it allows me to do Boolean queries. For instance, I can search for job descriptions with technical keywords of ""Pandas"" or ""R"" (example link [here](https://hiring.cafe/?searchState=%7B%22technologyKeywordsQuery%22%3A%22%5C%22Pandas%5C%22+or+%5C%22R%5C%22+%22%7D)). # Question for the DS community here Beyond job search, one thing I'm really excited about this 2.1 million job dataset is to be able to do a yearly or quarterly trend report. For instance, to look at what technical skills are growing in demand. What kinds of cool job trends analyses would you do if you had access to this data.",user_385ff9fd,733,0.93,96,2026-02-06 23:13:58,https://www.reddit.com/r/datascience/comments/1qy7a89/how_i_scraped_53_million_jobs_including_5335_data/,https://www.reddit.com/r/datascience/comments/1qy7a89/how_i_scraped_53_million_jobs_including_5335_data/,True,Projects,self.datascience,datascience,False,False
1qyhmtx,Retraining strategy with evolving classes + imbalanced labels?,"Hi all — I’m looking for advice on the best retraining strategy for a multi-class classifier in a setting where the label space can evolve. Right now I have about 6 labels, but I don’t know how many will show up over time, and some labels appear inconsistently or disappear for long stretches. My initial labeled dataset is \~6,000 rows and it’s extremely imbalanced: one class dominates and the smallest class has only a single example. New data keeps coming in, and my boss wants us to retrain using the model’s inferences plus the human corrections made afterward by someone with domain knowledge. I have concerns about retraining on inferences, but that's a different story. Given this setup, should retraining typically use all accumulated labeled data, a sliding window of recent data, or something like a recent window plus a replay buffer for rare but important classes? Would incremental/online learning (e.g., partial\_fit style updates or stream-learning libraries) help here, or is periodic full retraining generally safer with this kind of label churn and imbalance? I’d really appreciate any recommendations on a robust policy that won’t collapse into the dominant class, plus how you’d evaluate it (e.g., fixed “golden” test set vs rolling test, per-class metrics) when new labels can appear.",user_30c4016b,19,0.96,8,2026-02-07 08:06:22,https://www.reddit.com/r/datascience/comments/1qyhmtx/retraining_strategy_with_evolving_classes/,https://www.reddit.com/r/datascience/comments/1qyhmtx/retraining_strategy_with_evolving_classes/,True,Discussion,self.datascience,datascience,False,False
1qxltyk,Finding myself disillusioned with the quality of discussion in this sub,"I see multiple highly-upvoted comments per day saying things like “LLMs aren’t AI,” demonstrating a complete misunderstanding of the technical definitions of these terms. Or worse, comments that say “this stuff isn’t AI, AI is like \*insert sci-fi reference\*.” And this is just comments on very high-level topics. If these views are not just being expressed, but are widely upvoted, I can’t help but think this sub is being infiltrated by laypeople without any background in this field and watering down the views of the knowledgeable DS community. I’m wondering if others are feeling this way. Edits to address some common replies: * I misspoke about ""the technical definition"" of AI. As others have pointed out, there is no single accepted definition for artificial intelligence. * It is widely accepted in the field that machine learning is a subfield of artificial intelligence. * In the 4th Edition of Russell and Norvig's Artificial Intelligence: A Modern Approach (one of the, if not the, most popular academic texts on the topic) states >In the public eye, there is sometimes confusion between the terms “artificial intelligence” and “machine learning.” Machine learning is a subfield of AI that studies the ability to improve performance based on experience. Some AI systems use machine learning methods to achieve competence, but some do not. * My point isn't that everyone who visits this community should know this information. Newcomers and outsiders should be welcome. Comments such as ""LLMs aren’t AI"" indicate that people are confidently posting views that directly contradict widely accepted views within the field. If such easily refutable claims are being confidently shared and upvoted, that indicates to me that more nuanced conversations in this community may be driven by confident yet uninformed opinions. None of us are experts in everything, and, when reading about a topic I don't know much about, I have to trust that others in that conversation are informed. If this community is the blind leading the blind, it is completely worthless.",user_970ca8dd,178,0.77,149,2026-02-06 08:11:36,https://www.reddit.com/r/datascience/comments/1qxltyk/finding_myself_disillusioned_with_the_quality_of/,https://www.reddit.com/r/datascience/comments/1qxltyk/finding_myself_disillusioned_with_the_quality_of/,True,Discussion,self.datascience,datascience,False,False
1qxf2xt,Is Gen AI the only way forward?,"I just had 3 shitty interviews back-to-back. Primarily because there was an insane mismatch between their requirements and my skillset. I am your standard Data Scientist (*Banking, FMCG and Supply Chain*), with analytics heavy experience along with some ML model development. A generalist, one might say. I am looking for new jobs but all I get calls are for Gen AI. But their JD mentions other stuff - Relational DBs, Cloud, Standard ML toolkit...you get it. So, I had assumed GenAI would not be the primary requirement, but something like good-to-have. But upon facing the interview, it turns out, **these are GenAI developer roles** that require heavily technical and training of LLM models. Oh, these are all API calling companies, not R&D. Clearly, I am not a good fit. But I am unable to get roles/calls in standard business facing data science roles. This kind of indicates the following things: 1. Gen AI is wayyy too much in demand, inspite of all the AI Hype. 2. The DS boom in last decade has an oversupply of generalists like me, thus standard roles are saturated. **I would like to know your opinions and definitely can use some advice.** **Note**: The experience is APAC-specific. I am aware, market in US/Europe is competitive in a whole different manner.",user_520ead06,271,0.88,143,2026-02-06 03:25:29,https://www.reddit.com/r/datascience/comments/1qxf2xt/is_gen_ai_the_only_way_forward/,https://www.reddit.com/r/datascience/comments/1qxf2xt/is_gen_ai_the_only_way_forward/,True,Career | Asia,self.datascience,datascience,False,False
1qxcgd1,Fun matplotlib upgrade,,user_310943db,187,0.97,20,2026-02-06 00:46:07,https://i.redd.it/hehy4p02v2fg1.gif,https://www.reddit.com/r/datascience/comments/1qxcgd1/fun_matplotlib_upgrade/,False,Tools,i.redd.it,datascience,False,False
1qxv8ng,"This was posted by a guy who ""helps people get hired"", so take it with a grain of salt - ""Which companies hire the most first-time Data Analysts?""",,user_3b4b526e,15,0.76,8,2026-02-06 13:57:18,https://imgur.com/3v39lf4,https://www.reddit.com/r/datascience/comments/1qxv8ng/this_was_posted_by_a_guy_who_helps_people_get/,False,Discussion,imgur.com,datascience,False,False
1qxjifc,Data cleaning survival guide,"In the [first post](https://www.reddit.com/r/datascience/comments/1qsxuaa/why_is_data_cleaning_hard/), I defined data cleaning as **aligning data with reality**, not making it look neat. Here’s the 2nd post on best practices how to make data cleaning less painful and tedious. # Data cleaning is a loop Most real projects follow the same cycle: **Discovery → Investigation → Resolution** Example (e-commerce): you see random revenue spikes and a model that predicts “too well.” You inspect spike days, find duplicate orders, talk to the payment team, learn they retry events on timeouts, and ingestion sometimes records both. You then dedupe using an event ID (or keep latest status) and add a flag like collapsed\_from\_retries for traceability. It’s a loop because you rarely uncover all issues upfront. # When it becomes slow and painful * Late / incomplete discovery: you fix one issue, then hit another later, rerun everything, repeat. * Cross-team dependency: business and IT don’t prioritize “weird data” until you show impact. * Context loss: long cycles, team rotation, meetings, and you end up re-explaining the same story. # Best practices that actually help **1) Improve Discovery (find issues earlier)** Two common misconceptions: * exploration isn’t just describe() and null rates, it’s “does this behave like the real system?” * discovery isn’t only the data team’s job, you need business/system owners to validate what’s plausible A simple repeatable approach: * quick first pass (formats, samples, basic stats) * write a small list of **project-critical assumptions** (e.g., “1 row = 1 order”, “timestamps are UTC”) * test assumptions with targeted checks * validate fast with the people who own the system **2) Make Investigation manageable** Treat anomalies like product work: * prioritize by **impact vs cost** (with the people who will help you). * frame issues as outcomes, not complaints (“if we fix this, the churn model improves”) * track a small backlog: observation → hypothesis → owner → expected impact → effort **3) Resolution without destroying signals** * keep **raw data immutable** (cleaned data is an interpretation layer) * implement transformations **by issue** (e.g., resolve\_gateway\_retries()), not generic “cleaning steps”, not by column. * preserve uncertainty with flags (was\_imputed, rejection reasons, dedupe indicators) **Bonus**: documentation is leverage (especially with AI tools) Don’t just document code. Document **assumptions and decisions** (“negative amounts are refunds, not errors”). Keep a short living “cleaning report” so the loop gets cheaper over time.",user_8dcabaa6,13,0.64,3,2026-02-06 06:45:51,https://www.reddit.com/r/datascience/comments/1qxjifc/data_cleaning_survival_guide/,https://www.reddit.com/r/datascience/comments/1qxjifc/data_cleaning_survival_guide/,True,Discussion,self.datascience,datascience,False,False
1qxo3le,easy_sm - A Unix-style CLI for AWS SageMaker that lets you prototype locally before deploying,"I built [`easy_sm`](https://prteek.github.io/easy_sm/) to solve a pain point with AWS SageMaker: the slow feedback loop between local development and cloud deployment. **What it does:** Train, process, and deploy ML models locally in Docker containers that mimic SageMaker's environment, then deploy the same code to actual SageMaker with minimal config changes. It also manages endpoints and training jobs with composable, pipable commands following Unix philosophy. **Why it's useful:** Test your entire ML workflow locally before spending money on cloud resources. Commands are designed to be chained together, so you can automate common workflows like ""get latest training job → extract model → deploy endpoint"" in a single line. It's experimental (APIs may change), requires Python 3.13+, and borrows heavily from [Sagify](https://github.com/Kenza-AI/sagify). MIT licensed. Docs: [https://prteek.github.io/easy\_sm/](https://prteek.github.io/easy_sm/) GitHub: [https://github.com/prteek/easy\_sm](https://github.com/prteek/easy_sm) PyPI: [https://pypi.org/project/easy-sm/](https://pypi.org/project/easy-sm/) Would love feedback, especially if you've wrestled with SageMaker workflows before.",user_b0ff59b2,3,1.0,1,2026-02-06 09:33:06,https://www.reddit.com/r/datascience/comments/1qxo3le/easy_sm_a_unixstyle_cli_for_aws_sagemaker_that/,https://www.reddit.com/r/datascience/comments/1qxo3le/easy_sm_a_unixstyle_cli_for_aws_sagemaker_that/,True,ML,self.datascience,datascience,False,False
1qx11ri,Traditional ML vs Experimentation Data Scientist,"I’m a Senior Data Scientist (5+ years) currently working with traditional ML (forecasting, fraud, pricing) at a large, stable tech company. I have the option to move to a smaller / startup-like environment focused on causal inference, experimentation (A/B testing, uplift), and Media Mix Modeling (MMM). I’d really like to hear opinions from people who have experience in either (or both) paths: • Traditional ML (predictive models, production systems) • Causal inference / experimentation / MMM Specifically, I’m curious about your perspective on: 1. Future outlook: Which path do you think will be more valuable in 5–10 years? Is traditional ML becoming commoditized compared to causal/decision-focused roles? 2. Financial return: In your experience (especially in the US / Europe / remote roles), which path tends to have higher compensation ceilings at senior/staff levels? 3. Stress vs reward: How do these paths compare in day-to-day stress? (firefighting, on-call, production issues vs ambiguity, stakeholder pressure, politics) 4. Impact and influence: Which roles give you more influence on business decisions and strategy over time? I’m not early career anymore, so I’m thinking less about “what’s hot right now” and more about long-term leverage, sustainability, and meaningful impact. Any honest takes, war stories, or regrets are very welcome.",user_1358e086,73,0.97,34,2026-02-05 15:18:28,https://www.reddit.com/r/datascience/comments/1qx11ri/traditional_ml_vs_experimentation_data_scientist/,https://www.reddit.com/r/datascience/comments/1qx11ri/traditional_ml_vs_experimentation_data_scientist/,True,Discussion,self.datascience,datascience,False,False
1qx1cr3,Has anyone experienced a hands-on Python coding interview focused on data analysis and model training?,"I have a Python coding round coming up where I will need to analyze data, train a model, and evaluate it. I do this for work, so I am confident I can put together a simple model in 60 minutes, but I am not sure how they plan to test Python specifically. Any tips on how to prep for this would be appreciated.",user_d528b440,62,1.0,29,2026-02-05 15:31:09,https://www.reddit.com/r/datascience/comments/1qx1cr3/has_anyone_experienced_a_handson_python_coding/,https://www.reddit.com/r/datascience/comments/1qx1cr3/has_anyone_experienced_a_handson_python_coding/,True,Career | US,self.datascience,datascience,False,False
1qwcdb6,"Thinking About Going into Consulting? McKinsey and BCG Interviews Now Test AI Skills, Too",,user_b85d427c,39,0.79,4,2026-02-04 21:10:37,https://www.interviewquery.com/p/mckinsey-bcg-ai-consulting-interviews,https://www.reddit.com/r/datascience/comments/1qwcdb6/thinking_about_going_into_consulting_mckinsey_and/,False,Discussion,interviewquery.com,datascience,False,False
1qw9fvl,"Production patterns for RAG chatbots: asyncio.gather(), BackgroundTasks, and more",,user_6bf3868f,10,0.86,0,2026-02-04 18:52:50,/r/Rag/comments/1qw9dxy/production_patterns_for_rag_chatbots/,https://www.reddit.com/r/datascience/comments/1qw9fvl/production_patterns_for_rag_chatbots/,False,ML,,datascience,False,False
1qwz1yi,Writing good evals is brutally hard - so I built an AI to make it easier,"I spent years on Apple's Photos ML team teaching models incredibly subjective things - like which photos are ""meaningful"" or ""aesthetic"". It was humbling. Even with careful process, getting consistent evaluation criteria was brutally hard. Now I build an eval tool called [Kiln](https://github.com/kiln-ai/kiln), and I see others hitting the exact same wall: people can't seem to write great evals. They miss edge cases. They write conflicting requirements. They fail to describe boundary cases clearly. Even when they follow the right process - golden datasets, comparing judge prompts - they struggle to write prompts that LLMs can consistently judge. So I built an AI copilot that helps you build evals and synthetic datasets. The result: **5x faster development time and 4x lower judge error rates**. **TL;DR:** An AI-guided refinement loop that generates tough edge cases, has you compare your judgment to the AI judge, and refines the eval when you disagree. You just rate examples and tell it why it's wrong. Completely free. # How It Works: AI-Guided Refinement The core idea is simple: the AI generates synthetic examples targeting your eval's weak spots. You rate them, tell it why it's wrong when it's wrong, and iterate until aligned. 1. **Review before you build** \- The AI analyzes your eval goals and task definition before you spend hours labeling. Are there conflicting requirements? Missing details? What does that vague phrase actually mean? It asks clarifying questions upfront. 2. **Generate tough edge cases** \- It creates synthetic examples that intentionally probe the boundaries - the cases where your eval criteria are most likely to be unclear or conflicting. 3. **Compare your judgment to the judge** \- You see the examples, rate them yourself, and see how the AI judge rated them. When you disagree, you tell it why in plain English. That feedback gets incorporated into the next iteration. 4. **Iterate until aligned** \- The loop keeps surfacing cases where you and the judge might disagree, refining the prompts and few-shot examples until the judge matches your intent. If your eval is already solid, you're done in minutes. If it's underspecified, you'll know exactly where. By the end, you have an eval dataset, a training dataset, and a synthetic data generation system you can reuse. # Results I thought I was decent at writing evals (I build an open-source eval framework). But the evals I create with this system are noticeably better. For **technical evals**: it breaks down every edge case, creates clear rule hierarchies, and eliminates conflicting guidance. For **subjective evals**: it finds more precise, judgeable language for vague concepts. I said ""no bad jokes"" and it created categories like ""groaner"" and ""cringe"" - specific enough for an LLM to actually judge consistently. Then it builds few-shot examples demonstrating the boundaries. # Try It Completely free and open source. Takes a few minutes to get started: * [GitHub (4.6k stars)](https://github.com/kiln-ai/kiln) * [Docs with Demo](https://docs.kiln.tech/docs/evals-and-specs/specifications) What's the hardest eval you've tried to write? I'm curious what edge cases trip people up - happy to answer questions!",user_cf37a366,0,0.37,8,2026-02-05 13:59:18,https://www.reddit.com/r/datascience/comments/1qwz1yi/writing_good_evals_is_brutally_hard_so_i_built_an/,https://www.reddit.com/r/datascience/comments/1qwz1yi/writing_good_evals_is_brutally_hard_so_i_built_an/,True,Projects,self.datascience,datascience,False,False
1qv95en,Why is backward elimination looked down upon yet my team uses it and the model generates millions?,"I’ve been reading Frank Harrell’s critiques of backward elimination, and his arguments make a lot of sense to me. That said, if the method is really that problematic, why does it still seem to work reasonably well in practice? My team uses backward elimination regularly for variable selection, and when I pushed back on it, the main justification I got was basically “we only want statistically significant variables.” Am I missing something here? When, if ever, is backward elimination actually defensible?",user_4e69ec53,119,0.89,59,2026-02-03 16:17:10,https://www.reddit.com/r/datascience/comments/1qv95en/why_is_backward_elimination_looked_down_upon_yet/,https://www.reddit.com/r/datascience/comments/1qv95en/why_is_backward_elimination_looked_down_upon_yet/,True,Statistics,self.datascience,datascience,False,False
1qvdw7t,Destroy my A/B Test Visualization (Part 2) [D],,user_50c1c915,0,0.5,2,2026-02-03 19:46:22,/r/statistics/comments/1qv1a2n/destroy_my_ab_test_visualization_part_2_d/,https://www.reddit.com/r/datascience/comments/1qvdw7t/destroy_my_ab_test_visualization_part_2_d/,False,Projects,,datascience,False,False
1qtzy39,"U.S. Tech Jobs Could See Growth in Q1 2026, Toptal Data Suggests",,user_7f97b18b,153,0.9,32,2026-02-02 08:35:22,https://www.interviewquery.com/p/us-tech-jobs-growth-q1-2026,https://www.reddit.com/r/datascience/comments/1qtzy39/us_tech_jobs_could_see_growth_in_q1_2026_toptal/,False,Discussion,interviewquery.com,datascience,False,False
1qtr5cw,"[Project] PerpetualBooster v1.1.2: GBM without hyperparameter tuning, now 2x faster with ONNX/XGBoost support","Hi all, We just released v1.1.2 of PerpetualBooster. For those who haven't seen it, it's a gradient boosting machine (GBM) written in Rust that eliminates the need for hyperparameter optimization by using a generalization algorithm controlled by a single ""budget"" parameter. This update focuses on performance, stability, and ecosystem integration. Key Technical Updates: - Performance: up to 2x faster training. - Ecosystem: Full R release, ONNX support, and native ""Save as XGBoost"" for interoperability. - Python Support: Added Python 3.14, dropped 3.9. - Data Handling: Zero-copy Polars support (no memory overhead). - API Stability: v1.0.0 is now the baseline, with guaranteed backward compatibility for all 1.x.x releases (compatible back to v0.10.0). Benchmarking against LightGBM + Optuna typically shows a 100x wall-time speedup to reach the same accuracy since it hits the result in a single run. GitHub: https://github.com/perpetual-ml/perpetual Would love to hear any feedback or answer questions about the algorithm!",user_8593d7f2,78,0.95,17,2026-02-02 02:08:33,https://www.reddit.com/r/datascience/comments/1qtr5cw/project_perpetualbooster_v112_gbm_without/,https://www.reddit.com/r/datascience/comments/1qtr5cw/project_perpetualbooster_v112_gbm_without/,True,Projects,self.datascience,datascience,False,False
1qtlvfu,"Weekly Entering & Transitioning - Thread 02 Feb, 2026 - 09 Feb, 2026","Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include: * Learning resources (e.g. books, tutorials, videos) * Traditional education (e.g. schools, degrees, electives) * Alternative education (e.g. online courses, bootcamps) * Job search questions (e.g. resumes, applying, career prospects) * Elementary questions (e.g. where to start, what next) While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",user_ac31a110,7,1.0,20,2026-02-01 21:01:38,https://www.reddit.com/r/datascience/comments/1qtlvfu/weekly_entering_transitioning_thread_02_feb_2026/,https://www.reddit.com/r/datascience/comments/1qtlvfu/weekly_entering_transitioning_thread_02_feb_2026/,True,,self.datascience,datascience,False,False
1qtzq0k,[Discussion] How many years out are we from this?,,user_5fc844e2,0,0.33,14,2026-02-02 08:27:26,/r/statistics/comments/1qtzpgv/discussion_how_many_years_out_are_we_from_this/,https://www.reddit.com/r/datascience/comments/1qtzq0k/discussion_how_many_years_out_are_we_from_this/,False,Discussion,,datascience,False,False
1qsls5g,"Am I drifting away from Data Science, or building useful foundations? (2 YOE working in a startup, no coding)","I’m looking for some career perspective and would really appreciate advice from people working in or around data science. I’m currently not sure where exactly is my career heading and want to start a business eventually in which I can use my data science skills as a tool, not forcefully but purposefully. Also my current job is giving me good experience of being in a startup environment where I’m able to learning to set up a manufacturing facility from scratch and able to first hand see business decisions and strategies. I also have some freedom to implement some of my ideas to improve or set new systems in the company and see it work eg. using m365 tools like sharepoint power automate power apps etc to create portals, apps and automation flows which collect data and I present that in meetings. But this involves no coding at all and very little implementation of what I learnt in school. Right now I’m struggling with a few questions: 1)Am I moving away from a real data science career, or building underrated foundations? 2)What does an actual data science role look like day-to-day in practice? 3)Is this kind of startup + tooling experience valuable, or will it hurt me later? 4)If my end goal is entrepreneurship + data, what skills should I be prioritizing now? 5)At what point should I consider switching roles or companies? This is my first job and I’ve been here for 2 years. I’m not sure what exactly to expect from an actual DS role and currently I’m not sure if Im going in the right direction to achieve my end goal of starting a company of my own before 30s.",user_62d7cae1,42,0.9,10,2026-01-31 18:19:48,https://www.reddit.com/r/datascience/comments/1qsls5g/am_i_drifting_away_from_data_science_or_building/,https://www.reddit.com/r/datascience/comments/1qsls5g/am_i_drifting_away_from_data_science_or_building/,True,Career | US,self.datascience,datascience,False,False
1qrtgse,What separates data scientists who earn a good living (100k-200k) from those who earn 300k+ at FAANG?,Is it just stock options and vesting? Or is it just FAANG is a lot of work. Why do some data scientists deserve that much? I work at a Fortune 500 and the ceiling for IC data scientists is around $200k unless you go into management of course. But how and why do people make 500k at Google without going into management? Obviously I’m talking about 1% or less of data scientists but still. I’m less than a year into my full time data scientist job and figuring out my goals and long term plans.,user_59fa8efa,546,0.95,205,2026-01-30 21:15:29,https://www.reddit.com/r/datascience/comments/1qrtgse/what_separates_data_scientists_who_earn_a_good/,https://www.reddit.com/r/datascience/comments/1qrtgse/what_separates_data_scientists_who_earn_a_good/,True,Discussion,self.datascience,datascience,False,False
1qsylys,Brainstorming around the visualization of customer segment data,,user_50c1c915,1,0.6,8,2026-02-01 05:35:10,https://ibb.co/C3pxC8TV,https://www.reddit.com/r/datascience/comments/1qsylys/brainstorming_around_the_visualization_of/,False,Challenges,ibb.co,datascience,False,False
1qsxuaa,Why is data cleaning hard?,"In almost all polls, data cleaning is always at the top of data scientists’ pain points. Recently, I tried to sit down and structure my thought about it from first principles. It help me realized what actually is data cleaning, why it is often necessary and why it feels hard. \- data cleaning is not about make data looks cleaner, it is fixing data to be closer to reality. \- data cleaning is often necessary in data science when we work on new use cases, or simply because the data pipeline fail at some point. \- data cleaning is hard because it often requires knowledge from other teams: business knowledge from operational team and system knowledge from IT team. This make it slow and painful particularly when those teams are not ready to support data science. This is a first article on the topic, I will try to do other articles on best prectices to make the process better and maybe a case study. Hopefully it could help our community, mostly junior ppl. And you, how are your experience and thoughts on this topic?",user_8dcabaa6,0,0.5,19,2026-02-01 05:00:05,https://www.reddit.com/r/datascience/comments/1qsxuaa/why_is_data_cleaning_hard/,https://www.reddit.com/r/datascience/comments/1qsxuaa/why_is_data_cleaning_hard/,True,Discussion,self.datascience,datascience,False,False
1qt2hhe,My thoughts on my recent interview experiences in tech,"Hi folks, You might remember me from some of my previous posts in this subreddit about how to pass product analytics interviews in tech. Well, it turns out I needed to take my own advice because I was laid off last year. I recently started interviewing and wanted to share my experience in case it’s helpful. I also share what I learned about salary and total compensation. Note that this post is mostly about my experience trying to pass interviews, not about getting interviews. # Context * I’m a data scientist focused on product analytics in tech, targeting staff and lead level roles. This post won’t be very relevant to you if you’re more focused on machine learning, data engineering, or research * I started applying on January 1st * In the last two weeks, I had: * 6 recruiter calls * 4 tech screens * 2 hiring manager calls Companies so far are a mix of MAANG, other large tech companies, and mid to late stage startups. # Pipeline so far: * 6 recruiter screens * 5 moved me forward * 4 tech screens, two hiring manager calls (1 hiring manager did not move me forward) * I passed 2 tech screens, waiting to hear back from the other 2 * Right now I have two final rounds coming up. One with a MAANG and one with a startup. # Recruiter Calls The recruiter calls were all pretty similar. They asked me: * About my background and experience * One behavioral question (influencing roadmap, leading an AB test, etc.) * What I’m looking for next * Compensation expectations * Work eligibility and remote or relocation preferences * My timeline, where I am in the process with other companies * They told me more about the company, role, and what the process looks like **Here’s a tip about compensation:** I did my research so when they asked my compensation expectations, I told them a number that I thought would be on the high end of their band. But here's the tip: After sharing my number, I asked: “Is that in your range?” Once they replied, I followed with: “What is the range, if you don’t mind me asking?” 2 out of 6 recruiters actually shared what typical offers look like! A MAAANG company told me: * Staff/Lead: 230k base, 390k total comp, 40k signing bonus * Senior: 195k base, 280k total comp, 20k signing bonus A late stage startup told me: * Staff/Lead: 235k base, 435k total comp * Senior: 200k base, 315k total comp * (I don’t know how they’re valuing their equity to come up with total comp) # Tech Screens I’ve done 4 tech screens so far. All were 45 to 60 minutes. **SQL** All four tested SQL. I used SQL daily at work, but I was rusty from not working for a while. I used [Stratascratch ](https://www.stratascratch.com/?via=productanalyst)to brush up. I did 5 questions per day for 10 days: 1 easy, 3 medium, 1 hard. My rule of thumb for SQL is: * Easy: 100% in under 3 minutes * Medium: 100% in under 4 minutes * Hard: \~80% in under 7 minutes If you can do this, you can pass almost any SQL tech screen for product analytics roles. **Case questions** 3 out of 4 tech screens had some type of case product question. * Two were follow ups to the SQL. I was asked to interpret the results, explain what is happening, hypothesize why, where I would dig deeper, etc. * One asked a standalone case: Is feature X better than feature Y? I had to define what “better” means, propose metrics, outline an AB test * One showed me some statistical output and asked me to interpret it, what other data I would want to see, and recommend next steps. The output contained a bunch of descriptive data, a funnel analysis, and p-values If you struggle with product sense, analytics case questions, and/or AB testing, there’s a lot of resources out there. Here’s what I used: * [Here's a free framework and case study](https://medium.com/datainterview/principles-and-frameworks-of-product-metrics-youtube-case-study-ff63257a82d3) * [Another framework guide](https://medium.com/data-science/the-ultimate-guide-to-cracking-business-case-interviews-for-data-scientists-part-1-cb768c37edf4) * Watch mock interviews on Youtube * If you’re willing to spend some money, [Ace the Data Science Interview ](https://amzn.to/4a9kzTE)has a few good chapters with common frameworks, and several practice cases with answers * [Trustworthy Online Controlled Experiments](https://amzn.to/4qS2O2p) is the gold standard for AB testing **Python** Only one tech screen so far had a Python component, but another tech screen that I’m waiting to take has a Python component too. I don’t use Python much in my day to day work. I do my data wrangling in SQL and use Python just for statistical tests. And even when I did use Python, I’d lean on AI, so I’m weak on this part. Again, I used [Stratascratch ](https://www.stratascratch.com/?via=productanalyst)to prep. I usually do 5-10 questions a day. But I focused too much on manipulating data with Pandas. The one Python tech screen I had tested on: * Functions * Loops * List comprehension I can’t do these from memory so I did not do well in the interview. # Hiring Manager Calls I had two of these. Some companies stick this step in between the recruiter screen and tech screen. I was asked about: * Specific examples of influencing the roadmap * Working with, and influencing leadership * Most technical project I’ve worked on * One case question about measuring the success of a feature * What I’m looking for next # Where I am now * Two final rounds scheduled in the next 2-3 weeks * Waiting to hear back from two tech screens # Final thoughts It feels like the current job market is much harder than when I was looking \~4 years ago. It’s harder to get interviews, and the tech screens are harder. When I was looking 4 years ago, I must have done 8 or 10 tech screens and they were purely SQL. Now, the tech screens might have a Python component and case questions. The pay bands also seem lower or flat compared to 4 years ago. The Senior total comp at one MAANG is lower than what I was offered in 2022 as a Senior, and the Staff/Lead total comp is lower than what I was making as a Senior in big tech. I hope this was helpful. I plan to do another update after I do a few final loops. If you want more information about how to pass product analytics interviews at tech companies, check out my previous post: [How to pass the Product Analytics interview at tech companies](https://futureproductanalyst.substack.com/p/how-to-pass-the-product-analytics)",user_91bf0daf,0,0.45,18,2026-02-01 08:09:31,https://www.reddit.com/r/datascience/comments/1qt2hhe/my_thoughts_on_my_recent_interview_experiences_in/,https://www.reddit.com/r/datascience/comments/1qt2hhe/my_thoughts_on_my_recent_interview_experiences_in/,True,Education,self.datascience,datascience,False,False
1qrohou,Managers what's your LLM strategy?,"I'm a data science manager with a small team, so I've been interested in figuring out how to use more LLM magic to get my team some time back. Wondering what some common strategies are? The areas I've found challenges in are * documentation: we don't have enough detailed documentation readily available to plug in, so it's like a cold start problem. * validation: LLMs are so eager to spit out lines of code, so it writes 100 lines of code for the 20 lines of code it needed and reviewing it can be almost more effort than writing it yourself. * tools: either we give it something too generic and have to write a ton of documentation / best practice or we spend a ton of time structuring the tools to the point we lack any flexibility.",user_168158f9,34,0.78,27,2026-01-30 17:24:03,https://www.reddit.com/r/datascience/comments/1qrohou/managers_whats_your_llm_strategy/,https://www.reddit.com/r/datascience/comments/1qrohou/managers_whats_your_llm_strategy/,True,Discussion,self.datascience,datascience,False,False
1qqvlcn,"While US Tech Hiring Slows, Countries Like Finland Are Attracting AI Talent",,user_e6f6eb17,172,0.95,24,2026-01-29 20:31:53,https://www.interviewquery.com/p/finland-fast-track-tech-visas-ai-talent,https://www.reddit.com/r/datascience/comments/1qqvlcn/while_us_tech_hiring_slows_countries_like_finland/,False,Discussion,interviewquery.com,datascience,False,False
1qqtj9y,From Individual Contributor to Team Lead — what actually changes in how you create value?,"I recently got promoted from individual contributor to data science team lead, and honestly I’m still trying to recalibrate how I should work and think. As an IC, value creation was pretty straightforward: pick a problem, solve it well, ship something useful. If I did my part right, the value was there. Now as a team lead, the bottleneck feels very different. It’s much more about judgment than execution: * Is this problem even worth solving? * Does it matter for the business or the system as a whole? * Is it worth spending our limited time and people on it instead of something else? * How do I get results *through* other people and through the organization, rather than by doing everything myself? I find that being “technically right” is often not the hard part anymore. The harder part is deciding *what* to be right about, and *where* to apply effort. For those of you who’ve made a similar transition: * How did you train your sense of value judgment? * How do you decide what *not* to work on? * What helped you move from “doing good work yourself” to “creating leverage through others”? * Any mental models, habits, or mistakes-you-learned-from that were particularly helpful? Would love to hear how people here think about this shift. I suspect this is one of those transitions that looks simple from the outside but is actually pretty deep.",user_476dbb1a,53,0.92,14,2026-01-29 18:55:01,https://www.reddit.com/r/datascience/comments/1qqtj9y/from_individual_contributor_to_team_lead_what/,https://www.reddit.com/r/datascience/comments/1qqtj9y/from_individual_contributor_to_team_lead_what/,True,Discussion,self.datascience,datascience,False,False
1qqg341,Just had a job interview and was told that no-one uses Airflow in 2026,So basically the title. I didn't react to the comment because I just was extremely surprised by it. What is your experience? How true is the statement?,user_6c2e3f87,105,0.93,90,2026-01-29 10:06:40,https://www.reddit.com/r/datascience/comments/1qqg341/just_had_a_job_interview_and_was_told_that_noone/,https://www.reddit.com/r/datascience/comments/1qqg341/just_had_a_job_interview_and_was_told_that_noone/,True,Tools,self.datascience,datascience,False,False
1qputs6,Google Maps query for whole state,"I live in North Carolina, US and in my state there is a grocery chain called Food Lion. Anecdotally I have observed that where there is a Food Lion there is a Chinese restaurant in the same shopping center. Is there a way to query Google Maps for Food Lion and Chinese restaurants in the state of North Carolina and get the latitude and longitude for each location so I can calculate all the distances?",user_67e7d08b,43,0.95,10,2026-01-28 17:38:30,https://www.reddit.com/r/datascience/comments/1qputs6/google_maps_query_for_whole_state/,https://www.reddit.com/r/datascience/comments/1qputs6/google_maps_query_for_whole_state/,True,Projects,self.datascience,datascience,False,False
1qohv5a,How long did it take you to get comfortable with statistics?,how long did it take from your first undergrad class to when you felt comfortable with understanding statistics? (Whatever that means for you) When did you get the feeling like you understood the methodologies and papers needed for your level?,user_1479602f,68,0.96,52,2026-01-27 08:02:12,https://www.reddit.com/r/datascience/comments/1qohv5a/how_long_did_it_take_you_to_get_comfortable_with/,https://www.reddit.com/r/datascience/comments/1qohv5a/how_long_did_it_take_you_to_get_comfortable_with/,True,Statistics,self.datascience,datascience,False,False
1qnshcs,What do you guys do during a gridsearch,So I'm building some models and I'm having to do some gridsearch to fine tune my decision trees. They take about 50 mins for my computer to run. I'm just curious what everyone does while these long processes are running. Getting coffee and a conversation is only 10mins. Thanks,user_b74ae00a,60,0.9,59,2026-01-26 12:49:37,https://www.reddit.com/r/datascience/comments/1qnshcs/what_do_you_guys_do_during_a_gridsearch/,https://www.reddit.com/r/datascience/comments/1qnshcs/what_do_you_guys_do_during_a_gridsearch/,True,Discussion,self.datascience,datascience,False,False
1qn6qhu,"Weekly Entering & Transitioning - Thread 26 Jan, 2026 - 02 Feb, 2026","Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include: * Learning resources (e.g. books, tutorials, videos) * Traditional education (e.g. schools, degrees, electives) * Alternative education (e.g. online courses, bootcamps) * Job search questions (e.g. resumes, applying, career prospects) * Elementary questions (e.g. where to start, what next) While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",user_ac31a110,14,0.95,19,2026-01-25 21:01:28,https://www.reddit.com/r/datascience/comments/1qn6qhu/weekly_entering_transitioning_thread_26_jan_2026/,https://www.reddit.com/r/datascience/comments/1qn6qhu/weekly_entering_transitioning_thread_26_jan_2026/,True,,self.datascience,datascience,False,False
1qlb03x,"Went on a date and the girl said... ""Soooo.... What kind of... data do you science???""",Didn't know what to say. Humor me with your responses. Update: I sent her this post and she loved it 🤣,user_4378e9ab,1013,0.94,152,2026-01-23 18:41:58,https://www.reddit.com/r/datascience/comments/1qlb03x/went_on_a_date_and_the_girl_said_soooo_what_kind/,https://www.reddit.com/r/datascience/comments/1qlb03x/went_on_a_date_and_the_girl_said_soooo_what_kind/,True,Discussion,self.datascience,datascience,False,False
1qkzkgd,How do you get over a poor interview performance?,"I recently did a hiring manager round at a company I would have loved to work for. From the beginning, the hiring manager seemed a bit disinterested and it felt like he was chatting with someone else during the interview. At one point I even saw him smiling while I was talking, and I was not saying anything remotely amusing. That really threw me off and I got distracted, which led to me not answering some questions as well as I should have. The questions were about my past experience, things I definitely knew, and I think that ultimately contributed to my rejection. I was really looking forward to interviewing there, and in hindsight I feel like I could have done much better, especially if I had prepared a bit more. Hindsight is always 20 20. How do you get over interviews like this?",user_4e69ec53,52,0.91,29,2026-01-23 10:58:44,https://www.reddit.com/r/datascience/comments/1qkzkgd/how_do_you_get_over_a_poor_interview_performance/,https://www.reddit.com/r/datascience/comments/1qkzkgd/how_do_you_get_over_a_poor_interview_performance/,True,Career | US,self.datascience,datascience,False,False
1qkw300,[D] Bayesian probability vs t-test for A/B testing,,user_50c1c915,12,0.84,15,2026-01-23 08:52:31,/r/statistics/comments/1qkv067/d_bayesian_probability_vs_ttest_for_ab_testing/,https://www.reddit.com/r/datascience/comments/1qkw300/d_bayesian_probability_vs_ttest_for_ab_testing/,False,Discussion,,datascience,False,False
1qjoqu2,Do you still use notebooks in DS?,"I work as a data scientist and I usually build models in a notebook and then create them into a python script for deployment. Lately, I’ve been wondering if this is the most efficient approach and I’m curious to learn about any hacks, workflows or processes you use to speed things up or stay organized. Especially now that AI tools are everywhere and GenAI still not great at working with notebooks.",user_22d39bdb,90,0.96,74,2026-01-22 00:03:11,https://www.reddit.com/r/datascience/comments/1qjoqu2/do_you_still_use_notebooks_in_ds/,https://www.reddit.com/r/datascience/comments/1qjoqu2/do_you_still_use_notebooks_in_ds/,True,Discussion,self.datascience,datascience,False,False
1qjkko5,What’s your Full stack data scientist story.,"Data scientists label has been applied with a broad brush in some company data scientists mostly do analytics, some do mostly stat and quant type work, some make models but limited to notebooks and so on. It’s seems logical to be at a startup company or a small team in order to become a full-stack data scientist. Full stack in a sense: ideation-to POC -to Production. My experience (mid size US company \~2000 employees) mostly has been talking with the product clients (internal and external), decide on models and approach, training and testing models and putting the tested version python scripts into git, data engineering/production team clones and implements it. What is your story and what do you suggest getting more exposure to the DATA ENG side to become a full stack data scientist?",user_762dcdb5,49,0.89,15,2026-01-21 20:17:56,https://www.reddit.com/r/datascience/comments/1qjkko5/whats_your_full_stack_data_scientist_story/,https://www.reddit.com/r/datascience/comments/1qjkko5/whats_your_full_stack_data_scientist_story/,True,Discussion,self.datascience,datascience,False,False
1qja2xv,Best and worst companies for DS in 2026?,"I might be losing my big tech job soon, so looking for inputs on trends in the industry for where to apply next with 3-5 YOE. Does anyone have recommendations for what companies/industries to look into and what to avoid in 2026?",user_1479602f,101,0.96,40,2026-01-21 12:59:43,https://www.reddit.com/r/datascience/comments/1qja2xv/best_and_worst_companies_for_ds_in_2026/,https://www.reddit.com/r/datascience/comments/1qja2xv/best_and_worst_companies_for_ds_in_2026/,True,Discussion,self.datascience,datascience,False,False
1qjhf6p,Prod grade python backend patterns,https://open.substack.com/pub/zohaiba886596/p/production-grade-python-backends?utm\_source=share&utm\_medium=android&r=1symwe,user_6bf3868f,17,0.95,7,2026-01-21 17:54:43,https://www.reddit.com/r/datascience/comments/1qjhf6p/prod_grade_python_backend_patterns/,https://www.reddit.com/r/datascience/comments/1qjhf6p/prod_grade_python_backend_patterns/,True,Coding,self.datascience,datascience,False,False
1qinepv,Looking for Group,"Hello all, I am looking for any useful and free email subscriptions to various data analytics/ data science information. Doesn’t matter if it’s from a platform like snowflake or just a substack. Let me know and suggest away.",user_a4271bb8,23,0.96,14,2026-01-20 19:53:36,https://www.reddit.com/r/datascience/comments/1qinepv/looking_for_group/,https://www.reddit.com/r/datascience/comments/1qinepv/looking_for_group/,True,Career | US,self.datascience,datascience,False,False
1qi02sq,Safe space - what's one task you are willing to admit AI does better than 99% of DS?,"Let's just admit any little function you believe AI does better, and will forever do better than 99% of DS You know when you're data cleansing and you need a regex? Yeah The AI overlords got me beat on that.",user_da289fbe,71,0.74,102,2026-01-20 04:41:54,https://www.reddit.com/r/datascience/comments/1qi02sq/safe_space_whats_one_task_you_are_willing_to/,https://www.reddit.com/r/datascience/comments/1qi02sq/safe_space_whats_one_task_you_are_willing_to/,True,AI,self.datascience,datascience,False,False
1qi4mn8,How common is econometrics/causal inf?,,user_2924eca8,8,0.79,19,2026-01-20 07:48:18,/r/analytics/comments/1qi4lyd/how_common_is_econometricscausal_inf/,https://www.reddit.com/r/datascience/comments/1qi4mn8/how_common_is_econometricscausal_inf/,False,Discussion,,datascience,False,False
1qh8z6e,"Indeed: Tech Hiring Is Down 36%, But Data Scientist Jobs Held Steady",,user_7f97b18b,299,0.97,46,2026-01-19 08:32:42,https://www.interviewquery.com/p/indeed-tech-hiring-collapse-data-scientists-exception,https://www.reddit.com/r/datascience/comments/1qh8z6e/indeed_tech_hiring_is_down_36_but_data_scientist/,False,Discussion,interviewquery.com,datascience,False,False
1qhiw2d,What signals make a non-traditional background credible in analytics hiring?,"I’m a PhD student in microbiology pivoting into analytics. I don’t have a formal degree in data science or statistics, but I do have years of research training and quantitative work. I’m actively upskilling and am currently working through DataCamp’s Associate Data Scientist with Python track, alongside building small projects. I intend on doing something similar for SQL and PowerBI. What I’m trying to understand from a hiring perspective is: What actually makes someone with a non-traditional background credible for an analytics role? In particular, I’m unsure how much weight structured tracks like this really carry. Do you expect a career-switcher to “complete the whole ladder” (e.g. finish a full Python track, then a full SQL track, then Power BI, etc.) before you have confidence in them? Or is credibility driven more by something else entirely? I’m trying to avoid empty credential-collecting and focus only on what materially changes your hiring decision. From your perspective, what concrete signals move a candidate like me from “interesting background” to “this person can actually do the job”?",user_56d750c9,31,0.84,22,2026-01-19 14:26:50,https://www.reddit.com/r/datascience/comments/1qhiw2d/what_signals_make_a_nontraditional_background/,https://www.reddit.com/r/datascience/comments/1qhiw2d/what_signals_make_a_nontraditional_background/,True,Discussion,self.datascience,datascience,False,False
1qhnugu,"To those who work in SaaS, what projects and analyses does your data team primarily work on?","Background: - CPA with ~5 years of experience - Finishing my MS in Statistics in a few months The company I work for is maturing with the data it handles. In the near future, it will be a good time to get some experience under my belt by helping out with data projects. So what are your takes on good projects to help out on and maybe spear point?",user_1b486c1c,10,0.92,8,2026-01-19 17:52:44,https://www.reddit.com/r/datascience/comments/1qhnugu/to_those_who_work_in_saas_what_projects_and/,https://www.reddit.com/r/datascience/comments/1qhnugu/to_those_who_work_in_saas_what_projects_and/,True,Projects,self.datascience,datascience,False,False
1qhldsg,Using logistic regression to probabilistically audit customer–transformer matches (utility GIS / SAP / AMI data),"Hey everyone, I’m currently working on a project using utility asset data (GIS / SAP / AMI) and I’m exploring whether this is a solid use case for introducing ML into a **customer-to-transformer matching audit** problem. The goal is to ensure that meters (each associated with a customer) are connected to the correct transformer. # Important context * Current customer → transformer associations are driven by a **location ID** containing circuit, address/road, and company (opco). * After an initial analysis, some associations appear wrong, but **ground truth is partial** and validation is expensive (field work). * The goal is **NOT** to auto-assign transformers. * The goal is to **prioritize which existing matches are most likely wrong**. I’m leaning toward framing this as a **probabilistic risk scoring** problem rather than a hard classification task, with something like **logistic regression** as a first model due to interpretability and governance needs. # Initial checks / predictors under consideration **1) Distance** * Binary distance thresholds (e.g., >550 ft) * Whether the assigned transformer is the **nearest** transformer * Distance ratio: distance to assigned vs. nearest transformer (e.g., nearest is 10 ft away but assigned is 500 ft away) **2) Voltage consistency** * Identifying customers with similar service voltage * Using voltage consistency as a signal to flag unlikely associations (challenging due to very high customer volume) Model output to be: P(current customer → transformer match is wrong) This probability would be used to define operational tiers (auto-safe, monitor, desktop review, field validation). # Questions 1. Does **logistic regression** make sense as a first model for this type of probabilistic audit problem? 2. Any pitfalls when relying heavily on **distance + voltage** as primary predictors? 3. When people move beyond logistic regression here, is it usually **tree-based models + calibration**? 4. Any advice on **threshold / tier design** when labels are noisy and incomplete?",user_73370d11,12,1.0,9,2026-01-19 16:06:17,https://www.reddit.com/r/datascience/comments/1qhldsg/using_logistic_regression_to_probabilistically/,https://www.reddit.com/r/datascience/comments/1qhldsg/using_logistic_regression_to_probabilistically/,True,Projects,self.datascience,datascience,False,False
1qh0m1y,Which role better prepares you for AI/ML and algorithm design?,"Hi everyone, I’m a perception engineer in automotive and joined a new team about 6 months ago. Since then, my work has been split between two very different worlds: • Debugging nasty customer issues and weird edge cases in complex algorithms • C++ development on embedded systems (bug fixes, small features, integrations) Now my manager wants me to pick one path and specialize: 1. Customer support and deep analysis This is technically intense. I’m digging into edge cases, rare failures, and complex algorithm behavior. But most of the time I’m just tuning parameters, writing reports, and racing against brutal deadlines. Almost no real design or coding. 2. Customer projects More ownership and scope fewer fire drills. But a lot of it is integration work and following specs. Some algorithm implementation, but also the risk of spending months wiring things together. Here’s the problem: My long-term goal is AI/ML and algorithm design. I want to build systems, not just debug them or glue components together. Right now, I’m worried about getting stuck in: \* Support hell where I only troubleshoot \* Or integration purgatory where I just implement specs If you were in my shoes: Which path actually helps you grow into AI/ML or algorithm roles? What would you push your manager for to avoid career stagnation? Any real-world advice would be hugely appreciated. Thanks!",user_26333b14,21,0.92,9,2026-01-19 02:25:00,https://www.reddit.com/r/datascience/comments/1qh0m1y/which_role_better_prepares_you_for_aiml_and/,https://www.reddit.com/r/datascience/comments/1qh0m1y/which_role_better_prepares_you_for_aiml_and/,True,AI,self.datascience,datascience,False,False
1qgv0ij,"Weekly Entering & Transitioning - Thread 19 Jan, 2026 - 26 Jan, 2026","Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include: * Learning resources (e.g. books, tutorials, videos) * Traditional education (e.g. schools, degrees, electives) * Alternative education (e.g. online courses, bootcamps) * Job search questions (e.g. resumes, applying, career prospects) * Elementary questions (e.g. where to start, what next) While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",user_ac31a110,9,1.0,9,2026-01-18 21:01:45,https://www.reddit.com/r/datascience/comments/1qgv0ij/weekly_entering_transitioning_thread_19_jan_2026/,https://www.reddit.com/r/datascience/comments/1qgv0ij/weekly_entering_transitioning_thread_19_jan_2026/,True,,self.datascience,datascience,False,False
1qflxse,How the Kronecker product helped me get to benchmark performance.,"Hi everyone, Recently had a common problem, where I had to improve the speed of my code 5x, to get to benchmark performance needed for production level code in my company. Long story short, OCR model scans a document and the goal is to identify which file from the folder with 100,000 files the scan is referring to. I used a bag-of-words approach, where 100,000 files were encoded as a sparse matrix using scipy. To prepare the matrix, CountVectorizer from scikit-learn was used, so I ended up with a 100,000 x 60,000 sparse matrix. To evaluate the number of shared words between the OCR results, and all files, there is a ""minimum"" method implemented, which performs element-wise minimum operation on matrices of the same shape. To use it, I had to convert the 1-dimensional vector encoding the word count in the new scan, to a huge matrix consisting of the same row 100,000 times. One way to do it is to use the ""vstack"" from Scipy, but this turned out to be the bottleneck when I profiled the script. Got the feedback from the main engineer that it has to be below 100ms, and I was stuck at 250ms. Long story short, there is another way of creating a ""large"" sparse matrix with one row repeated, and that is to use the [kron](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.kron.html#scipy.sparse.kron) method (stands for ""Kronecker product""). After implementing, inference time got cut to 80ms. Of course, I left a lot of the details out because it would be too long, but the point is that a somewhat obscure fact from mathematics (I knew about the Kronecker product) got me the biggest performance boost. A.I. was pretty useful, but on its own wasn't enough to get me down below 100ms, had to do old style programming!! Anyway, thanks for reading. I posted this because first I wanted to ask for help how to improve performance, but I saw that the rules don't allow for that. So instead, I'm writing about a neat solution that I found.",user_c0892f6d,51,0.89,21,2026-01-17 11:10:03,https://www.reddit.com/r/datascience/comments/1qflxse/how_the_kronecker_product_helped_me_get_to/,https://www.reddit.com/r/datascience/comments/1qflxse/how_the_kronecker_product_helped_me_get_to/,True,Coding,self.datascience,datascience,False,False
1qf9zxw,Is LLD commonly asked to ML Engineers?,"I am a last year student and i am currently studying for MLE interviews. My focus at the moment is on DSA and basics of ML system design, but i was wondering if i should prepare also oop/design patterns/lld. Are they normally asked to ml engineers or rarely?",user_b7a887ca,18,0.8,27,2026-01-17 02:36:09,https://www.reddit.com/r/datascience/comments/1qf9zxw/is_lld_commonly_asked_to_ml_engineers/,https://www.reddit.com/r/datascience/comments/1qf9zxw/is_lld_commonly_asked_to_ml_engineers/,True,Discussion,self.datascience,datascience,False,False
1qdpz1b,Spent few days on case study only to get ghosted. Is it the market or just bad employer?,"I spent a few days working on a case study for a company and they completely ghosted me after I submitted it. It’s incredibly frustrating because I could have used that time for something more productive. With how bad the job market is, it feels like there’s no real choice but to go along with these ridiculous interview processes. The funniest part is that I didn’t even apply for the role. They reached out to me on LinkedIn. I’ve decided that from now on I’m not doing case studies as part of interviews. Do any of you say no to case studies too?",user_d528b440,87,0.91,29,2026-01-15 09:33:30,https://www.reddit.com/r/datascience/comments/1qdpz1b/spent_few_days_on_case_study_only_to_get_ghosted/,https://www.reddit.com/r/datascience/comments/1qdpz1b/spent_few_days_on_case_study_only_to_get_ghosted/,True,Career | US,self.datascience,datascience,False,False
1qdrqh6,LLM for document search,"My boss wants to have an LLM in house for document searches. I've convinced him that we'll only use it for identifying relevant documents due to the risk of hallucinations, and not perform calculations and the like. So for example, finding all PDF files related to customer X, product Y between 2023-2025. Because of legal concerns it'll have to be hosted locally and air gapped. I've only used Gemini. Does anyone have experience or suggestions about picking a vendor for this type of application? I'm familiar with CNNs but have zero interest in building or training a LLM myself.",user_f22e1a23,2,0.55,33,2026-01-15 10:35:27,https://www.reddit.com/r/datascience/comments/1qdrqh6/llm_for_document_search/,https://www.reddit.com/r/datascience/comments/1qdrqh6/llm_for_document_search/,True,Projects,self.datascience,datascience,False,False
1qd7eq3,Google DS interview,Have a Google Sr. DS interview coming up in a month. Has anyone taken it? tips?,user_b2768c9e,32,0.75,41,2026-01-14 18:34:52,https://www.reddit.com/r/datascience/comments/1qd7eq3/google_ds_interview/,https://www.reddit.com/r/datascience/comments/1qd7eq3/google_ds_interview/,True,Discussion,self.datascience,datascience,False,False
1qd3z2h,Does anyone know how hard it is to work with the All of Us database?,I have limited python proficiency but I can code well with R. I want to design a project that’ll require me to collect patient data from the All of Us database. Does this sound like an unrealistic plan with my limited python proficiency?,user_b3b84b8d,16,0.79,16,2026-01-14 16:04:42,https://www.reddit.com/r/datascience/comments/1qd3z2h/does_anyone_know_how_hard_it_is_to_work_with_the/,https://www.reddit.com/r/datascience/comments/1qd3z2h/does_anyone_know_how_hard_it_is_to_work_with_the/,True,Projects,self.datascience,datascience,False,False
1qcp6k6,How far should I go with LeetCode topics for coding interviews?,"I recently started doing LeetCode to prep for coding interviews. So far I’ve mostly been focusing on arrays, hash maps, strings, and patterns like two pointers, sliding window, and binary search. Should I move on to other topics like stacks, queues, and trees, or is this enough for now?",user_d528b440,24,0.79,24,2026-01-14 06:49:18,https://www.reddit.com/r/datascience/comments/1qcp6k6/how_far_should_i_go_with_leetcode_topics_for/,https://www.reddit.com/r/datascience/comments/1qcp6k6/how_far_should_i_go_with_leetcode_topics_for/,True,Discussion,self.datascience,datascience,False,False
1qdc3uq,SQL performance training question,,user_b65b9798,0,0.43,4,2026-01-14 22:26:14,/r/SQL/comments/1qdc37k/sql_performance_training_question/,https://www.reddit.com/r/datascience/comments/1qdc3uq/sql_performance_training_question/,False,Education,,datascience,False,False
1qcpxga,Modeling exercise for triplets,,user_b65b9798,1,0.6,0,2026-01-14 07:18:26,/r/learnSQL/comments/1qcg0u4/modeling_exercise_for_triplets/,https://www.reddit.com/r/datascience/comments/1qcpxga/modeling_exercise_for_triplets/,False,Education,,datascience,False,False
1qbx8bd,There are several odd things in this analysis.,"I found this in a serious research paper from university of Pennsylvania, related to my research. Those are 2 populations histograms, log-transformed and finally fitted to a normal distribution. Assuming that the data processing is right, how is it that the curves fit the data so wrongly. Apparently the red curve mean is positioned to the right of the blue control curve (value reported in caption), although the histogram looks higher on the left. I don´t have a proper justification for this. what do you think? both chatGPT and gemini fail to interpretate what is wrong with the analysis, so our job is still safe.",user_cb3f0086,54,0.95,23,2026-01-13 09:24:54,https://i.redd.it/cydd3klvf5dg1.png,https://www.reddit.com/r/datascience/comments/1qbx8bd/there_are_several_odd_things_in_this_analysis/,False,Analysis,i.redd.it,datascience,False,False
1qbtoyf,Looking for advice on switching domain/industry,"Hello everyone, I am currently a data scientist with 4.5 yoe and work in aerospace/defense in the DC area. I am about to finish the Georgia tech OMSCS program and am going to start looking for new positions relatively soon. I would like to find something outside of defense. However, given how often I see domain and industry knowledge heralded as this all important thing in posts here, I am under the impression that switching to a different industry or domain in DS is quite difficult. This is likely especially true in my case as going from government/contracting to the private sector is likely harder than the other way around. As far as technical skills, I feel pretty confident in the standard python DS stack (numpy/pandas/matplotlib) as well as some of the ML/DL libraries (XGBoost/PyTorch) as I use them at work regularly. I also use SQL and other certain other things that come up on job ads such as git, Linux, and Apache Airflow. The main technical gap I feel that I have is that I don’t use cloud at all for my job but I am currently studying for one of the AWS certification exams so that should hopefully help at least a little bit. There are a couple other things here and there I should probably brush up on such as Spark and Docker/kubernetes but I do have basic knowledge of those things. I would be grateful if anyone here had any tips on what I can do to improve my chances at positions in different industries. The only thing I could think of off the bat is to think of an industry or domain I am interested in and try to do a project related to that industry so I could put it on my resume. I would probably prefer something in banking/finance or economics but am open to other areas.",user_f85580d0,34,0.9,31,2026-01-13 07:05:52,https://www.reddit.com/r/datascience/comments/1qbtoyf/looking_for_advice_on_switching_domainindustry/,https://www.reddit.com/r/datascience/comments/1qbtoyf/looking_for_advice_on_switching_domainindustry/,True,Career | US,self.datascience,datascience,False,False
1qbhvqw,Nearly 450K Tech Job Posts But Still No Hires—Here’s Why It’s Happening,,user_b85d427c,244,0.96,43,2026-01-12 20:31:27,https://www.interviewquery.com/p/worker-productivity-up-hiring-stagnant-2026,https://www.reddit.com/r/datascience/comments/1qbhvqw/nearly_450k_tech_job_posts_but_still_no/,False,Discussion,interviewquery.com,datascience,False,False
1qc6mv2,Undergrad Data Science dissertation ideas [Quantitative Research],"Hi everyone, I’m a undergraduate Data Science student in the UK starting my dissertation and I’m looking for ideas that would be relevant to quantitative research, which is the field I’d like to move into after graduating I’m not coming in with a fixed idea yet I’m mainly interested in data science / ML problems that are realistic at undergrad level to do over a course of a few months and aligned with how quantitative research is actually done I’ve worked on ML and neural networks as part of my degree projects and previous internship, but I’m still early in understanding how these ideas are applied in quant research, so I’m very open to suggestions. I’d really appreciate: * examples of dissertation topics that would be viewed positively for quant research roles * areas that are commonly misunderstood or overdone * pointers to papers or directions worth exploring Thanks in advance! any advice would be really helpful.",user_fef24868,0,0.36,10,2026-01-13 15:11:10,https://www.reddit.com/r/datascience/comments/1qc6mv2/undergrad_data_science_dissertation_ideas/,https://www.reddit.com/r/datascience/comments/1qc6mv2/undergrad_data_science_dissertation_ideas/,True,Projects,self.datascience,datascience,False,False
1qb5g4v,Optimization of GBDT training complexity to O(n) for continual learning,"We’ve spent the last few months working on **PerpetualBooster**, an open-source gradient boosting algorithm designed to handle tabular data more efficiently than standard GBDT frameworks: [https://github.com/perpetual-ml/perpetual](https://github.com/perpetual-ml/perpetual) The main focus was solving the retraining bottleneck. By optimizing for **continual learning**, we’ve reduced training complexity from the typical O(n\^2) to O(n). In our current benchmarks, it’s outperforming AutoGluon on several standard tabular datasets: [https://github.com/perpetual-ml/perpetual?tab=readme-ov-file#perpetualbooster-vs-autogluon](https://github.com/perpetual-ml/perpetual?tab=readme-ov-file#perpetualbooster-vs-autogluon) We recently launched a managed environment to make this easier to operationalize: * **Serverless Inference:** Endpoints that scale to zero (pay-per-execution). * **Integrated Monitoring:** Automated data and concept drift detection that can natively trigger continual learning tasks. * **Marimo Integration:** We use Marimo as the IDE for a more reproducible, reactive notebook experience compared to standard Jupyter. * **Data Ops:** Built-in quality checks and 14+ native connectors to external sources. What’s next: We are currently working on expanding the platform to support LLM workloads. We’re in the process of adding NVIDIA Blackwell GPU support to the infrastructure for those needing high-compute training and inference for larger models. If you’re working with tabular data and want to test the O(n) training or the serverless deployment, you can check it out here:[https://app.perpetual-ml.com/signup](https://app.perpetual-ml.com/signup) I'm happy to discuss the architecture of PerpetualBooster or the drift detection logic if anyone has questions.",user_8593d7f2,7,0.82,5,2026-01-12 11:59:49,https://www.reddit.com/r/datascience/comments/1qb5g4v/optimization_of_gbdt_training_complexity_to_on/,https://www.reddit.com/r/datascience/comments/1qb5g4v/optimization_of_gbdt_training_complexity_to_on/,True,Tools,self.datascience,datascience,False,False
1qalzjc,"Weekly Entering & Transitioning - Thread 12 Jan, 2026 - 19 Jan, 2026","Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include: * Learning resources (e.g. books, tutorials, videos) * Traditional education (e.g. schools, degrees, electives) * Alternative education (e.g. online courses, bootcamps) * Job search questions (e.g. resumes, applying, career prospects) * Elementary questions (e.g. where to start, what next) While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",user_ac31a110,13,1.0,5,2026-01-11 21:01:38,https://www.reddit.com/r/datascience/comments/1qalzjc/weekly_entering_transitioning_thread_12_jan_2026/,https://www.reddit.com/r/datascience/comments/1qalzjc/weekly_entering_transitioning_thread_12_jan_2026/,True,,self.datascience,datascience,False,False
1q85xuw,What’s your 2026 data science coding stack + AI tools workflow?,"Last year, there was a thread on the same question but for [2025](https://www.reddit.com/r/datascience/comments/1k26kp3/whats_your_2025_data_science_coding_stack_ai/) * At the time, my workflow was scattered across many tools, and AI was helping to speed up a few things. However, since then, Opus 4.5 was launched, and I have almost exclusively been using Cursor in combination with Claude Code. * I've been focusing a lot on prompts, skills, subagents, MCP, and slash commands to speed up and improve workflows [similar to this](https://www.youtube.com/watch?v=X2ciJedw2vU). * Recently, I have been experimenting with [Claudish](https://github.com/MadAppGang/claudish), which allows for plugging any model into Claude Code. Also, I have been transitioning to use [Marimo](https://github.com/marimo-team/marimo) instead of Jupyter Notebooks. I've roughly tripled my productivity since October, maybe even 5x in some workflows. I'm curious to know what has changed for you since last year.",user_e5c336b3,82,0.84,67,2026-01-09 03:32:56,https://www.reddit.com/r/datascience/comments/1q85xuw/whats_your_2026_data_science_coding_stack_ai/,https://www.reddit.com/r/datascience/comments/1q85xuw/whats_your_2026_data_science_coding_stack_ai/,True,Tools,self.datascience,datascience,False,False
1q7eznu,Data integreity questions,,user_b65b9798,2,0.57,6,2026-01-08 07:38:53,/r/learnSQL/comments/1q7eyyq/data_integreity_questions/,https://www.reddit.com/r/datascience/comments/1q7eznu/data_integreity_questions/,False,Education,,datascience,False,False
1q6k1xl,53% of Tech Jobs Now Demand AI Skills; Generalists Are Getting Left Behind,"Hiring data shows companies increasingly favor specialized, AI-adjacent skills over broad generalist roles. Do you think this is applicable to data science roles?",user_e6f6eb17,72,0.76,53,2026-01-07 08:31:18,https://www.interviewquery.com/p/ai-skills-tech-jobs-generalists-left-behind,https://www.reddit.com/r/datascience/comments/1q6k1xl/53_of_tech_jobs_now_demand_ai_skills_generalists/,False,Discussion,interviewquery.com,datascience,False,False
1q64yb5,Improvable AI - A Breakdown of Graph Based Agents,"For the last few years my job has centered around making humans like the output of LLMs. The main problem is that, in the applications I work on, the humans tend to know a lot more than I do. Sometimes the AI model outputs great stuff, sometimes it outputs horrible stuff. I can't tell the difference, but the users (who are subject matter experts) can. I have a lot of opinions about testing and how it should be done, which I've written about extensively (mostly in a RAG context) if you're curious. \- [Vector Database Accuracy at Scale](https://www.eyelevel.ai/post/do-vector-databases-lose-accuracy-at-scale?utm_source=x&utm_medium=social&utm_id=santiago-rag2) \- [Testing Document Contextualized AI](https://iaee.substack.com/p/testing-document-contextualized-ai) \- [RAG evaluation](https://www.eyelevel.ai/post/how-to-test-rag-and-agents-in-the-real-world) For the sake of this discussion, let's take for granted that you know what the actual problem is in your AI app (which is not trivial). There's another problem which we'll concern ourselves in this particular post. If you know what's wrong with your AI system, how do you make it better? That's the point, to discuss making maintainable AI systems. I've been [bullish about AI agents for a while now](https://iaee.substack.com/p/the-future-is-agentic-5c644f6b8f5b), and it seems like the industry has come around to the idea. they can break down problems into sub-problems, ponder those sub-problems, and use external tooling to help them come up with answers. Most developers are familiar with the approach and understand its power, but I think many are under-appreciative of their drawbacks from a maintainability prospective. When people discuss ""AI Agents"", I find they're typically referring to what I like to call an ""Unconstrained Agent"". When working with an unconstrained agent, you give it a query and some tools, and let it have at it. The agent thinks about your query, uses a tool, makes an observation on that tools output, thinks about the query some more, uses another tool, etc. This happens on repeat until the agent is done answering your question, at which point it outputs an answer. This was proposed in the landmark paper ""ReAct: Synergizing Reasoning and Acting in Language Models"" which I discuss at length in [this article](https://iaee.substack.com/p/llm-agents-intuitively-and-exhaustively-explained-8905858e18e2?utm_source=publication-search). This is great, especially for open ended systems that answer open ended questions like ChatGPT or Google (I think this is more-or-less what's happening when ChatGPT ""thinks"" about your question, though It also probably does some reasoning model trickery, [a-la deepseek](https://iaee.substack.com/p/deepseek-r1-intuitively-and-exhaustively?utm_source=publication-search)). This unconstrained approach isn't so great, I've found, when you build an AI agent to do something specific and complicated. If you have some logical process that requires a list of steps and the agent messes up on step 7, it's hard to change the agent so it will be right on step 7, without messing up its performance on steps 1-6. It's hard because, the way you define these agents, you tell it how to behave, then it's up to the agent to progress through the steps on its own. Any time you modify the logic, you modify all steps, not just the one you want to improve. I've heard people use ""whack-a-mole"" when referring to the process of improving agents. This is a big reason why. I call graph based agents ""constrained agents"", in contrast to the ""unconstrained agents"" we discussed previously. Constrained agents allow you to control the logical flow of the agent and its decision making process. You control each step and each decision independently, meaning you can add steps to the process as necessary. [Imagine you developed a graph which used an LLM to introduce itself to the user, then progress to general questions around qualification \(1\). You might decide this is too simple, and opt to check the user's response to ensure that it does contain a name before progressing \(2\). Unexpectedly, maybe some of your users don’t provide their full name after you deploy this system to production. To solve this problem you might add a variety of checks around if the name is a full name, or if the user insists that the name they provided is their full name \(3\).](https://preview.redd.it/3ini75u95tbg1.png?width=700&format=png&auto=webp&s=2f7960052ed2df34afec0ee969d337b45e9a0a97) [image source](https://iaee.substack.com/p/langgraph-intuitively-and-exhaustively?utm_source=publication-search) This allows you to much more granularly control the agent at each individual step, adding additional granularity, specificity, edge cases, etc. This system is much, much more maintainable than unconstrained agents. I [talked](https://www.youtube.com/watch?v=N59Z7uJ8DDA&t=444s) with some folks at [arize](https://arize.com/) a while back, a company focused on AI observability. Based on their experience at the time of the conversation, the vast amount of actually functional agentic implementations in real products tend to be of the constrained, rather than the unconstrained variety. I think it's worth noting, these approaches aren't mutually exclusive. You can run a ReAct style agent within a node within a graph based agent, allowing you to allow the agent to function organically within the bounds of a subset of the larger problem. That's why, in my workflow, graph based agents are the first step in building any agentic AI system. They're more modular, more controllable, more flexible, and more explicit.",user_d4a985de,18,0.83,9,2026-01-06 19:51:12,https://www.reddit.com/r/datascience/comments/1q64yb5/improvable_ai_a_breakdown_of_graph_based_agents/,https://www.reddit.com/r/datascience/comments/1q64yb5/improvable_ai_a_breakdown_of_graph_based_agents/,True,Discussion,self.datascience,datascience,False,False
1q5kb9b,Ds Masters never found job in DS,"Hello all, I got my Data Science Masters in May 2024, I went to school part time while working in cybersecurity. I tried getting a job in data science after graduation but couldn't even get an interview I continued on with my cybersecurity job which I absolutely hate. DS was supposed to be my way out but I feel my degree did little to prepare me for the career field especially after all the layoffs, recruiters seem to hate career changers and cant look past my previous experience in a different field. I want to work in DS but my skills have atrophied badly and I already feel out of date. I am not sure what to do I hate my current field, cybersecurity is awful, and feel I just wasted my life getting my DS masters, should I take a boot camp would that make me look better to recruiters should I get a second DS masters or an AI specific masters so I can get internships I am at a complete loss how to proceed could use some constructive advice.",user_f964884f,134,0.94,144,2026-01-06 06:38:22,https://www.reddit.com/r/datascience/comments/1q5kb9b/ds_masters_never_found_job_in_ds/,https://www.reddit.com/r/datascience/comments/1q5kb9b/ds_masters_never_found_job_in_ds/,True,Career | US,self.datascience,datascience,False,False
1q4li4h,I’m doing a free webinar on my experience building and deploying a talk-to-your-data Slackbot at my company,"I gave this talk at an event called DataFest last November, and it did really well, so I thought it might be useful to share it more broadly. That session wasn’t recorded, so I’m running it again as a live webinar. I’m a senior data scientist at Nextory, and the talk is based on work I’ve been doing over the last year integrating AI into day-to-day data science workflows. I’ll walk through the architecture behind a talk-to-your-data Slackbot we use in production, and focus on things that matter once you move past demos. Semantic models, guardrails, routing logic, UX, and adoption challenges. If you’re a data scientist curious about agentic analytics and what it actually takes to run these systems in production, this might be relevant. Sharing in case it’s helpful. You can register here: [https://luma.com/4f8lqzsp](https://luma.com/4f8lqzsp)",user_fddb3a50,13,0.78,17,2026-01-05 05:20:33,https://www.reddit.com/r/datascience/comments/1q4li4h/im_doing_a_free_webinar_on_my_experience_building/,https://www.reddit.com/r/datascience/comments/1q4li4h/im_doing_a_free_webinar_on_my_experience_building/,True,Projects,self.datascience,datascience,False,False
1q4iro4,Distributed LightGBM on Azure SynapseML: scaling limits and alternatives?,"I’m looking for advice on running LightGBM in true multi-node / distributed mode on Azure, given some concrete architectural constraints. Current setup: - Pipeline is implemented in Azure Databricks with Spark - Feature engineering and orchestration are done in PySpark - Model training uses LightGBM via SynapseML - Training runs are batch, not streaming Key constraint / problem: - Current setup runs LightGBM on a single node (large VM) Although the Spark cluster can scale, LightGBM itself remains single-node, which appears to be a limitation of SynapseML at the moment (there seems to be an open issue for multi-node support). What I’m trying to understand: Given an existing Databricks + Spark pipeline, what are viable ways to run LightGBM distributed across multiple nodes on Azure today? Native LightGBM distributed mode (MPI / socket-based) on Databricks? Any practical workarounds beyond SynapseML? How do people approach this in Azure Machine Learning? Custom training jobs with MPI? Pros/cons compared to staying in Databricks? Is AKS a realistic option for distributed LightGBM in production, or does the operational overhead outweigh the benefits? From experience: Where do scaling limits usually appear (networking, memory, coordination)? At what point does distributed LightGBM stop being worth it compared to single-node + smarter parallelization? I’m specifically interested in experience-based answers: what you’ve tried on Azure, what scaled (or didn’t), and what you would choose again under similar constraints.",user_8d5763e6,14,0.95,5,2026-01-05 02:59:08,https://www.reddit.com/r/datascience/comments/1q4iro4/distributed_lightgbm_on_azure_synapseml_scaling/,https://www.reddit.com/r/datascience/comments/1q4iro4/distributed_lightgbm_on_azure_synapseml_scaling/,True,ML,self.datascience,datascience,False,False
1q4ps8r,Normalization training questions,,user_b65b9798,3,0.64,6,2026-01-05 08:09:57,/r/learnSQL/comments/1q4nboe/normalization_training_questions/,https://www.reddit.com/r/datascience/comments/1q4ps8r/normalization_training_questions/,False,Education,,datascience,False,False
1q47c7e,Tips for standing out in this market?,"Hey all, I just finished my master's in data science last month and I want to see what it takes to break into a mid level DS role. I haven't had a chance to sterilize my resume yet (2 young kids and a lot of recent travel), but here's a breakdown: - 13 years of work experience (10 in logistics, but transferred to analytics 3-4 years ago. I've worked in the US. Germany and Qatar). - Earned my MBA in 2017 - Just finished my MSc in Data science - Proficient in RStudio, Python and SQL (also have dashboarding experience with PowerBI and RShiny). - Building my GitHub with 3-5 projects demonstrating ML, advanced SQL, etc. If needed, I can update with a sanitized version of my resume. I should also note that in my current role, I've applied ML, text mining (to include NLTK) and analyses on numerous datasets for both reporting and dashboarding. I'm also currently working on a SQL project to get data currently stored into Excel sheets over to a database and normalized (probably 2NF when it's all said and done). Any tips are much appreciated.",user_1d3c7e62,50,0.97,34,2026-01-04 16:58:40,https://www.reddit.com/r/datascience/comments/1q47c7e/tips_for_standing_out_in_this_market/,https://www.reddit.com/r/datascience/comments/1q47c7e/tips_for_standing_out_in_this_market/,True,Career | US,self.datascience,datascience,False,False
1q47let,Learning Python by doing projects: What does that even mean?,"I’m learning Python and considering this approach: choose a real dataset, frame a question I want to answer, then work toward it step by step by breaking it into small tasks and researching each step as needed. For those of you who are already comfortable with Python, is this an effective way to build fluency, or will I be drowning in confusion and you recommend something better?",user_56d750c9,43,0.84,41,2026-01-04 17:09:32,https://www.reddit.com/r/datascience/comments/1q47let/learning_python_by_doing_projects_what_does_that/,https://www.reddit.com/r/datascience/comments/1q47let/learning_python_by_doing_projects_what_does_that/,True,Discussion,self.datascience,datascience,False,False
1q3txz8,Which class should I take to help me get a job?,I'm in my final semester of my MS program and am deciding between Spatial and Non-Parametric statistics. I feel like spatial is less common but would make me stand out more for jobs specifically looking for spatial whereas NP would be more common but less flashy. Any advice is welcome!,deleted_user,22,0.76,15,2026-01-04 08:17:08,https://www.reddit.com/r/datascience/comments/1q3txz8/which_class_should_i_take_to_help_me_get_a_job/,https://www.reddit.com/r/datascience/comments/1q3txz8/which_class_should_i_take_to_help_me_get_a_job/,True,Career | US,self.datascience,datascience,False,False
1q4co2e,"Weekly Entering & Transitioning - Thread 05 Jan, 2026 - 12 Jan, 2026","Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include: * Learning resources (e.g. books, tutorials, videos) * Traditional education (e.g. schools, degrees, electives) * Alternative education (e.g. online courses, bootcamps) * Job search questions (e.g. resumes, applying, career prospects) * Elementary questions (e.g. where to start, what next) While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",user_ac31a110,2,0.75,11,2026-01-04 21:01:38,https://www.reddit.com/r/datascience/comments/1q4co2e/weekly_entering_transitioning_thread_05_jan_2026/,https://www.reddit.com/r/datascience/comments/1q4co2e/weekly_entering_transitioning_thread_05_jan_2026/,True,,self.datascience,datascience,False,False
1q39r6f,"Is Python needed if I know R enough to wrangle, model and visualise data?","I hope I don't trigger anyone with this question. I apologise in advance if it comes off as naïve. I was exposed to R before python, so in my head, I struggle with the syntax of Python much more than my beloved tidyverse. Do most employers insist that you know python even if you've got R on your belt, for data science roles?",user_56d750c9,60,0.79,105,2026-01-03 15:32:50,https://www.reddit.com/r/datascience/comments/1q39r6f/is_python_needed_if_i_know_r_enough_to_wrangle/,https://www.reddit.com/r/datascience/comments/1q39r6f/is_python_needed_if_i_know_r_enough_to_wrangle/,True,Discussion,self.datascience,datascience,False,False
1q2uqtv,From radar signal processing to data science,"Hi everyone, I have a Masters in Robotics & AI and 2 years of experience in radar signal processing on embedded devices. My work involves implementing C++ signal processing algorithms, leveraging multi-core and hardware acceleration, analyzing radar datasets, and some exposure to ML algorithms. I’m trying to figure out the best path to break into data science roles. I’m debating between: Leveraging my current skills to transition directly into data science, emphasizing my experience with signal analysis, ML exposure, and dataset handling. Doing research with a professor to strengthen my ML/data experience and possibly get publications. Pursuing a dedicated Master’s in Data Science to formally gain data engineering, Python, and ML skills. My questions are: How much does experience with embedded/real-time signal processing matter for typical data science roles? Can I realistically position myself for data science jobs by building projects with Python/PyTorch and data analysis, without a second degree? Would research experience (e.g., with a professor) make a stronger impact than self-directed projects? I’d love advice on what recruiters look for in candidates with technical backgrounds like mine, and the most efficient path to data science. Thanks in advance!",user_26333b14,23,0.96,9,2026-01-03 05:34:09,https://www.reddit.com/r/datascience/comments/1q2uqtv/from_radar_signal_processing_to_data_science/,https://www.reddit.com/r/datascience/comments/1q2uqtv/from_radar_signal_processing_to_data_science/,True,Career | US,self.datascience,datascience,False,False
1q2s48r,"sharepoint-to-text: Pure Python text extraction from Office files (including legacy .doc/.xls/.ppt) - no LibreOffice, no Java, no subprocess calls","Built this because I needed to extract text from enterprise SharePoint dumps for RAG pipelines, and the existing options were painful: * **LibreOffice-based**: 1GB+ container images, headless X11 setup * **Apache Tika**: Java runtime, 500MB+ footprint * **subprocess wrappers**: security concerns, platform issues `sharepoint-to-text` parses Office binary formats (OLE2) and OOXML directly in Python. Zero system dependencies. **What it handles:** * Legacy Office: `.doc`, `.xls`, `.ppt` * Modern Office: `.docx`, `.xlsx`, `.pptx` * OpenDocument: `.odt`, `.ods`, `.odp` * PDF, Email (`.eml`, `.msg`, `.mbox`), HTML, plain text formats **Basic usage:** python import sharepoint2text result = next(sharepoint2text.read_file(""document.docx"")) text = result.get_full_text() # Or iterate by page/slide/sheet for RAG chunking for unit in result.iterate_units(): chunk = unit.get_text() Also extracts tables, images, and metadata. Has a CLI. JSON serialization built in. **Install:** `uv add sharepoint-to-text` or `pip install sharepoint-to-text` **Trade-offs to be aware of:** * No OCR - scanned PDFs return empty text * Password-protected files are rejected * Word docs don't have page boundaries (that's a format limitation, not ours) GitHub: [https://github.com/Horsmann/sharepoint-to-text](https://github.com/Horsmann/sharepoint-to-text) Happy to answer questions or take feedback.",user_52e5d8c9,14,0.71,15,2026-01-03 03:12:20,https://www.reddit.com/r/datascience/comments/1q2s48r/sharepointtotext_pure_python_text_extraction_from/,https://www.reddit.com/r/datascience/comments/1q2s48r/sharepointtotext_pure_python_text_extraction_from/,True,Projects,self.datascience,datascience,False,False
1q36dkr,Ideas for a Undergrad Data Science dissertation - algorithmic trading,"Hi everyone, I’m a 3rd-year undergraduate Data Science student starting my final semester dissertation, and I’m looking at ideas around neural networks applied to algorithmic trading I already trade manually (mainly FX/commodities), and I’m interested in building a trading system (mainly for research) where the core contribution is the machine learning methodology, not just PnL (I don't believe I'm ready for something PnL-focused yet) Some directions I’m considering: * Deep learning models for financial time series (LSTM / CNN / Transformers) * Reinforcement learning for trading * Neural networks for regime detection or strategy switching The goal would be to design something academically solid, with strong evaluation and methodology, that could be deployed live in a small size, but is primarily assessed as research I’d really appreciate: * Dissertation-worthy research questions in this space * Things to avoid * Suggestions on model choices, or framing that examiners tend to like Thanks in advance, any advice or references would be very helpful",user_fef24868,3,0.55,24,2026-01-03 13:15:32,https://www.reddit.com/r/datascience/comments/1q36dkr/ideas_for_a_undergrad_data_science_dissertation/,https://www.reddit.com/r/datascience/comments/1q36dkr/ideas_for_a_undergrad_data_science_dissertation/,True,Projects,self.datascience,datascience,False,False
1q22kk7,How different are Data Scientists vs Senior Data Scientists technical interviews?,"Hello everyone! I am preparing for a technical interview for a Senior DS role and wanted to hear from those that have gone through the process, is it much different? Do you prepare in the same way? Leet code and general ML and experimentation knowledge?",user_c7e1342a,63,0.93,38,2026-01-02 08:08:55,https://www.reddit.com/r/datascience/comments/1q22kk7/how_different_are_data_scientists_vs_senior_data/,https://www.reddit.com/r/datascience/comments/1q22kk7/how_different_are_data_scientists_vs_senior_data/,True,Discussion,self.datascience,datascience,False,False
1q0vtzx,[Official] 2025 End of Year Salary Sharing thread,"This is the official thread for sharing your current salaries (or recent offers). See [last year's Salary Sharing thread here](https://www.reddit.com/r/datascience/comments/1ia175l/official_2024_end_of_year_salary_sharing_thread/). Please only post salaries/offers if you're including hard numbers, but feel free to use a throwaway account if you're concerned about anonymity. You can also generalize some of your answers (e.g. ""Large biotech company""), or add fields if you feel something is particularly relevant. **Title:** * **Tenure length:** * **Location:** * **$Remote:** * **Salary:** * **Company/Industry:** * **Education:** * **Prior Experience:** * **$Internship** * **$Coop** * **Relocation/Signing Bonus:** * **Stock and/or recurring bonuses:** * **Total comp:** Note that while the primary purpose of these threads is obviously to share compensation info, discussion is also encouraged.",user_3aeed02d,115,0.98,142,2025-12-31 20:38:20,https://www.reddit.com/r/datascience/comments/1q0vtzx/official_2025_end_of_year_salary_sharing_thread/,https://www.reddit.com/r/datascience/comments/1q0vtzx/official_2025_end_of_year_salary_sharing_thread/,True,,self.datascience,datascience,False,False
1q0uu3t,Preparing for Classical ML Interviews - What Mathematical Proofs Should I Practice?,"Hey everyone, I'm preparing for classical ML interviews and I have been hearing that some companies ask candidates to prove mathematical concepts. I want to be ready for these questions. For example, I have heard questions like: * Prove that MSE loss is non-convex for logistic regression * Derive why the mean (not median) is used as the centroid in k means What are the most common mathematical proofs/derivations you have encountered or think are essential to know?",user_2f3d0bc4,49,0.84,17,2025-12-31 19:40:27,https://www.reddit.com/r/datascience/comments/1q0uu3t/preparing_for_classical_ml_interviews_what/,https://www.reddit.com/r/datascience/comments/1q0uu3t/preparing_for_classical_ml_interviews_what/,True,Discussion,self.datascience,datascience,False,False
1q0a3xb,Feature selection strategies for multivariate time series forecasting,,user_722a94d8,11,0.88,3,2025-12-31 02:40:46,/r/MLQuestions/comments/1q0a3lj/feature_selection_strategies_for_multivariate/,https://www.reddit.com/r/datascience/comments/1q0a3xb/feature_selection_strategies_for_multivariate/,False,ML,,datascience,False,False
1q04gab,Aggregations and Grouping - practice opportunity,,user_b65b9798,2,0.58,0,2025-12-30 21:02:05,/r/learnSQL/comments/1pznpk6/aggregations_and_grouping_practice_opportunity/,https://www.reddit.com/r/datascience/comments/1q04gab/aggregations_and_grouping_practice_opportunity/,False,Education,,datascience,False,False
1pzwuw9,Is it worth making side projects to earn money as an LLM engineer instead of studying?,,user_ca1c3470,0,0.45,12,2025-12-30 15:13:50,/r/LLMDevs/comments/1pzwt5k/is_it_worth_making_side_projects_to_earn_money_as/,https://www.reddit.com/r/datascience/comments/1pzwuw9/is_it_worth_making_side_projects_to_earn_money_as/,False,Discussion,,datascience,False,False
1pyzmwh,Updates: DataSetIQ Python client for economic datasets now supports one-line feature engineering,"With this update now new helpers available in the DataSetIQ Python client to go from raw macro data to model-ready features in one call New: \- add\_features: lags, rolling stats, MoM/YoY %, z-scores \- get\_ml\_ready: align multiple series, impute gaps, add per-series features \- get\_insight: quick summary (latest, MoM, YoY, volatility, trend) \- search(..., mode=""semantic"") where supported Example: import datasetiq as iq iq.set_api_key(""diq_your_key"") df = iq.get_ml_ready( [""fred-cpi"", ""fred-gdp""], align=""inner"", impute=""ffill+median"", features=""default"", lags=[1,3,12], windows=[3,12], ) print(df.tail()) pip install datasetiq Tell us what other transforms you’d want next.",user_ee7a7c00,20,0.88,5,2025-12-29 14:02:52,https://github.com/DataSetIQ/datasetiq-python,https://www.reddit.com/r/datascience/comments/1pyzmwh/updates_datasetiq_python_client_for_economic/,False,Coding,github.com,datascience,False,False
1pye3el,What skills did you learn on the job this past year?,"What skills did you actually learn on the job this past year? Not from self-study or online courses, but through live hands-on training or genuinely challenging assignments. My hunch is that learning opportunities have declined recently, with many companies leaning on “you own your career” narratives or treating a Udemy subscription as equivalent to employee training. Curious to hear: what did you learn because of your job, not just alongside it?",user_48d03593,93,0.94,78,2025-12-28 21:44:47,https://www.reddit.com/r/datascience/comments/1pye3el/what_skills_did_you_learn_on_the_job_this_past/,https://www.reddit.com/r/datascience/comments/1pye3el/what_skills_did_you_learn_on_the_job_this_past/,True,Discussion,self.datascience,datascience,False,False
1pyct4y,Modern Git-aware File Tree and global search/replace in Jupyter,"I used jupyter lab for years, but the file browser menu is lack of some important features like tree view/aware of git status; I tried some of the old 3rd extensions but none of them fit those modern demands which most of editors/IDE have(like vscode) so i created this extension, that provides some important features that jupyter lab lack of: **1. File explorer sidebar with Git status colors & icons** https://preview.redd.it/og04weg6o2ag1.png?width=1194&format=png&auto=webp&s=864e7db14d8328425c348a253c9dc7061142c46a Besides a tree view, It can mark files in gitignore as gray, mark un-commited modified files as yellow, additions as green, deletion as red. **2. Global search/replace** Global search and replace tool that works with all file types(including ipynb), it can also automatically skip ignore files like venv or node modules. https://preview.redd.it/2uzvph8zn2ag1.png?width=750&format=png&auto=webp&s=f4b81ab1f6e73ace2f3eca40af2eee6d65f720f9 **How to use?** pip install runcell Looking for feedback and suggestions if this is useful for you :)",user_a907813a,16,0.87,7,2025-12-28 20:40:47,https://www.reddit.com/r/datascience/comments/1pyct4y/modern_gitaware_file_tree_and_global/,https://www.reddit.com/r/datascience/comments/1pyct4y/modern_gitaware_file_tree_and_global/,True,Tools,self.datascience,datascience,False,False
1pyd8i1,"Weekly Entering & Transitioning - Thread 29 Dec, 2025 - 05 Jan, 2026","Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include: * Learning resources (e.g. books, tutorials, videos) * Traditional education (e.g. schools, degrees, electives) * Alternative education (e.g. online courses, bootcamps) * Job search questions (e.g. resumes, applying, career prospects) * Elementary questions (e.g. where to start, what next) While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",user_ac31a110,5,0.86,4,2025-12-28 21:01:37,https://www.reddit.com/r/datascience/comments/1pyd8i1/weekly_entering_transitioning_thread_29_dec_2025/,https://www.reddit.com/r/datascience/comments/1pyd8i1/weekly_entering_transitioning_thread_29_dec_2025/,True,,self.datascience,datascience,False,False
1pwsmg9,Are some people really as busy as they really look?,"There is someone I have to work together and we both work remotely. I'm a data scientist and he is a product manager. This person appears to be always busy. His Slack status is either on a huddle or on a meeting. He is probably having more than 10 meetings a day lol. When I want to talk about something with him, he asks me to set a meeting on calendar at weird times like 2 days later, but we can actually solve the problem right at that time in couple minutes. Normally I don't give a shit, but I don't like his attitude recently. He says stuff like ""I'm focused"", ""Don't be distractive"" bla bla. He also said that ""You are not working at all"" because I'm managing my time in a more flexible way. I think he will try to get rid of me soon. I have no idea how to deal with this. Does anyone had to work with this type of person before?",user_2b5f59f2,85,0.83,47,2025-12-27 00:13:30,https://www.reddit.com/r/datascience/comments/1pwsmg9/are_some_people_really_as_busy_as_they_really_look/,https://www.reddit.com/r/datascience/comments/1pwsmg9/are_some_people_really_as_busy_as_they_really_look/,True,Discussion,self.datascience,datascience,False,False
1pwysz9,PhD microbiologist pivoting to GCC data analytics. Is a master’s needed or portfolio and projects sufficient?,"I am finishing a wet-lab microbiology PhD. Over the last year I realised that I prefer data work. I use R, Excel and command line regularly and want to move toward analytics roles in industry rather than academic biology. My target is business-focused or operational analytics rather than bioinformatics. Long term I am looking at GCC markets, so I expect competition with candidates who already come from consulting or commercial backgrounds. My question is: Should I spend time and money on a taught master’s in data/analytics/, or build a portfolio, learn SQL and Power BI, and go straight for analyst roles without any ""data analyst"" experience? I feel like i'm in a difficult spot either way... I want to hear from people who actually switched from research into analytics or consulting. What convinced your employers: \- another degree \- certifications \- portfolio projects \- internships \- networking and referrals Of course a mix of them would be ideal. I get that. If you need context to give a useful answer, say what you need and I’ll add it. Or we can talk privately if you'd like. Thanks in advance :)",user_56d750c9,14,0.75,25,2025-12-27 06:15:12,https://www.reddit.com/r/datascience/comments/1pwysz9/phd_microbiologist_pivoting_to_gcc_data_analytics/,https://www.reddit.com/r/datascience/comments/1pwysz9/phd_microbiologist_pivoting_to_gcc_data_analytics/,True,Discussion,self.datascience,datascience,False,False
1puabxx,How much of your job is actually “selling” your work?,"What % of your role is convincing stakeholders to act on your recommendations? Do you like that part, and how did you learn to do it well? Or are you in an environment where good analysis & models naturally leads to implementation?",user_48d03593,92,0.97,34,2025-12-23 16:59:54,https://www.reddit.com/r/datascience/comments/1puabxx/how_much_of_your_job_is_actually_selling_your_work/,https://www.reddit.com/r/datascience/comments/1puabxx/how_much_of_your_job_is_actually_selling_your_work/,True,Discussion,self.datascience,datascience,False,False
1pu71am,Chemist Turned Data Scientist: Looking for Career Development Advice in Hybrid Roles,"Hi everyone, I'm looking for advice on career development and would appreciate input from different perspectives - data professionals, managers, and chemist or folks from adjacent fields (if any frequent this subreddit). **About me:** - I'm a trained chemist and have been working as a data scientist for three years - my current role is a hybrid one: I generate business value from data through ad-hoc analyses, data sourcing, workflow optimisation and consulting. - I typically work on chemical process optimisation but also on numeric problems in python, and recently started exploring LLMs (which has only a limited application to our work). - I also manage projects and implement available tools that help teams work more efficiently. **What I enjoy:** - working with people to solve challenging problems - enabling others by providing better tools and processes - stay technical enough to understand and contribute, but not going too deep into code or algorithms /every day/. **Current observations:** - the chemical industry is relatively conservative with lower digital maturity compared to other sectors. Certifications tend to be valued more than in pure data science environments (at least in Germany). - my data science work is often basic - ML has only come up once in three years (in a very minor capacity) **Areas I'm considering for development:** - Numeric problem-solving - Operations Research (I've started to learn but no certification yet) - Business intelligence / Analytical Operation (e.g. building better data pipelines to enable my coworkers; Snowflake want necessary yet, plus silos are a real challenge) - as a new area: possibly Supply Chain, as it seems relevant to my experience in manufacturing, chemical processes and quality support. **Questions for you:** 1) What certifications or skills would you recommend for someone in a chemistry + data hybrid role? 2) are there other areas in chemical or pharmaceutical companies where such a hybrid profile could add value? 3) how can I best identify roads or projects with strong overlap between chemistry and data science? 4) from a management perspective, what qualities or experiences should I build now to prepare for leadership in this space? 5) any general advice on networking or positioning myself for the next step? I already hold a PhD, so I'm not looking for another degree - but I'm open to targeted certifications or practical learning paths. Thanks in advance for your insights! (Also posted in r/chempros for additional perspectives)",user_28f062cc,42,0.93,16,2025-12-23 14:28:20,https://www.reddit.com/r/datascience/comments/1pu71am/chemist_turned_data_scientist_looking_for_career/,https://www.reddit.com/r/datascience/comments/1pu71am/chemist_turned_data_scientist_looking_for_career/,True,Career | Europe,self.datascience,datascience,False,False
1pu8h8d,"Resources for learning Neural Nets, Autoencoders (VAEs)","Can someone point me to resources on learning Neural Nets and Variational Autoencoders? My past work has mostly been the “standard” scikit-learn suite of modeling. But now I’m placed in a project at work that is a HUGE learning experience for me. We basically have financial data and we’re trying to use it in a semi-unsupervised way. We’re not entirely sure what the outcome should be, but we’re trying to use VAEs to extract relationships with the data. Conceptually I understand neural networks, back propagation, etc, but I have ZERO experience with Keras, PyTorch, and TensorFlow. And when I read code samples, it seems vastly different than any modeling pipeline based in scikit-learn. So I’m basically hitting a wall in terms of how to actually implement anything. And would love help or being pointed in the right direction. Thanks!",user_1821ffa2,22,0.97,8,2025-12-23 15:32:55,https://www.reddit.com/r/datascience/comments/1pu8h8d/resources_for_learning_neural_nets_autoencoders/,https://www.reddit.com/r/datascience/comments/1pu8h8d/resources_for_learning_neural_nets_autoencoders/,True,ML,self.datascience,datascience,False,False
1puve3n,Real world data is messy and that’s exactly why it keeps breaking our models,"Most of my early data science work focused on clean datasets Nice tables Clear labels No ambiguity Everything looked great in notebooks and benchmarks Then I started working on problems closer to real users and everything fell apart Inputs were vague Feedback contradicted itself People didn’t describe problems the way we expected Edge cases were the norm, not the exception What finally worked for me was that the mess is not noise to remove, It is the signal Real value hides in half sentences, complaints, follow up comments, and weird phrasing That is where intent, confusion, and unmet needs actually live Polished datasets rarely show you that Since then I stopped obsessing over perfect schemas and started paying more attention to how people talk about problems in the wild It completely changed how I think about feature design, evaluation, and even model choice Clean data is great for learning mechanics Messy data is where models learn usefulness That shift alone improved my results more than any new architecture or metric ever did",user_9989f072,0,0.38,21,2025-12-24 11:32:27,https://www.reddit.com/r/datascience/comments/1puve3n/real_world_data_is_messy_and_thats_exactly_why_it/,https://www.reddit.com/r/datascience/comments/1puve3n/real_world_data_is_messy_and_thats_exactly_why_it/,True,Discussion,self.datascience,datascience,False,False
1ptq71x,Suggestions for reading list,I saw a post on r/programming that recommended some must-read books for software engineers. What are some books that you think are must-reads for people in data science?,user_5257546c,46,0.98,19,2025-12-23 01:58:21,https://www.reddit.com/r/datascience/comments/1ptq71x/suggestions_for_reading_list/,https://www.reddit.com/r/datascience/comments/1ptq71x/suggestions_for_reading_list/,True,Discussion,self.datascience,datascience,False,False
1ptlund,Deciding on an offer: Higher Salary vs Stability,"Trying to decide between staying in a stable, but stagnating position or move for higher pay and engagement with higher risk of layoff. Would love to hear the subreddits thoughts on a move in this climate. I currently work for a city as a Senior DS. The position has good WLB, early retirement healthcare (in 5 years), and relative security. However, my role has shifted to mostly reporting in Tableau and Excel with shrinking DS opportunities. There is no growth in terms of salary or position. I have an offer from a mature startup that would give me a large pay bump and allow me to work on DS projects with a more contemporary tech stack. However, their reviews have mentioned recent layoffs and slow career growth. Below are some more specifics: I am 35 in a VHCOL city. DINK with a mortgage and student loans Current Job: -$130k * Okay pension with early retirement Healthcare in 5 years * Good WLB, but non-DS work with an aging tech stack * Raises and promotions are extremely rare (none for my team in the last 4 years) * 2 days in office New Job - same title: * $170k * DS work with a much more modern tech stack stack * fully remote * 1st year off 2 years of layoffs * reviews frequently cite few raises and promotions; however, really good wlb. One nice thing is I don't lose my pension progress if I leave, so if I do end up in a city or state position again I start up where I left off. UPDATE: I've decided to go with the new place - with my reasoning below: * Doing the math my pension benefit can be replicated with a 15% raise (less than the 30% the new role would give). * Talked to the new hiring manager and learned some more about the volatility and needs of the team which alleviated some concerns. * The holiday week at my current job has been very annoying. Like it has been doubling down on my concerns. This may be because I have an offer in my pocket, but they were particularly apparent in what should be a quieter week. My biggest concern is giving up the higher stability, but the points below were pretty good at pointing out that I am likely overrating it (might have been a different story if I was in a union but I am at-will). I appreciate everyone's help!",user_f2f1c119,69,0.94,29,2025-12-22 21:29:49,https://www.reddit.com/r/datascience/comments/1ptlund/deciding_on_an_offer_higher_salary_vs_stability/,https://www.reddit.com/r/datascience/comments/1ptlund/deciding_on_an_offer_higher_salary_vs_stability/,True,Career | US,self.datascience,datascience,False,False
1ptr5zo,Got an offer manager track in my smaller fintech or go to major retailer,"I have a job offer of manager with big retailer around 160-170 total comp with all the benefits. I expect just salary and bonus to be 143k then we add in the profit sharing, stocks and equity, rrsp contributions we expect the comp to push that generous number. Big retailer. Currently i make 120.5k. Small niche fintech. 3 years of experience i perform as a DS but did a pretty good job in my current role and i do genuinely innovate. So i am also on track to be manager in my current role. Type of work: Retailer is a lot of causal inference. I have to manage 4 people eventually 6. Building team from scratch in a pressure cooker environment. Fintech is a lot of credit risk and end to end ownership + docker + portfolio management + causal inference. I am going to take it to my manager and see the offer on the table. My big boss is super generous so it’s not out of the table to get great salaries. Unprompted i got an offer from 102500 total to 120.5. So i am 100%. Environment: Big retailer: 4 days in office Fintech: 2-3 days in offie probably 3 by next years. People: Big retailer: dont know but i go back to corporate. Fintech: we do have a bunch of idiots in the company and execs are not really my favorite. I do like some of our senior leadership but the top exec other than 1 exec i dont really like them. Career outlook: i came from original bank i had more interviews with big tech in the big bank than i did with fintech. Most of my interviews came from the fact i work in a big bank. So maybe going to big tech might be the play. I am gunning for the big tech roles so i am pushing as much as possible to hit the 180-200k comps so i can then climb the ladder. Do note for retailer I rejected their senior ds offer as it matched my comp. So they went in with manager and then svps sought me out. I interviewed and left a strong impression of how I explain + scope things as I do end to end ownership on my fintech role. Career insight is appreciated.",user_9cbc51f8,15,0.72,8,2025-12-23 03:00:17,https://www.reddit.com/r/datascience/comments/1ptr5zo/got_an_offer_manager_track_in_my_smaller_fintech/,https://www.reddit.com/r/datascience/comments/1ptr5zo/got_an_offer_manager_track_in_my_smaller_fintech/,True,Career | US,self.datascience,datascience,False,False
1pt93dh,I'm sure there will be some incredible horror stories in the coming years...,,user_662c7639,229,0.94,10,2025-12-22 11:50:04,https://i.redd.it/656q9g2y6t8g1.png,https://www.reddit.com/r/datascience/comments/1pt93dh/im_sure_there_will_be_some_incredible_horror/,False,Monday Meme,i.redd.it,datascience,False,False
1ptpoe1,Non-Stationary Categorical Data,"Assume features are categorical(i.e. 1 or 0) The target is binary, but the model outputs a probability, and we use that probability as a continuous score for ranking rather than applying a hard threshold. Imagine I have a backlog of items(samples) that need to be worked on by a team, and at any given moment I want to rank them by “probability of success”. Assume historical target variable is “was this item successful”(binary) and 1 million rows historical data. When an item first appears in the backlog(on Day 0), only partial information is available, so if I score it at that point, it might get a score of 0.6. Over time(let’s say day 5), additional information about that same item becomes available (metadata is filled in, external inputs arrive, some fields flip from unknown to known). If I were to score the item again later(on day 5), the score might update to 0.7 or 0.8. The important part is that the model is not trying to predict how the item evolves over time. Each score is meant to answer a static question: “Given everything we know right now, how should this item be prioritized relative to the others?” The system periodically re-scores items that haven’t been acted on yet and reorders the queue based on the latest scores. **I’m trying to reason about what modeling approach makes sense here, and how training/testing should be done so it matches how inference works?** I can’t seem to find any similar problems online. I’ve looked into things like Online Machine Learning but haven’t found anything that helps.",user_b414890c,10,0.71,13,2025-12-23 01:23:22,https://www.reddit.com/r/datascience/comments/1ptpoe1/nonstationary_categorical_data/,https://www.reddit.com/r/datascience/comments/1ptpoe1/nonstationary_categorical_data/,True,Discussion,self.datascience,datascience,False,False
1puckhr,Data scientist dumped all over the SaaS product used at my job,"Long story short, a coworker data scientist practically started spitting whenever we discussed the SaaS product we use. He repeatedly called it useless and insisted that it was not compliant with privacy law and company policy for AI use, even though he does not have direct knowledge of the procurement process or compliance reviews. (The people who do know are on vacation at the moment; my team will follow up with them.) DS succeeded in killing off a whole project just because he was so vehement that the SaaS was absolutely terrible and everybody just caved. And now my boss - who doesn't know anything about this stuff - is considering cancelling the contract and getting ... some other SaaS that does the same things because we won't always have a DS available. I don't know what to make of this. Some fairly senior people were involved in the decision to get the SaaS so DS is basically implying they didn't do their jobs properly. Also it just seemed weird, to be so publicly semi-enraged about such a thing. I quietly did my own little side-by-side comparison of the SaaS outputs and those from the DS's work and the SaaS seemed to do OK, for the fairly straightforward task we were doing. I haven't dared tell anyone I did this in case it gets back to DS. I guess my question is: Is that a normal way for a DS to behave?",user_83842e40,0,0.38,41,2025-12-23 18:50:51,https://www.reddit.com/r/datascience/comments/1puckhr/data_scientist_dumped_all_over_the_saas_product/,https://www.reddit.com/r/datascience/comments/1puckhr/data_scientist_dumped_all_over_the_saas_product/,True,Discussion,self.datascience,datascience,False,False
1pt2sd8,sharing my updated data science resources handbook,"A few months ago, I shared my list of resources for data analysis here. Since then, I've completely reworked it. The main change is that it's no longer just a list for data analysis. I've expanded it to cover a wider range of Data Science tasks, added new sections and resources, and overhauled the structure to make it easier to use. The main goal of this list is to save time for data scientists and analysts in finding tools and resources for their tasks. If it helps you solve a task too – that would be the best reward for me. [https://github.com/PavelGrigoryevDS/awesome-data-analysis](https://github.com/PavelGrigoryevDS/awesome-data-analysis) Happy holidays!",user_2ef378aa,46,0.96,4,2025-12-22 07:45:27,https://www.reddit.com/r/datascience/comments/1pt2sd8/sharing_my_updated_data_science_resources_handbook/,https://www.reddit.com/r/datascience/comments/1pt2sd8/sharing_my_updated_data_science_resources_handbook/,True,Tools,self.datascience,datascience,False,False
1psr1zf,"Weekly Entering & Transitioning - Thread 22 Dec, 2025 - 29 Dec, 2025","Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include: * Learning resources (e.g. books, tutorials, videos) * Traditional education (e.g. schools, degrees, electives) * Alternative education (e.g. online courses, bootcamps) * Job search questions (e.g. resumes, applying, career prospects) * Elementary questions (e.g. where to start, what next) While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",user_ac31a110,8,1.0,12,2025-12-21 21:01:37,https://www.reddit.com/r/datascience/comments/1psr1zf/weekly_entering_transitioning_thread_22_dec_2025/,https://www.reddit.com/r/datascience/comments/1psr1zf/weekly_entering_transitioning_thread_22_dec_2025/,True,,self.datascience,datascience,False,False
1psfidt,workforce moving to oversee,"My company is investing more and more in its overseas workforce, mostly in India. For every one job posted in the U.S., there are about ten in India. Is my company an exception, or is this happening everywhere?",user_2db079db,39,0.81,23,2025-12-21 11:57:54,https://www.reddit.com/r/datascience/comments/1psfidt/workforce_moving_to_oversee/,https://www.reddit.com/r/datascience/comments/1psfidt/workforce_moving_to_oversee/,True,Discussion,self.datascience,datascience,False,False
1psxo3h,Data Scientist Looking to Move Into Product/Strategy — Are CSM & CSPO Worth It?,,user_6e1439d0,1,0.67,0,2025-12-22 03:49:36,/r/projectmanagement/comments/1psxmkf/csm_cspo_for_a_data_scientist_moving_toward/,https://www.reddit.com/r/datascience/comments/1psxo3h/data_scientist_looking_to_move_into/,False,Discussion,,datascience,False,False
1psu4em,SQL assigments - asking for feedback,,user_b65b9798,0,0.43,0,2025-12-22 00:04:46,/r/learnSQL/comments/1prjnrs/sql_assigments_asking_for_feedback/,https://www.reddit.com/r/datascience/comments/1psu4em/sql_assigments_asking_for_feedback/,False,Education,,datascience,False,False
1prs5fg,New Data Science Team Lead struggling with aggressive PM on timelines and model expectations,"I’m a data scientist who was recently promoted to be a data science team lead. Overall I enjoy the role, but I’m running into a recurring challenge with a very aggressive product manager (also a leader) that I’m not sure how to handle well yet. There are two main issues: **1. Project timelines** Whenever we plan a project, she strongly questions why the data science timeline is “so long.” From my perspective, the timeline reflects real uncertainties: data quality issues, iteration cycles, experimentation, validation, and sometimes dependency on upstream systems. But in discussions, it often turns into “why can’t this be done faster?” rather than a conversation about trade-offs or risk. **2. Model performance expectations** She also frequently questions why the model performance “isn’t better.” Even when we’ve already applied reasonable feature engineering, tried multiple models, and are close to what I believe is the practical upper bound given the data, the response is often “can’t we push it further?” without a clear cost-benefit discussion. I understand that pushing for faster delivery and better results is part of a PM’s job. I’m not against being challenged. But I’m struggling with: * How to defend timelines without sounding defensive * How to explain model limitations in a way that’s convincing to non-technical stakeholders * How to avoid these conversations becoming emotionally charged or unproductive * How much of this is “normal PM behavior” vs. something I should actively push back on as a DS lead For those of you who’ve been senior ICs, DS managers, or team leads: * How do you handle PMs who are very aggressive on timelines and metrics? * What frameworks or language have you found effective when explaining uncertainty and diminishing returns? * At what point do you escalate, and how? Any advice, examples, or even “this is normal, here’s how to survive it” stories would be greatly appreciated.",user_476dbb1a,131,0.98,35,2025-12-20 15:44:23,https://www.reddit.com/r/datascience/comments/1prs5fg/new_data_science_team_lead_struggling_with/,https://www.reddit.com/r/datascience/comments/1prs5fg/new_data_science_team_lead_struggling_with/,True,Discussion,self.datascience,datascience,False,False
1prh1um,How complex are your experiment setups?,Are you all also just running t tests or are yours more complex? How often do you run complex setups? I think my org wrongly only runs t tests and are not understanding of the downfalls of defaulting to those,user_ae328c5b,21,0.84,44,2025-12-20 07:34:02,https://www.reddit.com/r/datascience/comments/1prh1um/how_complex_are_your_experiment_setups/,https://www.reddit.com/r/datascience/comments/1prh1um/how_complex_are_your_experiment_setups/,True,Statistics,self.datascience,datascience,False,False
1ppk6zj,Statistical Paradoxes and False Approaches to Data,"Hi all, published a blog covering some statistical paradoxes and approaches (Goodhart’s Law) that tend to mislead us. I always get valuable insights when I post here. I’d love to know any stories you have from industry experience of how statistical paradoxes or false approaches (Goodhart’s Law) have led to surprising results.",user_5444d864,105,0.98,22,2025-12-17 22:45:57,https://medium.com/@joshamayo7/statistical-paradoxes-that-could-be-misleading-your-analysis-159b4bf90fa9,https://www.reddit.com/r/datascience/comments/1ppk6zj/statistical_paradoxes_and_false_approaches_to_data/,False,Discussion,medium.com,datascience,False,False
1pqnkmy,SPARQL-LLM: From Natural Language to Executable Knowledge Graph Queries,,user_0f6bc3b6,0,0.39,1,2025-12-19 07:14:45,https://i.redd.it/iu5bva94f68g1.png,https://www.reddit.com/r/datascience/comments/1pqnkmy/sparqlllm_from_natural_language_to_executable/,False,AI,i.redd.it,datascience,False,False
1ppgky6,Open Source: datasetiq: Python client for millions of economic datasets – pandas-ready,"Datasetiq is a lightweight Python library that lets you fetch and work millions of global economic time series from trusted sources like FRED, IMF, World Bank, OECD, BLS, US Census, and more. It returns clean pandas DataFrames instantly, with built-in caching, async support, and simple configuration—perfect for macro analysis, econometrics, or quick prototyping in Jupyter. Python is central here: the library is built on pandas for seamless data handling, async for efficient batch requests, and integrates with plotting tools like matplotlib/seaborn. \### Target Audience Primarily aimed at economists, data analysts, researchers, macro hedge funds, central banks, and anyone doing data-driven macro work. It's production-ready (with caching and error handling) but also great for hobbyists or students exploring economic datasets. Free tier available for personal use. \### Comparison Unlike general API wrappers (e.g., fredapi or pandas-datareader), datasetiq unifies multiple sources (FRED + IMF + World Bank + 9+ others) under one simple interface, adds smart caching to avoid rate limits, and focuses on macro/global intelligence with pandas-first design. It's more specialized than broad data tools like yfinance or quandl, but easier to use for time-series heavy workflows. \### Quick Example `pip install datasetiq` import datasetiq as iq # Set your API key (one-time setup) iq.set_api_key(""your_api_key_here"") # Get data as pandas DataFrame df = iq.get(""FRED/CPIAUCSL"") # Display first few rows print(df.head()) # Basic analysis latest = df.iloc[-1] print(f""Latest CPI: {latest['value']} on {latest['date']}"") # Calculate year-over-year inflation df['yoy_inflation'] = df['value'].pct_change(12) * 100 print(df.tail()) Feedback welcome—issues/PRs appreciated!",user_ee7a7c00,36,0.92,6,2025-12-17 19:26:09,https://www.reddit.com/r/datascience/comments/1ppgky6/open_source_datasetiq_python_client_for_millions/,https://www.reddit.com/r/datascience/comments/1ppgky6/open_source_datasetiq_python_client_for_millions/,True,Coding,self.datascience,datascience,False,False
1pppvq7,Enterprise AI Agents: The Last 5 Years of Artificial Intelligence Evolution,,user_0f6bc3b6,0,0.44,0,2025-12-18 04:43:17,https://i.redd.it/fcel3485gy7g1.png,https://www.reddit.com/r/datascience/comments/1pppvq7/enterprise_ai_agents_the_last_5_years_of/,False,AI,i.redd.it,datascience,False,False
1pono4t,Requesting some feedback,,user_3c6c8192,84,0.9,34,2025-12-16 20:44:47,https://i.redd.it/0cmohmd52p7g1.png,https://www.reddit.com/r/datascience/comments/1pono4t/requesting_some_feedback/,False,Discussion,i.redd.it,datascience,False,False
1poq1rq,Data Analyst -> Data Scientist Success Stories,,user_fbc1579b,19,0.83,14,2025-12-16 23:00:41,/r/analytics/comments/1poppb8/data_analyst_data_scientist_success_stories/,https://www.reddit.com/r/datascience/comments/1poq1rq/data_analyst_data_scientist_success_stories/,False,Discussion,,datascience,False,False
1poadoi,Odd question: how do I pretend I still care about getting promoted?,"I know this might sound like a weird question, but here’s some context. I’ve got my performance review with my manager coming up this week. For the past 2 years I’ve been asking for a promotion, and my manager has basically been gaslighting me, moving the goal post, and never giving me any kind of clear roadmap. At this point I’m already interviewing elsewhere and honestly don’t really care if I get promoted or not. I’m pretty sure it’s not happening this year anyway. That said, I feel like I still have to bring it up so it doesn’t look like I suddenly stopped wanting a promotion. So yeah, how do I bring it up? And more importantly, what do I even say when they tell me no?",user_4e69ec53,91,0.92,33,2025-12-16 10:59:44,https://www.reddit.com/r/datascience/comments/1poadoi/odd_question_how_do_i_pretend_i_still_care_about/,https://www.reddit.com/r/datascience/comments/1poadoi/odd_question_how_do_i_pretend_i_still_care_about/,True,Career | US,self.datascience,datascience,False,False
1po3sqq,Does anyone have DS job that is low stress?,Started in DA and that was pretty low stress but boring. Mostly doing dashboard. Moved to DS and every project was high stress high priority with executive oversight. I experienced burn out and health issues. I got a low stress DS job just but it’s actually 100% DA so now I’m bored again. I want to go back to something more interesting like ML but don’t want all that stress again.,user_e05fd5f9,97,0.96,50,2025-12-16 06:48:36,https://www.reddit.com/r/datascience/comments/1po3sqq/does_anyone_have_ds_job_that_is_low_stress/,https://www.reddit.com/r/datascience/comments/1po3sqq/does_anyone_have_ds_job_that_is_low_stress/,True,Career | US,self.datascience,datascience,False,False
1po2tmr,Created list of AI tools and resources specifically for data scientists (Github repo),"For the past year, I’ve been working on integrating AI into my data science workflows to automate and optimise parts of it One of the things I noticed early on was that it was hard to find tools and resources that are truly aimed at data scientists and the ways we work. So I decided to put together this “AI data scientists handbook” gathering everything I’ve found along the way: AI-native tools, foundation models, learning resources, etc., that can actually help data scientists. Here is the link: [https://github.com/andresvourakis/ai-data-scientist-handbook](https://github.com/andresvourakis/ai-data-scientist-handbook) Let me know if there is anything else you’d like me to include (or make a PR). I’ll vet it and add it if it’s valuable Hope you find it valuable 🙏",user_fddb3a50,23,0.74,7,2025-12-16 06:08:03,https://www.reddit.com/r/datascience/comments/1po2tmr/created_list_of_ai_tools_and_resources/,https://www.reddit.com/r/datascience/comments/1po2tmr/created_list_of_ai_tools_and_resources/,True,Projects,self.datascience,datascience,False,False
1pockw2,How to start a reading group at work,"Has anyone started a paper/article reading group at their work place? My manager suggested doing something like this as a form of knowledge sharing. We already have a few 'interesting reads' channels but very few post to them and i'm not sure how many people actually read them. I would hope that having a low-stakes meeting where people can talk about interesting finds would drive engagement more than a channel would, but i also don't want to overload people's schedules with superfluous meetings. These reading groups were something i experienced at FAANG company earlier in my career but it was already extant when i joined, so i'm not sure what a good frequency/structure looks like. The last thing i want is for this to start up and then peter out after a few meetings, or to become the de facto presenter every week. The discussions don't need to be solely about research work, could be technical blogs with interesting points, as long as it gets people talking i guess? What have you seen work/not work?",user_8a97395a,7,0.82,6,2025-12-16 12:25:19,https://www.reddit.com/r/datascience/comments/1pockw2/how_to_start_a_reading_group_at_work/,https://www.reddit.com/r/datascience/comments/1pockw2/how_to_start_a_reading_group_at_work/,True,Discussion,self.datascience,datascience,False,False
1pndj6d,68% of Tech Workers Don’t Trust AI Hiring — So They’re Gaming the System,,user_7f97b18b,176,0.97,47,2025-12-15 09:34:27,https://www.interviewquery.com/p/tech-workers-gaming-ai-hiring-tools,https://www.reddit.com/r/datascience/comments/1pndj6d/68_of_tech_workers_dont_trust_ai_hiring_so_theyre/,False,Discussion,interviewquery.com,datascience,False,False
1pmmcwf,I got three offers from a two month job search - here's what I wish I knew earlier,"There's a lot of doom and gloom on reddit and elsewhere about the current state of the job market. And yes, it's bad. But reading all these stories of people going months and years without getting a job is the best way to ensure that you won't get a job either. Once you start panicking, you listen more to other people that are panicking and less to people who actually know what they're talking about. I'm not claiming to be one of those people, but I think my experience might be useful for some to hear. A quick summary of my journey: Worked for 5 years as a data scientist in Europe, moved to the US, got a job in San Francisco after 9 months, was laid off 9 months later, took several months off for personal reasons, and then got three good offers after about 2 months of pretty casual search. I've learnt a lot from this process though, and based on what I'm reading here and other places, I think many could benefit from learning from my experience. And for those with fewer years of experience reading this, you're definitely in a more difficult position than I was, but I still think many of my points are relevant for you as well. Before I get to the actual advice, I want to flesh out my background a bit more, if you’re interested in the context. If not, feel free to skip the next couple of paragraphs. I moved from Europe to the San Francisco area in the fall of 2023, after having worked as a data scientist for about 5 years at a startup. I did not consider myself a very talented DS at all, so I was very worried about not being able to find a job at all. With waiting for a work permit and being depressed for a while, it took me about 9 months before I started working, meaning that the gap on my resume kept growing while I was applying. I also did not have any network in the US, and had not had an interview for over 5 years, let alone one in the US interview culture. After struggling for months, I eventually got two offers in the same week; both came through LinkedIn, one through a cold referral ask, the other through reaching out to the HM directly (more on this in the “Referrals are great, but not necessary” section). I accepted one and worked there for 9 months before being part of a layoff. I then took about 4 months off before starting to apply seriously again (so yet another resume gap), and this time got three offers, two of which were remote. And I want to reiterate - I’m not a great data scientist; not at all naturally inclined to do well in interviews; and I’ve absolutely bombed a lot of them. But I feel like I’ve really understood now what it takes to do well in the job market. So, let’s get to the meat of this: My learnings from two (eventually) successful job search journeys: # 1. Put yourself in the hiring manager’s shoes! This point is a bit fluffier than the rest, but I think it’s actually the most important one, and most of the other points follow directly from this one. I’d advice you to put aside your own feelings around how grueling the job search is for the job searcher, and think about this for a moment before moving on: It has never been harder to find a good candidate for a position. Every job posting gets bombarded with applications the moment it’s posted, most of which are either fake (not a real person), severely unqualified, ineligible for the job (e.g. requiring visa sponsorship), or obviously AI generated. Also, be mindful of what the goal of the hiring manager is: Not to find the best possible candidate for this position - that’s basically impossible for most jobs out there due to the volume of applications - but to find someone who is eligible to work, meets the technical requirements, is excited about the job, and is likely to accept an offer. And, most importantly, they want to achieve this while minimizing the number of candidates they interview. That’s really, really difficult. So my first advice is: Feel empathy with the hiring manager! They’re not enjoying this process either. Your approach to the job search should be to help the hiring manager realize that you’re a great fit for this role. # 2. Only* apply for jobs that were recently posted From point 1, this should be obvious. Given the flood of applications, sending an application as soon as the job posting is opened dramatically increases your chances of your resume being read. Ideally you should apply within a day or two of the posting. \*However, if you have (or can get) a referral, or your background aligns with the position very well, you should still apply (one of my offers were in this category), but you should also try other ways to boost your visibility in this case (see point 4). # 3. Only apply for jobs that actually interest you (or that you can at least make yourself interested in) This might be a controversial point, and I’d be interested in hearing your thoughts on this! But this was the insight that made the largest impact on my job search. When I first started searching, I was filtering jobs by whether or not I was somewhat qualified, and applied for every job where I thought I might pass the bar for being considered. In my first few months of the search, I probably applied for 5-20 jobs per day. I did spend a bit more time on the ones I was more interested in, but not a significant amount. This approach led to a lot of rejections, some recruiter calls that wen’t tolerably well, but rarely did I progress past the HM interview, if I even got there. Once I changed my approach to only consider jobs that interested me, my mindset changed fundamentally: I spent much more time on each application because I genuinely wanted to work there, not just anywhere. The process became more fun - I was more motivated to tailor my resume, send in my application quickly, reach out on LinkedIn, and prepare for the interviews. Also, as mentioned in point 1., one of the main things a recruiter and hiring manager are looking for is someone who actually really wants to work there. When the recruiter asks you why you applied for the position, your answer (while it can be prepared in advance) should be genuine, and you should show that excitement. # 4. Referrals are great, but not necessary As mentioned in my background, I had no contacts in the US job market, but I still got 5 offers over the course of 1.5 years. Three were from cold applications, one from a LinkedIn-sourced referral, and one from reaching out to the HM on LinkedIn. So, while a standard application can definitely be enough, there are things you can do to increase your chances dramatically even without a network. I’ll briefly describe the two methods that has worked for me: **a. Ask for referrals** A lof of people sympathize with you in your job search, and even if they’re not the hiring manager, they also want the position to be filled. In addition, most people enjoy helping someone else. Keep in mind though: You have to meet them halfway. Make it easy for them to help you. Here’s an example of a message I received that, while very polite and polished, did not make me eager to help this person: >My name is XXX nice to meet you! I currently am a Chemical Engineer at 3M and have a passion for sustainability and I came across you and your previous company YYY. >I would love to have a chance to meet you and and discuss what type of work you were involved in, and what your honest experience was like at YYY. Let me know if you would be willing to. Thanks! For one, it’s not clear what their goals are. I assume they are fishing for an eventual referral, but I don’t want to meet with someone if they’re not upfront about why they want to meet. Secondly, they’re setting the barrier way to high: They’re asking for a call to discuss my experience at a company I no longer work for. Not to tout my own horn here, but here’s an example of a message I wrote which later ended up in a referral, and eventually a job offer: >Hi XX, >I was wondering if I could ask you some questions about what it's like to work with analytics engineering at YY? An AE position was just posted that looks very interesting to me, but with a somewhat different description than a typical AE role. >Thanks! In my opinion, this works because it makes it clear what I want (at least for now - I ask for a referral later in the conversation, but only after I’ve clearly shown my interest and appreciated their help), and most importantly, I make it easy for them to engage. All they have to say is “Sure!”. **b. Contact the hiring manager** There are lots of posts on how to efficiently use LinkedIn in your job search, so I won’t go into technical details here, but if you can find the hiring manager (or recruiter, though my success rate there is lower) on LinkedIn, try engaging with them! For one of my offers, I found that the HM had made a post on LinkedIn a couple of days before about the job opening, but there was very little engagement. My comment was simple - two sentences, very briefly stating my relevant experience, and that I've already applied. It’s worth repeating: Your goal is to help the HM see that you are a good fit for this role, while being mindful of their time. The opposite of that is comments like this: >Hello! I am interested and would love to know more on this. I have a lot of experience in chemical engineering and data analysis, so I am very excited about this role. My email address is: [xxx@gmail.com](mailto:xxx@gmail.com) This puts the burden on the HM to reach out to them, and to the HM, does not show any excitement about the role. From the HM’s perspective, if they were actually excited, they would have put in more effort. # 5. Optimize your resume, but not for the AI Your resume is (most likely) not being filtered by an AI, so don’t write your resume to optimize it for the AI! Obviously I’m not a recruiter so don’t take my word for this, but I’ve seen plenty of writing from people who are not recruiters talking about AI filtering out candidates, and plenty of writing from actual recruiters saying this is not true (e.g. [from Matt Hearnden](https://www.linkedin.com/posts/matthearnden_jobsearchstrategies-jobseekertips-mythbusting-activity-7178752657287761921-EuVG?utm_source=share&utm_medium=member_desktop&rcm=ACoAAA9ETNgB78IwolyXuuK2cKuagOwBigm5I1s), who also co-hosted the excellent podcast [\#opentowork](https://open.spotify.com/show/6zsTRagBhzqRA2TTLnpqH), which was very helpful in my job search). That being said, do optimize your resume. How to do this has been repeated ad nauseum in other posts, so I’ll be brief: Most importantly, every bullet point needs to show impact. Secondly, tailor your resume to the job description, for two reasons: One, obviously, to show that you can do the job. But secondly, to show that you are interested enough in the job to actually spend time on tailoring your resume! In the current state of AI-built resumes flying all over the place, an easy way to stand out is by showing you put in an effort. # 6. Prepare well for interviews This goes without saying, so I’ll just focus on the learnings that have been most useful to me. First, have your one-minute pitch about yourself locked down, and try to connect it to the company’s mission and values as much as you can (I typically gave the same intro in every interview, and then ended it by connecting my experience and goals to what the company is doing). Secondly, really take the time to prepare for the behavioral interviews. I’ve found practicing with an AI on this to be very useful - I’d paste in the JD and some info about the company, and ask it to come up with potential questions I might be asked, to which I prepared and wrote down answers for. And third, for technical interviews, two pieces of advice: First, “Ace the data science interview” - it’s expensive, but absolutely worth it (I think chapter 3 on cold emails is quite outdated, but the rest of the book is gold - especially the product sense chapter and the exercises at the end of it!). Second, if you bomb a technical interview because you were asked about things you just didn’t know, or the coding problems were too difficult - then you probably wouldn’t have enjoyed the job anyways! # 7. Be excited! It’s been somewhat of a red thread through this whole post, but it bears repeating at the end: Be excited about the position you’re applying and interviewing for! And if you’re interviewing over video, be doubly excited, as emotions don’t transmit as well through a screen. Smile as much as you can, especially in the first few minutes. This really makes a difference - it makes the interviewer more relaxed and excited to interview you, which in turns can make you more relaxed and perform better. Show the interviewer that you want to work with them. If you are excited about the role, it will also be easier to come up with good and genuine questions at the end that shows the interviewer that you’re serious about the role. If you’ve read this far, thank you so much! I would love to hear your thoughts or disagreements, or if you think I’m totally missing the mark on something. I’m actually mostly writing this up for my own sake, so that the next time I’m applying for jobs I can do so with confidence and manifest success.",user_11adb6e5,474,0.93,93,2025-12-14 11:16:58,https://www.reddit.com/r/datascience/comments/1pmmcwf/i_got_three_offers_from_a_two_month_job_search/,https://www.reddit.com/r/datascience/comments/1pmmcwf/i_got_three_offers_from_a_two_month_job_search/,True,Discussion,self.datascience,datascience,False,False
1pmz1nd,"Weekly Entering & Transitioning - Thread 15 Dec, 2025 - 22 Dec, 2025","Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include: * Learning resources (e.g. books, tutorials, videos) * Traditional education (e.g. schools, degrees, electives) * Alternative education (e.g. online courses, bootcamps) * Job search questions (e.g. resumes, applying, career prospects) * Elementary questions (e.g. where to start, what next) While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",user_ac31a110,8,1.0,11,2025-12-14 21:01:24,https://www.reddit.com/r/datascience/comments/1pmz1nd/weekly_entering_transitioning_thread_15_dec_2025/,https://www.reddit.com/r/datascience/comments/1pmz1nd/weekly_entering_transitioning_thread_15_dec_2025/,True,,self.datascience,datascience,False,False
1pmp2zn,Has anyone tried training models on raw discussions instead of curated datasets?,"I’ve always followed the usual advice when training models, like clean the data, normalize everything, remove noise, structure it nicely Recently I tried something different. Instead of polished datasets, I fed models long, messy discussion threads, real conversations, people arguing, correcting themselves, misunderstanding things, changing their mind mid sentence, explaining badly before explaining well No labels. No clean structure. Just raw text. What surprised me is that in some reasoning and writing tasks, the models trained on this kind of data felt more grounded, like less brittle not necessarily more accuratebut better at handling ambiguity and edge cases It made me wonder if what we often call noise is actually part of the signal! Human reasoning is messy by nature. Doubt, uncertainty, shortcuts, corrections, clean datasets remove all of that,but that’s not how people think or talk in the real world I’m not saying clean data is bad just questioning whether we’re over optimizing for neatness at the cost of realism Anyone else has experimented with this or seen similar effects in applied ML work?",user_9989f072,0,0.35,7,2025-12-14 13:09:53,https://www.reddit.com/r/datascience/comments/1pmp2zn/has_anyone_tried_training_models_on_raw/,https://www.reddit.com/r/datascience/comments/1pmp2zn/has_anyone_tried_training_models_on_raw/,True,ML,self.datascience,datascience,False,False
1plp7xo,Gemini Deep Research: Autonomous Intelligence for Enterprise Research,,user_0f6bc3b6,0,0.42,2,2025-12-13 08:19:57,https://i.redd.it/nafadc4gvz6g1.png,https://www.reddit.com/r/datascience/comments/1plp7xo/gemini_deep_research_autonomous_intelligence_for/,False,AI,i.redd.it,datascience,False,False
1pj7yir,"While 72% of Executives Back AI, Public Trust Is Tanking",,user_9e9ca6a8,181,0.97,30,2025-12-10 09:02:54,https://www.interviewquery.com/p/ai-trust-gap-research,https://www.reddit.com/r/datascience/comments/1pj7yir/while_72_of_executives_back_ai_public_trust_is/,False,Discussion,interviewquery.com,datascience,False,False
1pj7su0,Free course: data engineering fundamentals for python normies,"Hey folks, I'm a senior data engineer and co-founder of dltHub. We built `dlt`, a Python OSS library for data ingestion, and we've been teaching data engineering through courses on FreeCodeCamp and with Data Talks Club. Holidays are a great time to learn so we built a self-paced course on ELT fundamentals specifically for people coming from Python/analysis backgrounds. It teaches DE concepts and best practices though example. **What it covers:** * Schema evolution (why your data structure keeps breaking) * Incremental loading (not reprocessing everything every time) * Data validation and quality checks * Loading patterns for warehouses and databases **Is this about dlt or data engineering?** It uses our OSS library, but we designed it as a bridge for Python people to learn DE concepts. The goal is understanding the engineering layer before your analysis work. Free course + certification: [https://dlthub.learnworlds.com/course/dlt-fundamentals](https://dlthub.learnworlds.com/course/dlt-fundamentals) (there are more free courses but we suggest you start here) [Join 4000+ students who enrolled for our courses for free](https://preview.redd.it/sxyeyi4ma76g1.png?width=2048&format=png&auto=webp&s=d37012cf532696ca6ea5c61398c0194204679bfa) **The Holiday ""Swag Race"":** First 50 to complete the new module get swag (25 new learners, 25 returning). **PS - Relevant for data science workflows -** We added Marimo notebook + attach mode to give you SQL/Python access and visualization on your loaded data. Bc we use ibis under the hood, you can run the same code over local files/duckdb or online runtimes. First open pipeline [dashboard](https://dlthub.com/docs/general-usage/dashboard) to attach, then use marimo [here](https://dlthub.com/docs/general-usage/dataset-access/marimo). Thanks, and have a wonderful holiday season! \- adrian",user_f64187fa,108,0.94,11,2025-12-10 08:57:23,https://www.reddit.com/r/datascience/comments/1pj7su0/free_course_data_engineering_fundamentals_for/,https://www.reddit.com/r/datascience/comments/1pj7su0/free_course_data_engineering_fundamentals_for/,True,Education,self.datascience,datascience,False,False
1pjh3mg,"Most code agents cannot handle notebook well, so i build my own one in Jupyter.","https://i.redd.it/006immqrfg6g1.gif If you tried code agent, like cursor, claude code. They regards jupyter files as static text file and just edit them. Like u give a task, the you got 10 cells of code, and the agent hopes it can run all at once and solve your problem, which mostly cannot. The jupyter workflow is we analysis the cells result before, and then decide what to code next, so that's the code of runcell, the ai agent I build. which i setup a series of tools and make the agent understand jupyter cell context(cell output like df, charts etc). [runcell for eda](https://i.redd.it/pjv1q5oehg6g1.gif) Now it is a jupyter lab plugin and you can install it with pip install runcell. Welcome to test it in your jupyter and share your thoughts. Compare with other code agent: [runcell vs others](https://i.redd.it/nxdf6vq9ng6g1.gif)",user_a907813a,35,0.8,15,2025-12-10 14:47:42,https://www.reddit.com/r/datascience/comments/1pjh3mg/most_code_agents_cannot_handle_notebook_well_so_i/,https://www.reddit.com/r/datascience/comments/1pjh3mg/most_code_agents_cannot_handle_notebook_well_so_i/,True,AI,self.datascience,datascience,False,False
1pkfs40,Building the Enterprise Intelligence Core,,user_0f6bc3b6,0,0.25,2,2025-12-11 18:05:12,https://i.redd.it/4ls1s0ypao6g1.png,https://www.reddit.com/r/datascience/comments/1pkfs40/building_the_enterprise_intelligence_core/,False,AI,i.redd.it,datascience,False,False
1pj24c4,GBNet: fit XGBoost inside PyTorch,"Hi all, I maintain GBNet, an open source package that connects XGBoost and LightGBM to PyTorch. I find it incredibly useful (and practical) at exploring new model architectures for XGB or LGBM (ie GBMs). Please give it a try, and please let me know what you think:[ https://github.com/mthorrell/gbnet](https://github.com/mthorrell/gbnet) **HOW** \- GBMs consume derivatives and Hessians. PyTorch calculates derivatives and Hessians. GBNet does the orchestration between PyTorch and the GBM packages so you can fit XGBoost and/or LightGBM inside a PyTorch graph. **WHY** \- 1. Want a complex loss function you don't want to calculate the derivative of? ==> GBNet 2. Want to fit a GBM with some other structural components like a trend? ==> GBNet 3. Want to Frankenstein things and fit XGBoost and LightGBM in the same model at the same time? ==> GBNet **EXAMPLES** There are a few sci-kit-learn style models in the gbnet.models area of the codebase. 1. **Forecasting** \- Trend + GBM = actually pretty good forecasting out-of-the box. I have benchmarked against Meta's Prophet algorithm and have found Trend + GBM to have better test RMSE in about 75% of trials. I have a web-app with this functionality as well that is on GitHub pages:[ https://mthorrell.github.io/gbnet/web/app/](https://mthorrell.github.io/gbnet/web/app/) 2. **Ordinal Regression** \- Neither XGBoost nor LightGBM support ordinal regression. Ordinal Regression requires a complex loss function that itself has parameters to fit. After constructing that loss in PyTorch, GBNet let's you slap this loss (and fit its parameters) on top of XGBoost or LightGBM. 3. **Survival Analysis** \- Full hazard modeling in survival analysis requires integration over the hazard function. This GBNet model specifies the hazard function via GBM and integrates over this function using PyTorch. This all happens in each boost round during training. I don't believe there are any fully competing methods that do this. If you know one, please let me know. For a slightly more technical description, I have an article in the Journal of Open Source Software: [https://joss.theoj.org/papers/10.21105/joss.08047](https://joss.theoj.org/papers/10.21105/joss.08047)",user_2b1473cc,113,0.99,1,2025-12-10 05:07:46,https://i.redd.it/lzoessgvjd6g1.png,https://www.reddit.com/r/datascience/comments/1pj24c4/gbnet_fit_xgboost_inside_pytorch/,False,ML,i.redd.it,datascience,False,False
1pj5c8j,What’s the deal with job comp?,"I assume it’s just the market but I’ve had some recruiters reach out for roles that are asking for mid-level experience with entry-level pay. Even one role recently offered me a job but it was hybrid (I’m currently remote) and they refused to bump up pay (was $10k less than my current job). Do these companies really expect to poach talent with offers that at bare minimum match someone’s current role? It doesn’t make sense that these companies prefer people who are currently employed but fail to offer anything more than someone currently gets. Like where’s the pitch?, “Hey! Uproot and move for equal pay! Interested???” it’s bonkers to me. Maybe this is more of a rant than a question. I’m curious on other’s thoughts on what they’ve seen. For reference I’m early career DS (3 YOE) so my prospects in the current market are not top tier.",user_d441a134,35,0.83,30,2025-12-10 07:24:11,https://www.reddit.com/r/datascience/comments/1pj5c8j/whats_the_deal_with_job_comp/,https://www.reddit.com/r/datascience/comments/1pj5c8j/whats_the_deal_with_job_comp/,True,Discussion,self.datascience,datascience,False,False
1pjg4ul,Has anyone here tried training models on scraped conversations instead of clean datasets,"I am experimenting with something and I am trying to understand if others have seen similar results I always used cleaned datasets for fine tuning. Polished feedback, structured CSVs, annotated text, all of that. Recently I tried new thing, scraped long discussion threads from various platforms and used that messy text as the source. No labels, no structure, no formatting, just raw conversations where people argue, explain, correct each other, complain and describe their thinking in a natural way The strange part is that models trained on this kind of messy conversational data sometimes perform better for reasoning and writing tasks than models trained on tidy datasets. Not always but often enough that it surprised me It made me wonder if the real value is not the “cleanliness” but the hidden signals inside human conversations. Things like uncertainty, doubts, domain shortcuts, mistakes, corrections, and how people naturally talk through complex ideas So I wanted to ask people here who work in data science or applied ML Have you ever used raw scraped conversations as a training source? Did it help your model understand problems better?? Is this a known effect and I just never paid attention to it? I am not asking about legality or ethics right now, mostly curious about whether this approach is dumb luck or if it is actually a valid data strategy that people already use",user_9989f072,3,0.67,4,2025-12-10 14:08:35,https://www.reddit.com/r/datascience/comments/1pjg4ul/has_anyone_here_tried_training_models_on_scraped/,https://www.reddit.com/r/datascience/comments/1pjg4ul/has_anyone_here_tried_training_models_on_scraped/,True,Challenges,self.datascience,datascience,False,False
1phdam2,"Moving from ""Notebooks"" to ""Production"": I open-sourced a reference architecture for reliable AI Agents (LangGraph + Docker).","Hi everyone, I see a lot of discussion here about the shifting market and the gap between ""Data Science"" (training/analysis) and ""AI Engineering"" (building systems). One of the hardest hurdles is moving from a `.ipynb` file that works once, to a deployed service that runs 24/7 without crashing. I spent the last few months architecting a production standard for this, and I’ve **open-sourced the entire repo.** **The Repo:** [https://github.com/ai-builders-group/build-production-ai-agents](https://github.com/ai-builders-group/build-production-ai-agents) **The Engineering Gap (What this repo solves):** 1. **State Management (vs. Scripts):** Notebooks run linearly. Production agents need loops (retries, human-in-the-loop). We use **LangGraph** to model the agent as a State Machine. 2. **Data Validation (vs. Trust):** In a notebook, you just look at the output. In prod, if the LLM returns bad JSON, the app crashes. We use **Pydantic** to enforce strict schemas. 3. **Deployment (vs. Local):** The repo includes a production Dockerfile to containerize the agent for Cloud Run/AWS. The repo has a 10-lesson guide inside if you want to build it from scratch. Hope it helps you level up.",user_727b5fb9,54,0.85,17,2025-12-08 06:08:17,https://www.reddit.com/r/datascience/comments/1phdam2/moving_from_notebooks_to_production_i_opensourced/,https://www.reddit.com/r/datascience/comments/1phdam2/moving_from_notebooks_to_production_i_opensourced/,True,Projects,self.datascience,datascience,False,False
1phxhi0,Has anyone successfully built an “ai agent ecosystem”?,,user_0f6bc3b6,0,0.33,17,2025-12-08 19:43:54,https://i.redd.it/lgu6fvf0o36g1.jpeg,https://www.reddit.com/r/datascience/comments/1phxhi0/has_anyone_successfully_built_an_ai_agent/,False,AI,i.redd.it,datascience,False,False
1ph3u4m,"Weekly Entering & Transitioning - Thread 08 Dec, 2025 - 15 Dec, 2025","Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include: * Learning resources (e.g. books, tutorials, videos) * Traditional education (e.g. schools, degrees, electives) * Alternative education (e.g. online courses, bootcamps) * Job search questions (e.g. resumes, applying, career prospects) * Elementary questions (e.g. where to start, what next) While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",user_ac31a110,6,1.0,7,2025-12-07 21:01:38,https://www.reddit.com/r/datascience/comments/1ph3u4m/weekly_entering_transitioning_thread_08_dec_2025/,https://www.reddit.com/r/datascience/comments/1ph3u4m/weekly_entering_transitioning_thread_08_dec_2025/,True,,self.datascience,datascience,False,False
1phgszw,The thing that finally improved my workflow,"I used to think my bottleneck was tools Better models, better GPUs, better libraries, all that Turns out the real problem was way more basic. My inputs were trash... Not in a technical sense My datasets were fine. My pipelines worked. Everything ran, but the actual human language inside the data was stiff and way too “corporate clean” Once I started collecting messier real world phrasing from forums, comments, support tickets, and internal chats, everything changed!! Basically with RedditCommentScraper i got got all needed data to feed my LLM, and classifiers got sharper, my clustering made more sense, even my dumb little heuristics worked better lol Messy language carries intent, frustration, confusion, shortcuts, sarcasm, weird grammar. All the good stuff I need! What surprised me most is how fast the shift happened. I didn’t change the model. I didn’t tweak the architecture. I just fed it data that sounded like actual humans. Anyone else noticed this?",user_9989f072,0,0.44,12,2025-12-08 08:25:21,https://www.reddit.com/r/datascience/comments/1phgszw/the_thing_that_finally_improved_my_workflow/,https://www.reddit.com/r/datascience/comments/1phgszw/the_thing_that_finally_improved_my_workflow/,True,ML,self.datascience,datascience,False,False
1ph09wx,Inferential Statistics on long-form census data from stats can,"I am using the following tool [https://www150.statcan.gc.ca/t1/tbl1/en/tv.action?pid=9810065601](https://www150.statcan.gc.ca/t1/tbl1/en/tv.action?pid=9810065601) to query Statistics Canada and get data from the long-form census. However, since it's a census of 25% of the population, there is a need for inferential statistics. That being said in order to do inferential statistics on the numbers I come up with, I am going to need variance estimates. Does anyone know where I can get those variance estimates?",user_64acbac4,4,0.7,11,2025-12-07 18:02:42,https://www.reddit.com/r/datascience/comments/1ph09wx/inferential_statistics_on_longform_census_data/,https://www.reddit.com/r/datascience/comments/1ph09wx/inferential_statistics_on_longform_census_data/,True,Statistics,self.datascience,datascience,False,False
1pg2x2x,Lost and Feel Like a Fraud,"This might not be the appropriate place to say this, but I honestly feel like the biggest fraud ever. If I could go back, I don’t think I would have went into data science. I did my undergraduate in biology, and then did a masters in data science. I’ve continued to get better with coding (still not good enough like a CS major), learning, using AI, but I feel like I’m getting no where. In fact, I’m just getting more frustrated. My job is not related to data science AT ALL, just analyzing incoming live data. I’ve been polishing my resume, no luck at all for even 1 interview. I know the market is brutal, but even when you’re lucky enough to land a job, the salary is horrible in Canada. I don’t even think I enjoy doing data science work anymore since it’s becoming more and more dependant on AI. I’m too out of it to go back to school to do something else. In truth, I don’t know what I’m doing. I don’t even know why I’m writing this.",user_ec0654f4,114,0.95,42,2025-12-06 15:14:17,https://www.reddit.com/r/datascience/comments/1pg2x2x/lost_and_feel_like_a_fraud/,https://www.reddit.com/r/datascience/comments/1pg2x2x/lost_and_feel_like_a_fraud/,True,Discussion,self.datascience,datascience,False,False
1pg759t,DS audiobook recommendations?,"I have a very, very long road trip ahead of me. I would like recommendations for a DS audiobook that can help make the ride easier.",user_00223c6d,16,0.87,15,2025-12-06 18:37:29,https://www.reddit.com/r/datascience/comments/1pg759t/ds_audiobook_recommendations/,https://www.reddit.com/r/datascience/comments/1pg759t/ds_audiobook_recommendations/,True,Education,self.datascience,datascience,False,False
1pfwfn6,Are you using any AI agent in your work in data science/analytics? If so for what problem you use it? How much benefit did you see?,"Hi As the title says, I was wondering if anyone uses AI agents in their work. I want to explore them but I’m not sure how they would benefit me. Most examples I’ve seen involve automating tasks like scheduling appointments, sending calendar invites, or purchasing items. I’m curious how they’re actually used in data science and analytics. For example, in EDA we can already use common LLMs to help with coding, but the core of EDA still relies on domain knowledge and ideas. For user segmentation or statistical tests, we typically follow standard methodologies and apply domain expertise. For dashboarding, tools like Power BI already provide built-in AI features. So I’m trying to understand how people are using AI agents in practical data-science workflows. I’d also love to know which tools you used to build them. Even small examples—like something related to dashboarding or any data-science task—would be helpful. Edit- grammar, and one of the reasons i am asking is bcz some companies now asking for if you have built an agent, so gotta stay with the buzz. Edit 2- what i am more interested to know is use of AI agents, than just the use of AI or llms",user_d2481f01,48,0.8,59,2025-12-06 10:35:40,https://www.reddit.com/r/datascience/comments/1pfwfn6/are_you_using_any_ai_agent_in_your_work_in_data/,https://www.reddit.com/r/datascience/comments/1pfwfn6/are_you_using_any_ai_agent_in_your_work_in_data/,True,Discussion,self.datascience,datascience,False,False
1pfrp0c,The Latest Breakthrough from NVIDIA: Orchestrator-8B,,user_0f6bc3b6,14,0.83,2,2025-12-06 07:18:08,https://i.redd.it/v9gd0twenl5g1.jpeg,https://www.reddit.com/r/datascience/comments/1pfrp0c/the_latest_breakthrough_from_nvidia_orchestrator8b/,False,AI,i.redd.it,datascience,False,False
1pfgmpl,Why does Georgia Tech’s OMSA not get the same hate as other Analytics masters programs?,"Seems like this sub heavily favors stats and cs masters, with DS as more of a third option or something for career switchers. Masters in Data Analytics seem to be frowned upon with the exception of Georgia Tech’s program. What’s up with that???",user_fbc1579b,56,0.84,32,2025-12-05 20:47:48,https://www.reddit.com/r/datascience/comments/1pfgmpl/why_does_georgia_techs_omsa_not_get_the_same_hate/,https://www.reddit.com/r/datascience/comments/1pfgmpl/why_does_georgia_techs_omsa_not_get_the_same_hate/,True,Discussion,self.datascience,datascience,False,False
1pff4c3,Best books where you can read a ton of actual ML code?,"Looking for recommendations for books that are heavy on machine learning code, not just theory or high-level explanations. What did you find helpful for both interview prep and on-the-job coding?",user_48d03593,47,0.92,12,2025-12-05 19:27:33,https://www.reddit.com/r/datascience/comments/1pff4c3/best_books_where_you_can_read_a_ton_of_actual_ml/,https://www.reddit.com/r/datascience/comments/1pff4c3/best_books_where_you_can_read_a_ton_of_actual_ml/,True,Discussion,self.datascience,datascience,False,False
1pf4qfx,Best Data Conferences,What’s the best data conference you’ve been to? What made it awesome? I have a budget for some in-person PD and want to use it wisely.,user_57e54cc0,17,0.96,10,2025-12-05 11:47:47,https://www.reddit.com/r/datascience/comments/1pf4qfx/best_data_conferences/,https://www.reddit.com/r/datascience/comments/1pf4qfx/best_data_conferences/,True,Discussion,self.datascience,datascience,False,False
1pf76ye,Debating cancelling an interview because of poor communication during hiring,,user_ecec73a7,13,0.88,14,2025-12-05 13:26:23,/r/jobhunting/comments/1pf76fo/debating_cancelling_an_interview_because_of_poor/,https://www.reddit.com/r/datascience/comments/1pf76ye/debating_cancelling_an_interview_because_of_poor/,False,Discussion,,datascience,False,False
1pfezpe,Which TensorRT option to use,"I am working on a project that requires a regular torch.nn module inference to be accelerated. This project will be ran on a T4 GPU. After the model is trained (using mixed precision fp16) what are the next best steps for inference? From what I saw it would be exporting the model to ONNX and providing the TensorRT execution provider, right? But I also saw that it can be done using torch\_tensorrt (https://docs.pytorch.org/TensorRT/user\_guide/saving\_models.html) and the tensorrt (https://medium.com/@bskkim2022/accelerating-ai-inference-with-onnx-and-tensorrt-f9f43bd26854) packages as well, so there are 3 total options (from what I've seen) to use TensorRT... Are these the same? If so then I would just go with ONNX because I can provide fallback execution providers, but if not it might make sense to write a bit more code to further optimize stuff (if it brings faster performance).",user_674eb291,2,0.75,2,2025-12-05 19:21:05,https://www.reddit.com/r/datascience/comments/1pfezpe/which_tensorrt_option_to_use/,https://www.reddit.com/r/datascience/comments/1pfezpe/which_tensorrt_option_to_use/,True,Discussion,self.datascience,datascience,False,False
1pemhxl,Training by improving real world SQL queries,,user_b65b9798,8,0.83,6,2025-12-04 21:05:54,/r/learnSQL/comments/1pcdinm/training_by_improving_real_world_sql_queries/,https://www.reddit.com/r/datascience/comments/1pemhxl/training_by_improving_real_world_sql_queries/,False,Education,,datascience,False,False
1pe0a8r,How to Train Your AI Dragon,"[Article](https://medium.com/@michael.eric.stramaglia/how-to-train-your-ai-dragon-1df713d3a7c4) Wrote an article about AI in game design. In particular, using reinforcement learning to train AI agents. I'm a game designer and recently went back to school for AI. My classmate and I did our capstone project on training AI agents to play fantasy battle games Wrote about what AI can (and can't) do. One key them was the role of humans in training AI. Hope it's a funny and useful read! Key Takeaways: Reward shaping (be careful how in how you choose these) Compute time matters a ton Humans are still more important than AI. AI is best used to support humans",user_0fc9b69b,19,0.79,5,2025-12-04 05:41:06,https://www.reddit.com/r/datascience/comments/1pe0a8r/how_to_train_your_ai_dragon/,https://www.reddit.com/r/datascience/comments/1pe0a8r/how_to_train_your_ai_dragon/,True,Discussion,self.datascience,datascience,False,False
1peq0ep,Haskell IS a great language for data science,,user_5257546c,0,0.44,36,2025-12-05 00:39:51,https://jcarroll.com.au/2025/12/05/haskell-is-a-great-language-for-data-science/,https://www.reddit.com/r/datascience/comments/1peq0ep/haskell_is_a_great_language_for_data_science/,False,Discussion,jcarroll.com.au,datascience,False,False
1pdws8l,From Scalar to Tensor: How Compute Models Shape AI Performance,,user_0f6bc3b6,12,0.93,0,2025-12-04 02:37:25,https://i.redd.it/0amy2pucl74g1.png,https://www.reddit.com/r/datascience/comments/1pdws8l/from_scalar_to_tensor_how_compute_models_shape_ai/,False,AI,i.redd.it,datascience,False,False
1pda453,"Anthropic’s Internal Data Shows AI Boosts Productivity by 50%, But Workers Say It’s Costing Something Bigger",do you guys agree that using AI for coding can be productive? or do you think it does take away some key skills for roles like data scientist?,user_7f97b18b,170,0.89,74,2025-12-03 09:13:46,https://www.interviewquery.com/p/anthropic-ai-skill-erosion-report,https://www.reddit.com/r/datascience/comments/1pda453/anthropics_internal_data_shows_ai_boosts/,False,Discussion,interviewquery.com,datascience,False,False
1pd17ar,TabPFN now scales to 10 million rows (tabular foundation model),"Context: TabPFN is a pretrained transformer trained on more than hundred million synthetic datasets to perform in-context learning and output a predictive distribution for the test data. It natively supports missing values, categorical features, text and numerical features is robust to outliers and uninformative features. Published in Nature earlier this year, currently #1 on TabArena: [https://huggingface.co/TabArena](https://huggingface.co/TabArena) In January, TabPFNv2 handled 10K rows, a month ago 50K & 100K rows and now there is a Scaling Mode where we're showing strong performance up to 10M. Scaling Mode is a new pipeline around TabPFN-2.5 that removes the fixed row constraint. On our internal benchmarks (1M-10M rows), it's competitive with tuned gradient boosting and continues to improve. Technical blog post with benchmarks: [https://priorlabs.ai/technical-reports/large-data-model](https://priorlabs.ai/technical-reports/large-data-model) We welcome feedback and thoughts!",user_bb720034,39,0.92,7,2025-12-03 02:58:57,https://www.reddit.com/r/datascience/comments/1pd17ar/tabpfn_now_scales_to_10_million_rows_tabular/,https://www.reddit.com/r/datascience/comments/1pd17ar/tabpfn_now_scales_to_10_million_rows_tabular/,True,ML,self.datascience,datascience,False,False
1pcm88c,Just Broke the Trillion Row Challenge: 2.4 TB Processed in 76 Seconds,"When I started working on Burla three years ago, the goal was simple: anyone should be able to process terabytes of data in minutes. Today we broke the Trillion Row Challenge record. Min, max, and mean temperature per weather station across 413 stations on a 2.4 TB dataset in a little over a minute. Our open source tech is now beating tools from companies that have raised hundreds of millions, and we’re still just roommates who haven’t even raised a seed. This is a very specific benchmark, and not the most efficient solution, but it proves the point. We built the simplest way to run code across thousands of VMs in parallel. Perfect for embarrassingly parallel workloads like preprocessing, hyperparameter tuning, and batch inference. It’s open source. I’m making the install smoother. And if you don’t want to mess with cloud setup, I spun up [managed versions](https://docs.burla.dev/signup) you can try. Blog: [https://docs.burla.dev/examples/process-2.4tb-in-parquet-files-in-76s](https://docs.burla.dev/examples/process-2.4tb-in-parquet-files-in-76s) GitHub: [https://github.com/Burla-Cloud/burla](https://github.com/Burla-Cloud/burla)",user_d20acd83,161,0.83,44,2025-12-02 14:11:47,https://www.reddit.com/r/datascience/comments/1pcm88c/just_broke_the_trillion_row_challenge_24_tb/,https://www.reddit.com/r/datascience/comments/1pcm88c/just_broke_the_trillion_row_challenge_24_tb/,True,Challenges,self.datascience,datascience,False,False
1pdca12,Pivot to AI Career,,user_26333b14,0,0.46,11,2025-12-03 10:30:40,/r/cscareerquestionsEU/comments/1pcdzav/pivot_to_ai_career/,https://www.reddit.com/r/datascience/comments/1pdca12/pivot_to_ai_career/,False,Career | Europe,,datascience,False,False
1pcfzp7,I finally shipped DataSetIQ — a tool to search millions of macro datasets and get instant insights. Would love feedback from data people,"I’ve been working on a personal project for months that grew way bigger than expected. I got tired of jumping across government portals, PDFs, CSV dumps, and random APIs whenever I needed macroeconomic data. So I built DataSetIQ — now live here: https://www.datasetiq.com/platform What it does right now: • Search millions of public macro & finance datasets • Semantic + keyword hybrid search • Clean dataset pages with clear metadata • Instant AI insights (basic + advanced) • Dataset comparison • Trend & cycle interpretation • A proper catalog UI instead of 20 different government sites I’d honestly love feedback from people who actually touch data daily: • Does the search feel useful? • Are the insights too much / too little? • What feature is clearly missing? I am looking to improve the process further.",user_ee7a7c00,2,0.56,6,2025-12-02 10:18:44,https://www.reddit.com/r/datascience/comments/1pcfzp7/i_finally_shipped_datasetiq_a_tool_to_search/,https://www.reddit.com/r/datascience/comments/1pcfzp7/i_finally_shipped_datasetiq_a_tool_to_search/,True,Projects,self.datascience,datascience,False,False
1pbpnmz,Model learning selection bias instead of true relationship,"I'm trying to model a quite difficult case and struggling against issues in data representation and selection bias. Specifically, I'm developing a model that allows me to find the optimal offer for a customer on renewal. The options are either change to one of the new available offers for an increase in price (for the customer) or leave as is. Unfortunately, the data does not reflect common sense. Customers with changes to offers with an increase in price have lower churn rate than those customers as is. The model (catboost) picked up on this data and is now enforcing a positive relationship between price and probability outcome, while it should be inverted according to common sense. I tried to feature engineer and parametrize the inverse relationship with loss of performance (to an approximately random or worse). I don't have unbiased data that I can use, as all changes as there is a specific department taking responsibility for each offer change. How can I strip away this bias and have probability outcomes inversely correlated with price?",user_0800cecd,27,0.97,33,2025-12-01 13:37:07,https://www.reddit.com/r/datascience/comments/1pbpnmz/model_learning_selection_bias_instead_of_true/,https://www.reddit.com/r/datascience/comments/1pbpnmz/model_learning_selection_bias_instead_of_true/,True,ML,self.datascience,datascience,False,False
1pbjrp6,What worked for you for job search?,"So I am trying to switch after 2 years of experience in DS. Not getting enough calls. I hear people saying that they try applying through career pages of the companies. Does it work without any referral? Well, referrals are also tricky since you can't ask people for every other opening. Also does it help adding relevant keywords in your resume for getting shortlisted? I have got some good number of rejections so far (particularly from big tech and good startups). Although I am also not applying like 20 jobs a day! Can anyone share some strategies that helped them getting interview calls?",user_b9e86d83,36,0.97,32,2025-12-01 09:59:07,https://www.reddit.com/r/datascience/comments/1pbjrp6/what_worked_for_you_for_job_search/,https://www.reddit.com/r/datascience/comments/1pbjrp6/what_worked_for_you_for_job_search/,True,Discussion,self.datascience,datascience,False,False
1pbi7a6,What do you guys think about AI's effect on Jobs?,I am very much terrified given I am from a 3rd world country which has huge population. AI can lead to huge displacement of jobs. It is very difficult for me to catch up with everything happening in this space and also for some reason ppl want to implement llms every where the same ppl who were not fine with normal ml models. This seems to be mainly coming from stock market and shareholder thing. But you are required to pivot here as well. Also companies seems to not care as long it some what works I don't even know where we are going and what will be impact of all this. But AI for sure will get better and better with new research and I don't think we will get anything from these companies.,user_bf1f55d1,9,0.59,69,2025-12-01 09:02:17,https://www.reddit.com/r/datascience/comments/1pbi7a6/what_do_you_guys_think_about_ais_effect_on_jobs/,https://www.reddit.com/r/datascience/comments/1pbi7a6/what_do_you_guys_think_about_ais_effect_on_jobs/,True,Discussion,self.datascience,datascience,False,False
1pb3zf4,"Weekly Entering & Transitioning - Thread 01 Dec, 2025 - 08 Dec, 2025","Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include: * Learning resources (e.g. books, tutorials, videos) * Traditional education (e.g. schools, degrees, electives) * Alternative education (e.g. online courses, bootcamps) * Job search questions (e.g. resumes, applying, career prospects) * Elementary questions (e.g. where to start, what next) While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",user_ac31a110,10,0.92,18,2025-11-30 21:01:52,https://www.reddit.com/r/datascience/comments/1pb3zf4/weekly_entering_transitioning_thread_01_dec_2025/,https://www.reddit.com/r/datascience/comments/1pb3zf4/weekly_entering_transitioning_thread_01_dec_2025/,True,,self.datascience,datascience,False,False
1pbhcar,Not All AI Jobs Require Experience — These New Entry-Level AI Roles Are Hiring Fast into 2026,,user_e6f6eb17,0,0.45,0,2025-12-01 08:30:20,https://www.interviewquery.com/p/entry-level-ai-jobs-2026,https://www.reddit.com/r/datascience/comments/1pbhcar/not_all_ai_jobs_require_experience_these_new/,False,Discussion,interviewquery.com,datascience,False,False
1pandlg,MSE-DS or OMSCS?,"I've gotten a lot of mixed responses about this on other subreddits, so I wanted to ask here I was recently accepted to UPenn's online part-time MSE-DS program. I graduated from college this past May from a top 20 school with a degree in data science. To be honest, I originally applied to this program because I was having a tremendous amount of trouble landing a job in the data science industry (makes sense, since data scientist isn't an entry level role). However, I lucked out and eventually received an offer for a junior data scientist position. I like my current job, but the location isn't ideal. I'm a lot farther away from my family, and I'm only seeing them once or twice a year, and that has been very hard for me to deal with on top of adjusting to a much colder northeastern city. I was hoping a master's will help me job hop back to where my family is in a year or two, and that's also a reason why I have decided to not take a break from school. With the deadline to deposit coming, I am having a really hard time deciding whether this program is for me. I have listed some pros and cons below: Pros: 1. employer reimbursement - I will only have to pay around 20k for the entire program 2. UPenn name and prestige 3. asynchronous lectures, which is actually a plus for me because I tend to zone out during synchronous lectures lol Cons: 1. After talking to some people who attended my undergrad school and this program, it seems like there's a lot of overlap in terms of course content. So, i'd be learning a lot of the same things all over again 2. I want to become a data scientist, so maybe a CS program would improve my coding skills more. I've heard GT omscs is good, but I also heard it's hard and classes are huge, and I don't know if I'll be able to handle work with omscs. 3. Penn name doesn't matter as much since I have already broken into the DS industry, but at the same time GT name isn't as impressive on the resume Any advice would be greatly appreciated!!",user_e4a05cfc,14,0.82,12,2025-11-30 09:05:07,https://www.reddit.com/r/datascience/comments/1pandlg/mseds_or_omscs/,https://www.reddit.com/r/datascience/comments/1pandlg/mseds_or_omscs/,True,Education,self.datascience,datascience,False,False
1p9wal3,ggplotly - A Grammar of Graphics implementation in Python/Plotly,"[https://github.com/bbcho/ggplotly](https://github.com/bbcho/ggplotly) As a fun project, I decided to try and replicate ggplot2 in plotly and python. I know that plotnine exists, but I like the interactivity of plotly. Let me know what you think. Coverage isn't 100% but you can do most things. I tried to keep the syntax and naming conventions the same. So this should work: from ggplotly import * import pandas as pd import numpy as np x = np.linspace(0, 10, 100) y = np.random.random(100) df = pd.DataFrame({'x': x, 'y': y}) x = np.linspace(0, 10, 100) y = np.random.random(100) df2 = pd.DataFrame({'x': x, 'y': y}) ( ggplot(df, aes(x='x', y='y')) + geom_line() + geom_line(df2, aes(x='x', y='y', color='red'), name=""Test"", showlegend=False )",user_24862b4f,86,0.95,8,2025-11-29 10:39:26,https://www.reddit.com/r/datascience/comments/1p9wal3/ggplotly_a_grammar_of_graphics_implementation_in/,https://www.reddit.com/r/datascience/comments/1p9wal3/ggplotly_a_grammar_of_graphics_implementation_in/,True,Tools,self.datascience,datascience,False,False
1p9f29u,"Everyone Can ‘Code’ with AI Now, According to Google—But Tech Workers Aren't Fully Convinced",Have any data scientists here worked with AI for coding? Do you agree with experts' skepticism in using it for high-level tasks?,user_9e9ca6a8,326,0.95,110,2025-11-28 19:59:03,https://www.interviewquery.com/p/ai-coding-vibe-coding-explained,https://www.reddit.com/r/datascience/comments/1p9f29u/everyone_can_code_with_ai_now_according_to/,False,Discussion,interviewquery.com,datascience,False,False
1pag2q3,Are Spiking Neural Networks the Next Big Thing in Software Engineering?,"I’m putting together a community-driven overview of how developers see Spiking Neural Networks—where they shine, where they fail, and whether they actually fit into real-world software workflows. Whether you’ve used SNNs, tinkered with them, or are just curious about their hype vs. reality, your perspective helps. 🔗 **5-min input form:** [https://forms.gle/tJFJoysHhH7oG5mm7](https://forms.gle/tJFJoysHhH7oG5mm7) I’ll share the key insights and takeaways with the community once everything is compiled. Thanks! 🙌",user_50c54a04,0,0.5,8,2025-11-30 03:26:51,https://www.reddit.com/r/datascience/comments/1pag2q3/are_spiking_neural_networks_the_next_big_thing_in/,https://www.reddit.com/r/datascience/comments/1pag2q3/are_spiking_neural_networks_the_next_big_thing_in/,True,Discussion,self.datascience,datascience,False,False
1pa4tyg,"Designing the data collection for my undergrad capstone, what should I collect?","I will be completing my bachelors in Data Science this spring, culminating in an independent capstone project. I will be working with a local LGBT+ outreach/support group nonprofit, who I have learned has not been collecting any information in a focused manner, and has been struggling with grants due to not being able to prove with data any insights about event impacts to donors and stakeholders. Therefore, my project is looking like I will be helping them to design (the start of) a spreadsheet that can have information about each event entered, to make exploratory and prescriptive analysis possible. Best case scenario, the goal is to specifically collect data on what events are/are not drawing people in to start, with an extra focus on analyzing if people are coming in from out of town, as well as getting a sense of how overall head counts are trending for different types of events. I am just now starting to think about what information should be included in the design of data collection, and while I plan to have many talks with my professors and the nonprofit staff, I figured this subreddit could also be good to ask. Variables I have already thought of: \- Event Name \- Date \- Event Type \- City \- Target age range \- Online, in person, or hybrid \- Frequency of event \- On a weekend? \- Total attendance This is just a first draft and will most likely evolve dramatically as the data design progresses, but I would love advice directed at newbies to help me avoid potential pitfalls. Thanks!",user_bc0d1d25,4,0.65,10,2025-11-29 16:51:03,https://www.reddit.com/r/datascience/comments/1pa4tyg/designing_the_data_collection_for_my_undergrad/,https://www.reddit.com/r/datascience/comments/1pa4tyg/designing_the_data_collection_for_my_undergrad/,True,Analysis,self.datascience,datascience,False,False
1p9rwhf,Shap or LGBM gain for feature selection?,"Which one do you use during recursive feature elimination or forward/backward selection? I've always used gain and only used shap for analytics on model predictions, but came across some shap values recommendations. Bonus question: have you used ""null importance"" / permutation method? Fitting models with shuffled targets to remove features that look predictive by chance",user_9c857e3e,15,0.87,10,2025-11-29 07:38:50,https://www.reddit.com/r/datascience/comments/1p9rwhf/shap_or_lgbm_gain_for_feature_selection/,https://www.reddit.com/r/datascience/comments/1p9rwhf/shap_or_lgbm_gain_for_feature_selection/,True,Discussion,self.datascience,datascience,False,False
1p8pwnc,How are side-hustles seen to employers mid-career?,"Hello guys, I'm an early/mid-career data scientist. I'm 2 years into my first data scientist role in retail banking. I'm looking for my next company to be a tech or fintech company. I also have a side-project of 3 years which I think is quite cool. I've built a browser game entirely from scratch in C (built the API using raw sockets as well, front end is js though) and implemented ML models (RL and prediction, variety of architectures and looking to expand to neural nets if/when I get revenue) in the back end which control a core game mechanic . (The ML is in python not C lol) The game is in beta testing, but looking to put it on the market. Obviously the most likely scenario is it'll make peanuts, so I'm not considering leaving corporate or working on it more than I currently am. I'm wondering how this will look to recruiters? Is it something I should include on my CV? I genuinely think it's more impressive than anything I've built at work, but I don't want a recruiter to pass on me thinking I might flake or want to work on the game full time. Advice is very welcome 😁",user_91eb1b92,36,0.85,24,2025-11-28 00:37:59,https://www.reddit.com/r/datascience/comments/1p8pwnc/how_are_sidehustles_seen_to_employers_midcareer/,https://www.reddit.com/r/datascience/comments/1p8pwnc/how_are_sidehustles_seen_to_employers_midcareer/,True,Projects,self.datascience,datascience,False,False
1p9a4sh,The State of AI Agent Frameworks in 2025,,user_0f6bc3b6,0,0.5,0,2025-11-28 16:00:09,https://i.redd.it/0mp4atuyr24g1.png,https://www.reddit.com/r/datascience/comments/1p9a4sh/the_state_of_ai_agent_frameworks_in_2025/,False,AI,i.redd.it,datascience,False,False
1p7y708,2 YOE Data Scientist [Unemployed in data field] Burnt out and feeling helpless.,"Full resume [Link](https://drive.google.com/file/d/1PpN1hNRPFlGQ0vq6OwaJXZDZ2zMMp3MU/view?usp=sharing). Hello everyone. I am a 25 year old international student in the UK, who is heavily struggling to even land interviews and drowning in debt. I have tried retail/marketing industry and even Finance industry as I have the experience related to both of them. I also apply do not spray and pray. I send emails to hiring teams and people of the company after applying just to get in their radar. The freelancing job (The remote one) that I had, came from my Fiverr Gigs and It was going pretty well. I had to stop it because I moved to the UK for further studies in the hopes of getting better career progression. I think that I kinda messed up too by not applying for internships or even graduate programs (As I had experience on my CV). The last job I had was also a contractual job for 4 months and It came from the same company where I was working as a store manager (Retail). I have landed like 3 or 4 interviews in 3 years and am really really really struggling to understand what is going wrong. Is it my freelancing experience? Because I have learned a lot about CV's, applying to specific industry, working on stuff that the specific industry needs/wants. But I just simply do not understand. I am just lost literally lost. I would really really appreciate any help and honest feedback/advice, I know I will be grilled but sure bring it in it might help me. Thank you so much.",user_a8f9f63d,164,0.89,96,2025-11-27 01:40:13,https://i.redd.it/0f42mxydvc3g1.png,https://www.reddit.com/r/datascience/comments/1p7y708/2_yoe_data_scientist_unemployed_in_data_field/,False,Career | Europe,i.redd.it,datascience,False,False
1p8q2o9,Anyone working in printing and ads domain?,"I got an internship in a company that works with printing and ads domain. During the interview, they did not ask me anything related to the domain. Just basic ML and stats questions. I asked them about the work they do and they told, they have projects in inventory optimization, time series forecasting, etc.. Just wondering what are the work they do in these domains and what are the things I should learn before joining there?",user_dd6d9a5a,2,0.75,2,2025-11-28 00:49:13,https://www.reddit.com/r/datascience/comments/1p8q2o9/anyone_working_in_printing_and_ads_domain/,https://www.reddit.com/r/datascience/comments/1p8q2o9/anyone_working_in_printing_and_ads_domain/,True,Discussion,self.datascience,datascience,False,False
1p83xbo,Gifts for Data Scientists,"Some relatives have been asking what I, an unemployed data scientist, want for Christmas and they want to give something practical. Any suggestions for paid tools, subscription services, etc. that would be useful for upskilling, building a portfolio, or otherwise increasing my employability?",user_970ca8dd,49,0.79,72,2025-11-27 06:45:11,https://www.reddit.com/r/datascience/comments/1p83xbo/gifts_for_data_scientists/,https://www.reddit.com/r/datascience/comments/1p83xbo/gifts_for_data_scientists/,True,Tools,self.datascience,datascience,False,False
1p7je8p,Applied for 65 jobs in the past 2 months and only heard back from 1,Is there something wrong with my application approach or you guys are also getting similar callback rate? I am applying for primarily Senior roles. Edit: Should have given more context about myself. I have a MS in Statistics and I have 5 YOE working at a Fortune 25 company as a Data Scientist ML role. I will try to put an anonymized resume.,user_d528b440,45,0.79,46,2025-11-26 13:01:48,https://www.reddit.com/r/datascience/comments/1p7je8p/applied_for_65_jobs_in_the_past_2_months_and_only/,https://www.reddit.com/r/datascience/comments/1p7je8p/applied_for_65_jobs_in_the_past_2_months_and_only/,True,Career | US,self.datascience,datascience,False,False
1p77ms5,How do you store and organize your SQL queries?,"I’m curious how everyone organizes and stores their SQL queries, especially the ones used for exploratory analysis or ad hoc question rather than those for creating tables (dbt already solves that). Do you keep queries in the BI tool, use a folder with .sql files, package them into a library? Or what's the best set up you have found so far?",user_48d03593,42,0.95,38,2025-11-26 05:23:56,https://www.reddit.com/r/datascience/comments/1p77ms5/how_do_you_store_and_organize_your_sql_queries/,https://www.reddit.com/r/datascience/comments/1p77ms5/how_do_you_store_and_organize_your_sql_queries/,True,Discussion,self.datascience,datascience,False,False
1p7eh5l,Does adding online certifications help or cause harm?,"As a Data scientist with PhD and 6 yrs of experience, I am looking into possible new roles that involve AI projects. I have worked on several projects on embeddings via wordtovec, bert, sbert and others. I also have projects with LLM-API (mostly prompting) from my work. As not all the use cases of AI (RAG, Agentic) are needed in my current work. I have been preparing them by taking courses in online platforms i.e. Coursera, deeplearning.ai Just wanted to see yours opinion, adding certification of these course (LinkedIn or Resume) help or cause harm while applying for a Senior or lead roles ? Anyone with the hiring experience sharing their thoughts will be helpful.",user_762dcdb5,16,0.73,22,2025-11-26 09:53:28,https://www.reddit.com/r/datascience/comments/1p7eh5l/does_adding_online_certifications_help_or_cause/,https://www.reddit.com/r/datascience/comments/1p7eh5l/does_adding_online_certifications_help_or_cause/,True,Discussion,self.datascience,datascience,False,False
1p7c7cc,Building LLM-Native Data Pipelines: our workflow & lessons learned,"Hey everyone, i’m a senior data engineer and co-founder of the OSS data ingestion library dlt. I want to share a concrete workflow to build REST API → analytics pipelines in python. In the wild you often have to grab that data yourself from REST APIs. To help do that 10x faster and easier while keeping best practices we created a great OSS library for loading data (dlt) and a LLM native workflow and related tooling to make it easy to create REST API pipelines that are easy to review if they were correctly genearted and self-maintaining via schema evolution. Blog tutorial with video: [https://dlthub.com/blog/workspace-video-tutorial](https://dlthub.com/blog/workspace-video-tutorial) More education opportunities from us (data engineering courses): [https://dlthub.learnworlds.com/](https://dlthub.learnworlds.com/) oh and if you want to go meta i write quite a bit about how to make these systems work, this is my last post (this is more for LLM product PMs, how to think about it) [https://dlthub.com/blog/convergence](https://dlthub.com/blog/convergence) (also some stats) Discussion welcome",user_f64187fa,0,0.5,2,2025-11-26 08:28:59,https://www.reddit.com/r/datascience/comments/1p7c7cc/building_llmnative_data_pipelines_our_workflow/,https://www.reddit.com/r/datascience/comments/1p7c7cc/building_llmnative_data_pipelines_our_workflow/,True,Education,self.datascience,datascience,False,False
1p6eawa,How do I get the most out of the O’Reilly account?,"The organisation I work for has given me an account for training , learning etc. I have access to lots of content in there. 2.5 YOE, 6months AI Engineer, 2 years C++ dev. I want to progress in AI stream.",user_87122d72,34,0.93,11,2025-11-25 06:47:45,https://www.reddit.com/r/datascience/comments/1p6eawa/how_do_i_get_the_most_out_of_the_oreilly_account/,https://www.reddit.com/r/datascience/comments/1p6eawa/how_do_i_get_the_most_out_of_the_oreilly_account/,True,Discussion,self.datascience,datascience,False,False
1p6ihbi,Accept small internal promotion (DS) raise on current team or wait for another role (DE)?,Hi all. Got a career dilemma and looking for some thoughts. Additional context to my cross post. I'm Currently a DS and offered a promotion to stay on my current team for a 10% salary bump. The role I interviewed for was a DE position and would bring me a new title and ability to develop new skill set. Thanks!,user_08fa1c07,4,0.7,3,2025-11-25 09:24:02,/r/careeradvice/comments/1p6hm17/accept_small_internal_promotion_raise_on_current/,https://www.reddit.com/r/datascience/comments/1p6ihbi/accept_small_internal_promotion_ds_raise_on/,False,Career | US,,datascience,False,False
1p5tcrr,"AMA - DS, 8 YOE","I’ve worked in analytics for a while, banking for 4 years, and tech for the last 4 years. I was hoping to answer questions from folks, and will do my best to provide thoughtful answers. : )",user_69fe02fa,72,0.9,130,2025-11-24 13:13:07,https://www.reddit.com/r/datascience/comments/1p5tcrr/ama_ds_8_yoe/,https://www.reddit.com/r/datascience/comments/1p5tcrr/ama_ds_8_yoe/,True,Discussion,self.datascience,datascience,False,False
1p63hui,What’s the last project that got you excited about data?,Title. Just looking for some inspiration for personal projects.,user_8390043f,16,0.94,21,2025-11-24 20:45:20,https://www.reddit.com/r/datascience/comments/1p63hui/whats_the_last_project_that_got_you_excited_about/,https://www.reddit.com/r/datascience/comments/1p63hui/whats_the_last_project_that_got_you_excited_about/,True,Discussion,self.datascience,datascience,False,False
1p5mmx2,"New BCG/MIT Study: 76% of Leaders Now Call Agentic AI Colleagues, Not Tools",what are your own experiences with agentic AI? how do you think are they affecting DS roles?,user_b85d427c,31,0.64,21,2025-11-24 09:05:44,https://www.interviewquery.com/p/ai-agents-as-coworkers-2025,https://www.reddit.com/r/datascience/comments/1p5mmx2/new_bcgmit_study_76_of_leaders_now_call_agentic/,False,Discussion,interviewquery.com,datascience,False,False
1p4v7hg,Are LeetCode heavy Interviews becoming the norm for DS Modeling roles?,"I’ve been actively searching for DS Modeling roles again, and wow the landscape has changed a lot since the last time I was on the market. It seems like leetcode style interviews have become way more common. I’ve already failed or barely passed several rounds that focused heavily on DSA questions. At this point it feels like there’s no getting around it. Whenever a recruiter mentions a Python (not pandas) interview, my motivation instantly tanks. I want to get over this mental block, though, and actually prepare properly. For those of you who’ve interviewed recently, what’s the best way to approach this? And have you also noticed an increase in companies using leetcode style questions for DS roles?",user_4e69ec53,66,0.89,58,2025-11-23 11:14:35,https://www.reddit.com/r/datascience/comments/1p4v7hg/are_leetcode_heavy_interviews_becoming_the_norm/,https://www.reddit.com/r/datascience/comments/1p4v7hg/are_leetcode_heavy_interviews_becoming_the_norm/,True,Career | US,self.datascience,datascience,False,False
1p58a8q,"Weekly Entering & Transitioning - Thread 24 Nov, 2025 - 01 Dec, 2025","Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include: * Learning resources (e.g. books, tutorials, videos) * Traditional education (e.g. schools, degrees, electives) * Alternative education (e.g. online courses, bootcamps) * Job search questions (e.g. resumes, applying, career prospects) * Elementary questions (e.g. where to start, what next) While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",user_ac31a110,7,1.0,17,2025-11-23 21:01:15,https://www.reddit.com/r/datascience/comments/1p58a8q/weekly_entering_transitioning_thread_24_nov_2025/,https://www.reddit.com/r/datascience/comments/1p58a8q/weekly_entering_transitioning_thread_24_nov_2025/,True,,self.datascience,datascience,False,False
1p448m8,Will there be a discount for Physical O'Reilly Media books?,Will there be a discount for Physical O'Reilly Media books? Hello. Not sure if this is the best place to post this question so let me know. Does anyone know if there will be some Black Friday discount for Physical O'Reilly Media books somewhere? I would like to buy them as physical books so would like to know if anyone knows about this inquiry. Thank you.,user_9ff2b78f,17,0.83,14,2025-11-22 13:07:50,https://www.reddit.com/r/datascience/comments/1p448m8/will_there_be_a_discount_for_physical_oreilly/,https://www.reddit.com/r/datascience/comments/1p448m8/will_there_be_a_discount_for_physical_oreilly/,True,Education,self.datascience,datascience,False,False
1p33sdy,Indeed’s Job Report Shows 13% YoY Drop in Data & Analytics Roles,"""Roles like *business analyst, data analyst, data scientist,* and *BI developer* are drawing large talent pools that outpace the number of job postings, creating a fiercely competitive market."" do you agree with these findings - are data & analytics roles the hardest-hit in this sector-wide decline for tech jobs?",user_7f97b18b,278,0.97,59,2025-11-21 08:53:12,https://www.interviewquery.com/p/ai-boom-tech-jobs-decline-indeed-report,https://www.reddit.com/r/datascience/comments/1p33sdy/indeeds_job_report_shows_13_yoy_drop_in_data/,False,Discussion,interviewquery.com,datascience,False,False
1p3653q,How do you actually build intuition for choosing hyperparameters for xgboost?,"I’m working on a model at my job and I keep getting stuck on choosing the right hyperparameters. I’m running a kind of grid search with Bayesian optimization, but I don’t feel like I’m actually learning why the “best” hyperparameters end up being the best. Is there a way to build intuition for picking hyperparameters instead of just guessing and letting the search pick for me?",user_4e69ec53,77,0.96,21,2025-11-21 10:21:21,https://www.reddit.com/r/datascience/comments/1p3653q/how_do_you_actually_build_intuition_for_choosing/,https://www.reddit.com/r/datascience/comments/1p3653q/how_do_you_actually_build_intuition_for_choosing/,True,Education,self.datascience,datascience,False,False
1p2wvhr,How to become better at dashboarding,"So far I mainly did data management stuff or data science projects that involved creating static graphs to show and explain in a presentation. But now I am in a position that involves creating PowerBI reports for various stakeholders and I am struggling to get the best out of all the data. I do not struggle with the technical side of it rather with the way of presenting the data and telling the right story in those reports. So for example what is the right depth of information to show without overwhelming the user, the right use of sub-pages with more details or drill downs or bookmarks, making it visually appealing by using better colors, labels, sliders etc. Do you guys have any tipps for resources that could help me improve there?",user_f6c27d49,66,0.93,18,2025-11-21 04:05:06,https://www.reddit.com/r/datascience/comments/1p2wvhr/how_to_become_better_at_dashboarding/,https://www.reddit.com/r/datascience/comments/1p2wvhr/how_to_become_better_at_dashboarding/,True,Education,self.datascience,datascience,False,False
1p3683t,Experience with my recent online assessment. Bait and switch?,"This was for a data engineering position, that was heavily mentioned to use Python and other tools for data pipelines. I was given an assessment and only had 15 minutes to answers 12 questions. The questions: 1.) Scenario where I needed to explain the null hypothesis. 2.) Calculation for precision in a confusion matrix (and recall). 3.) How would I build a regression model in this scenario. 4.) Different types of machine learning models and when I'd use them. 5.) Average to calculate growth year over year for a scenario. 6.) And some different flavors of all of what I mentioned. I then had 12 additional critical thinking questions that were not very fun haha! Anyone have assessments like this that are totally different from the job posting? I was expecting some SQL, Python, and Javascript. I'm wondering how brain teasers and DS related stuff can related to this position?",user_2dfeaefc,10,0.92,7,2025-11-21 10:24:33,https://www.reddit.com/r/datascience/comments/1p3683t/experience_with_my_recent_online_assessment_bait/,https://www.reddit.com/r/datascience/comments/1p3683t/experience_with_my_recent_online_assessment_bait/,True,Discussion,self.datascience,datascience,False,False
1p2u2p8,Stationarity and Foundation Models,How big is the issue of non-stationary data when feeding them into foundation models for time series (e.g. Googles transformer-based TimesFM2.0)? Are they able to handle the data well or is transformation of the non-stationary features required/beneficial? Also I see many papers where no transformation is implemented for non-stationary data (across different ML models like tree-based or LSTM models). Do you know why?,user_68d26541,11,0.92,17,2025-11-21 01:17:33,https://www.reddit.com/r/datascience/comments/1p2u2p8/stationarity_and_foundation_models/,https://www.reddit.com/r/datascience/comments/1p2u2p8/stationarity_and_foundation_models/,True,ML,self.datascience,datascience,False,False
1p1zghy,Hands-on coding in DS interviews?,"Did anyone face hands-on coding in DS interviews - like using pandas to prepare the data, training model, tuning, inference etc. or to use tensorflow/pytorch to build a DL model? PS: Similar experience with MLE or AI Engineer roles as well, if any? For those roles I am assuming DSA atleast.",user_b9e86d83,38,0.92,36,2025-11-20 02:08:13,https://www.reddit.com/r/datascience/comments/1p1zghy/handson_coding_in_ds_interviews/,https://www.reddit.com/r/datascience/comments/1p1zghy/handson_coding_in_ds_interviews/,True,Discussion,self.datascience,datascience,False,False
1p1dklk,State of Interviewing 2025: Here’s how tech interview formats changed from 2020 to 2025,,user_e6f6eb17,69,0.8,15,2025-11-19 09:15:55,https://www.interviewquery.com/p/ai-interview-trends-tech-hiring-2025,https://www.reddit.com/r/datascience/comments/1p1dklk/state_of_interviewing_2025_heres_how_tech/,False,Discussion,interviewquery.com,datascience,False,False
1p0w4sd,Constant Deep Diving - Stakeholder Management Tips?,"To start, this isn't something I am totally unfamiliar with, but in the past (both in and outside my current org) it was restricted to one or two teams/leaders. However, for the past yearish I have been inundated with requests from multiple teams that boil down to A to Z deep dives of questions. While I don't expect *yes/no* asks it seems many requestors want us to pull out all the stops, such as multi-level cross-tabs, regression analysis, causal inference methods for what should be a quick pivot table. In the past, we knew who the usual suspects were and budgeted time for theses tasks and automated things where appropriate; however, it's currently not feasible given the workload. Current attempts at light pushback on the breadth of the request is met with ""Well I can't give *leader/stakeholder* a clear answer without a couple dozen slides of demographic breakdowns on this subject"" or ""What if they ask about the *extremely niche strata*'s trend?"". For context my organization doesn't have external clients or shareholders - most reporting ends up going to our executive leadership. I realize that maybe that is where this change is being driven by, but I know much of the work my team does is not full utilized in these conversations (and it really shouldn't be!). I guess my TLDR questions are: 1. How do I assuage stakeholders fear about not having enough insights or not going deep enough? 2. Outside top-down pressure is there another reason an organization as a whole could be adopting this over-compensation approach?",user_f2f1c119,22,0.92,15,2025-11-18 18:55:21,https://www.reddit.com/r/datascience/comments/1p0w4sd/constant_deep_diving_stakeholder_management_tips/,https://www.reddit.com/r/datascience/comments/1p0w4sd/constant_deep_diving_stakeholder_management_tips/,True,Discussion,self.datascience,datascience,False,False
1p0ekt8,"Three ‘Senior DS’ Interviews, Three Totally Different Skill Tests. How Do You Prepare?","I love how SWE folks can just grind LeetCode for a few months and then start applying once they’re “interview ready.” I feel like Data Science doesn’t really work that way. I’ve taken three interviews recently, all for “Senior Data Scientist” roles, and every single one tested something completely different: one was SQL + A/B testing/metrics investigation, another was exploratory data analysis with Pandas, and the last one was straight-up LeetCode. Honestly, it’s exhausting trying to prep for all these totally different expectations. Anyone have tips on how to navigate this?",user_d528b440,177,0.97,39,2025-11-18 07:17:08,https://www.reddit.com/r/datascience/comments/1p0ekt8/three_senior_ds_interviews_three_totally/,https://www.reddit.com/r/datascience/comments/1p0ekt8/three_senior_ds_interviews_three_totally/,True,Career | US,self.datascience,datascience,False,False
1p0ef0g,Traditional ML vs GenAI?,"This might be a stupid question, but for career growth and premium compensation which path is better - traditional ML (like timeseries forecasting etc.) vs GenAI? I have experience in both, but which one should I choose while switching? Any mature, unbiased opinion is much appreciated.",user_b9e86d83,40,0.86,46,2025-11-18 07:10:46,https://www.reddit.com/r/datascience/comments/1p0ef0g/traditional_ml_vs_genai/,https://www.reddit.com/r/datascience/comments/1p0ef0g/traditional_ml_vs_genai/,True,Discussion,self.datascience,datascience,False,False
1p0g6eb,Does the day of the week you submit your job application matter?,"Came across this image on CS Career subreddit, wondering what has your experience been. https://imgur.com/a/IZA3YAo",user_d528b440,25,0.86,13,2025-11-18 08:17:41,https://www.reddit.com/r/datascience/comments/1p0g6eb/does_the_day_of_the_week_you_submit_your_job/,https://www.reddit.com/r/datascience/comments/1p0g6eb/does_the_day_of_the_week_you_submit_your_job/,True,Career | US,self.datascience,datascience,False,False
1ozqvug,Why is my phone ringing so much?,,user_662c7639,240,0.96,16,2025-11-17 12:10:37,https://i.redd.it/hdx7416tjv1g1.png,https://www.reddit.com/r/datascience/comments/1ozqvug/why_is_my_phone_ringing_so_much/,False,Monday Meme,i.redd.it,datascience,False,False
1ozqb09,Relatable?,,user_662c7639,136,0.94,1,2025-11-17 11:49:28,https://i.redd.it/2ymroitffv1g1.png,https://www.reddit.com/r/datascience/comments/1ozqb09/relatable/,False,Monday Meme,i.redd.it,datascience,False,False
1oyyt5p,Where to Go After Data Science: Unconventional / Weird Exits?,"Data science careers often feel like they funnel into the same few paths—FAANG, ML/AI engineering, or analytics leadership—but people actually branch into wildly unexpected directions. I’m curious about those off-the-beaten-path exits: roles in unexpected industries, analytics-adjacent pivots, international moves, or entirely new ventures. Would love to hear some stories. P.S. Thread inspired from a thread in the consulting subreddit but adapted to DS.",user_48d03593,158,0.96,95,2025-11-16 14:12:36,https://www.reddit.com/r/datascience/comments/1oyyt5p/where_to_go_after_data_science_unconventional/,https://www.reddit.com/r/datascience/comments/1oyyt5p/where_to_go_after_data_science_unconventional/,True,Discussion,self.datascience,datascience,False,False
1oylljh,Meta's top AI researchers thinks LLMs are a dead end. Do many people here feel the same way from a technical perspective?,,user_67ad922a,429,0.95,184,2025-11-16 05:22:02,https://gizmodo.com/yann-lecun-world-models-2000685265,https://www.reddit.com/r/datascience/comments/1oylljh/metas_top_ai_researchers_thinks_llms_are_a_dead/,False,Analysis,gizmodo.com,datascience,False,False
1p04fao,"I feel very lost and hopeless, Loking for some senior to guide me","I am not a degree holder. But I kept working upon my skills. I gave up my previous job where I had a good position, but had a lot of interest in this field so decided to take a shift here. During my job I was abroad, I even gave up on my social life, just so that I could focus on studies in my free time. . Now that I came back, it feels like I'm lost, no one is willing to hire a degree-less person. I don't understand what to learn further, how to go forward. What to do next? How to translate my skills into business / client language ? What more to learn? . P.S (The director of DS was my position in a society from university, not a proper job - just added to gain recruiters attention + show relevancy in field)",user_b7d29722,0,0.41,24,2025-11-17 22:09:40,https://www.reddit.com/gallery/1p04fao,https://www.reddit.com/r/datascience/comments/1p04fao/i_feel_very_lost_and_hopeless_loking_for_some/,False,Career | Asia,reddit.com,datascience,False,False
1oz7lox,"Weekly Entering & Transitioning - Thread 17 Nov, 2025 - 24 Nov, 2025","Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include: * Learning resources (e.g. books, tutorials, videos) * Traditional education (e.g. schools, degrees, electives) * Alternative education (e.g. online courses, bootcamps) * Job search questions (e.g. resumes, applying, career prospects) * Elementary questions (e.g. where to start, what next) While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",user_ac31a110,6,0.88,11,2025-11-16 21:01:44,https://www.reddit.com/r/datascience/comments/1oz7lox/weekly_entering_transitioning_thread_17_nov_2025/,https://www.reddit.com/r/datascience/comments/1oz7lox/weekly_entering_transitioning_thread_17_nov_2025/,True,,self.datascience,datascience,False,False
1owgwg9,Regressing an Average on an Average,"Hello! If I have daily data in two datasets but the only way to align them is by year-month, is it statistically valid/sound to regress monthly averages on monthly averages? So essentially, does it make sense to do avg\_spot\_price \~ avg\_futures\_price + b\_1 + ϵ? Allow me to explain more about my two data sets. I have daily wheat futures quotes, where each quote refers to a specific delivery month (e.g., July 2025). I will have about 6-7 months of daily futures quotes for any given year-month. My second dataset is daily spot wheat prices, which are the actual realized prices on each calendar day for said year-month. So in this example, I'd have actual realized prices every day for July 2025 and then daily futures quotes as far back as January 2025. A Futures quote from January 2025 doesn't line up with a spot price from July and really only align by the delivery month-year in my dataset. For each target month in my data set (01/2020, 02/2020, .... 11/2025) I take: \- The average of all daily futures quotes for that delivery year-month \- The average of all daily spot prices in that year-month Then regress avg\_spot\_price \~ avg\_futures\_price + b\_1 + ϵ and would perform inference. Under this framework, I have built a valid linear regression model and would then be performing inference on my betas. Does collapsing daily data into monthly averages break anything important that I might be missing? I'm a bit concerned with the bias I've built into my transformed data as well as interpretability. Any insight would be appreciated. Thanks!",user_08fa1c07,29,0.99,17,2025-11-13 15:44:32,https://www.reddit.com/r/datascience/comments/1owgwg9/regressing_an_average_on_an_average/,https://www.reddit.com/r/datascience/comments/1owgwg9/regressing_an_average_on_an_average/,True,Analysis,self.datascience,datascience,False,False
1ovzhy2,How to deal with product managers?,"I work at a SaaS company as the single Data Scientist. I have 8 YoE and my role is similar to a lead DS in terms of responsibilities. I decide what models and techniques should we use in our product. Back then, I had no problems with delegating my research to engineers. Our team recently expanded and we hired some product managers. Right now, I'm having problems with a PM about the way of doing things. Our most interactions are like this: \* PM tells me ""customers need feature X"" \* I tell PM ""best way to do X is using A"" which is based on my current experiments and my past experiences in countless other projects \*couple hours later\* \* PM tells me ""I learned that the right way to do X is using B so we should do that"" and sends me a generic long ass ChatGPT response The problem is PM and some other lead developers believe that there are ""right"" ways of doing things instead of experimenting and picking whatever works best. They mostly consume very shallow content like ""use smote when class imbalance"" or ChatGPT slop. It seems like they don't value my opinions and they want to go along with what they want. Does anyone encounter something similar to this while working in a SaaS company? How should I deal with this?",user_2b5f59f2,112,0.95,36,2025-11-13 04:14:19,https://www.reddit.com/r/datascience/comments/1ovzhy2/how_to_deal_with_product_managers/,https://www.reddit.com/r/datascience/comments/1ovzhy2/how_to_deal_with_product_managers/,True,Discussion,self.datascience,datascience,False,False
1ow6bu4,How do you prep for a live EDA coding interview round?,"Got an interview coming up and the recruiter said it’ll involve data investigation and some exploratory data analysis in Python. Anyone done this kind of round before? How did you prep? I use Pandas every day at work, but I’m not sure if that alone is enough. Any tips or things I should brush up on?",user_d528b440,35,0.88,17,2025-11-13 08:56:16,https://www.reddit.com/r/datascience/comments/1ow6bu4/how_do_you_prep_for_a_live_eda_coding_interview/,https://www.reddit.com/r/datascience/comments/1ow6bu4/how_do_you_prep_for_a_live_eda_coding_interview/,True,Discussion,self.datascience,datascience,False,False
1ovx7sk,I’m working on a demand forecasting problem and need some guidance.,"Now my objective is to predict the weekly demand of each of the SKU that the retailer has placed an order for historically Business context: There are n retailers and m SKUs. Each retailer may or may not place an order every week, and when they do, they only order a subset of the SKUs. For any retailer who has historically ordered p SKUs (out of the total m), my goal is to predict their demand for those p SKUs for the upcoming week. I have a couple of questions: 1. How do I handle the scale of this problem? With many retailers and many SKUs — most of which are not ordered every week — this turns into a very sparse, high-dimensional forecasting problem. 2. Only about 15% of retailers place orders every week, while the rest order only occasionally. Will this irregular ordering behavior harm model accuracy or stability? If yes, how should I deal with it? Also, if anyone has recommendations for specific model types or architectures suited for this kind of sparse, multi-retailer, multi-SKU forecasting problem, I’d love your suggestions. PS - Used ChatGPT to better phrase my question.",user_0a62322c,41,0.94,35,2025-11-13 02:00:35,https://www.reddit.com/r/datascience/comments/1ovx7sk/im_working_on_a_demand_forecasting_problem_and/,https://www.reddit.com/r/datascience/comments/1ovx7sk/im_working_on_a_demand_forecasting_problem_and/,True,Projects,self.datascience,datascience,False,False
1ovzcfw,Gamified learning platform for data analytics,"Hey guys, I’ve been working on an idea of a gamified learning platform that turns the process of mastering data analytics into a story-driven RPG game. Instead of boring tutorials, you complete quests, earn XP, level up your character, and unlock new abilities in Excel, SQL, Power BI, and Python. Think of it as Duolingo meets Skyrim, but for learning analytics skills. I’m curious, would something like this motivate you to learn more effectively? I’m exploring whether there’s a real demand before taking the next step in development. Would you: \*Join such a learning adventure? \*Use it to stay consistent with learning goals? \*Or even contribute ideas for features, storylines, or skills to include?",user_4159db7b,9,0.74,5,2025-11-13 04:06:11,https://www.reddit.com/r/datascience/comments/1ovzcfw/gamified_learning_platform_for_data_analytics/,https://www.reddit.com/r/datascience/comments/1ovzcfw/gamified_learning_platform_for_data_analytics/,True,Education,self.datascience,datascience,False,False
1ovf9k2,How to prepare for AI Engineering interviews?,"I am a DS with 2 yrs exp. I have worked with both traditional ML and GenAI. I have been seeing different posts regarding AI Engineer interviews which are highly focused towards LLM based case studies. To be honest, I don't have much clue regarding how to answer them. Can anyone suggest how to prepare for LLM based case studies that are coming up in AI Engineer interviews? How to think about LLMs from a system perspective?",user_b9e86d83,16,0.72,23,2025-11-12 11:43:43,https://www.reddit.com/r/datascience/comments/1ovf9k2/how_to_prepare_for_ai_engineering_interviews/,https://www.reddit.com/r/datascience/comments/1ovf9k2/how_to_prepare_for_ai_engineering_interviews/,True,Discussion,self.datascience,datascience,False,False
1ow61lf,"Responsibilities among Data Scientist, Analyst, and Engineer?","As a brand manager of an AI-insights company, I’m feeling some friction on my team regarding boundaries among these roles. There is some overlap, but what tasks and tools are specific to these roles? - Would a Data Scientist use PyCharm? - Would a Data Analyst use tensorflow? - Would a Data Engineer use Pandas? - Is SQL proficiency part of a Data Scientist skill set? - Are there applications of AI at all levels? My thoughts: ## Data Scientist: - TASKS: Understand data, perceive anomalies, build models, make predictions - TOOLS: Sagemaker, Jupyter notebooks, Python, pandas, numpy, scikit-learn, tensorflow ## Data Analyst: - TASKS: Present data, including insight from Data Scientist - TOOLS: PowerBI, Grafana, Tableau, Splunk, Elastic, Datadog ## Data Engineer: - TASKS: Infrastructure, data ingest, wrangling, and DB population - TOOLS: Python, C++ (finance), NiFi, Streamsets, SQL, ## DBA - Focus on database (sql and non-) integrity and support.",user_539c7c9a,0,0.4,42,2025-11-13 08:45:35,https://www.reddit.com/r/datascience/comments/1ow61lf/responsibilities_among_data_scientist_analyst_and/,https://www.reddit.com/r/datascience/comments/1ow61lf/responsibilities_among_data_scientist_analyst_and/,True,Discussion,self.datascience,datascience,False,False
1oup4qu,Causal Meta Learners in 2025?,"Stuff like S/R/T/X learners. Anybody regularly use these in industry? Saw a bunch of big tech companies, especially Uber and Microsoft worked with them in early 2020s but haven't seen much mention of them in this sub or in job postings.",user_c643a297,38,0.89,27,2025-11-11 15:27:52,https://www.reddit.com/r/datascience/comments/1oup4qu/causal_meta_learners_in_2025/,https://www.reddit.com/r/datascience/comments/1oup4qu/causal_meta_learners_in_2025/,True,ML,self.datascience,datascience,False,False
1oud8cn,Tech Hiring Just Jumped 5% — At a Time You’d Least Expect,,user_9e9ca6a8,96,0.82,29,2025-11-11 08:01:33,https://www.interviewquery.com/p/tech-hiring-rebound-2025-trends,https://www.reddit.com/r/datascience/comments/1oud8cn/tech_hiring_just_jumped_5_at_a_time_youd_least/,False,Discussion,interviewquery.com,datascience,False,False
1oudx0d,Sr. DS role turned out to be an a research position. Not sure if I should still go through with it given the leetcode heavy process,"Got contacted on LinkedIn about a “Senior Data Scientist” role. I took the call out of curiosity, but after talking to the recruiter, it turns out the role is more like a Research Scientist / ML Engineer position. The interview process includes a DSA (data structures & algorithms) round as the technical screen, followed by system design in the onsite. For context, I’m a typical DS, I build models, write Python, and do analytics/ML work. I’ve done some LeetCode here and there, but I’m nowhere near ready to crush an hour long DSA interview right now. I could get there with about a month of prep, but I’m not sure the recruiter would wait that long. Would you go for it anyway, or pass and focus on roles more aligned with your skill set?",user_d528b440,64,0.91,12,2025-11-11 08:26:42,https://www.reddit.com/r/datascience/comments/1oudx0d/sr_ds_role_turned_out_to_be_an_a_research/,https://www.reddit.com/r/datascience/comments/1oudx0d/sr_ds_role_turned_out_to_be_an_a_research/,True,Career | US,self.datascience,datascience,False,False
1ov3nga,Prediction Pleasure – The Thrill of Being Right,"Trying to figure out what has made LLM so attractive and people hyped, way beyond reality. Human curiosity follows a simple cycle: explore, predict, feel suspense, and win a reward. Our brains light up when we guess correctly, especially when the “how” and “why” remain a mystery, making it feel magical and grabbing our full attention. Even when our guess is wrong, it becomes a challenge to get it right next time. But this curiosity can trap us. We’re drawn to predictions from Nostradamus, astrology, and tarot despite their flaws. Even mostly wrong guesses don’t kill our passion. One right prediction feels like a jackpot, perfectly feeding our confirmation bias and keeping us hooked. Now, reconsider what do we love about LLMs!! The fascination lies in the illusion of intelligence, humans project meaning onto fluent text, mistaking statistical tricks for thought. That psychological hook is why people are amazed, hooked, and hyped beyond reason. What do you folks think? What has made LLMs a good candidate for media and investors hype? Or, it's all worth it?",user_4e766d74,0,0.14,8,2025-11-12 04:20:08,https://www.reddit.com/r/datascience/comments/1ov3nga/prediction_pleasure_the_thrill_of_being_right/,https://www.reddit.com/r/datascience/comments/1ov3nga/prediction_pleasure_the_thrill_of_being_right/,True,Discussion,self.datascience,datascience,False,False
1oti1kt,When was the last time you inherited someone's problems? What happened?,,user_662c7639,282,0.97,13,2025-11-10 08:16:49,https://i.redd.it/6jeh2q95eg0g1.png,https://www.reddit.com/r/datascience/comments/1oti1kt/when_was_the_last_time_you_inherited_someones/,False,Monday Meme,i.redd.it,datascience,False,False
1ot53mz,"Weekly Entering & Transitioning - Thread 10 Nov, 2025 - 17 Nov, 2025","Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include: * Learning resources (e.g. books, tutorials, videos) * Traditional education (e.g. schools, degrees, electives) * Alternative education (e.g. online courses, bootcamps) * Job search questions (e.g. resumes, applying, career prospects) * Elementary questions (e.g. where to start, what next) While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",user_ac31a110,9,0.86,11,2025-11-09 21:01:38,https://www.reddit.com/r/datascience/comments/1ot53mz/weekly_entering_transitioning_thread_10_nov_2025/,https://www.reddit.com/r/datascience/comments/1ot53mz/weekly_entering_transitioning_thread_10_nov_2025/,True,,self.datascience,datascience,False,False
1otjgm8,Best Way to Organize ML Projects When Airflow Runs Separately?,,user_2f3d0bc4,0,0.44,0,2025-11-10 09:08:23,/r/mlops/comments/1otjbp1/best_way_to_organize_ml_projects_when_airflow/,https://www.reddit.com/r/datascience/comments/1otjgm8/best_way_to_organize_ml_projects_when_airflow/,False,Discussion,,datascience,False,False
1orws4r,"How to Decide Between Regression and Time Series Models for ""Forecasting""?","Hi everyone, I’m trying to understand intuitively when it makes sense to use a time series model like SARIMAX versus a simpler approach like linear regression, especially in cases of weak autocorrelation. For example, in wind power generation forecasting, energy output mainly depends on wind speed and direction. The past energy output (e.g., 30 minutes ago) has little direct influence. While autocorrelation might appear high, it’s largely driven by the inputs, if it’s windy now, it was probably windy 30 minutes ago. So my question is: how can you tell, just by looking at a “forecasting” problem, whether a time series model is necessary, or if a regression on relevant predictors is sufficient? From what I've seen online the common consensus is to try everything and go with what works best. Thanks :)",user_a63b5984,100,0.97,49,2025-11-08 10:32:05,https://www.reddit.com/r/datascience/comments/1orws4r/how_to_decide_between_regression_and_time_series/,https://www.reddit.com/r/datascience/comments/1orws4r/how_to_decide_between_regression_and_time_series/,True,Discussion,self.datascience,datascience,False,False
1orp0yj,"Free Learning Paths for Data Analysts, Data Scientists, and Data Engineers – Using 100% Open Resources","Hey, I’m Ryan, and I’ve created https://www.datasciencehive.com/learning-paths A platform offering free, structured learning paths for data enthusiasts and professionals alike. The current paths cover: • Data Analyst: Learn essential skills like SQL, data visualization, and predictive modeling. • Data Scientist: Master Python, machine learning, and real-world model deployment. • Data Engineer: Dive into cloud platforms, big data frameworks, and pipeline design. The learning paths use 100% free open resources and don’t require sign-up. Each path includes practical skills and a capstone project to showcase your learning. The ""Data Analyst"" path has homework for each section, will try to expand in to other learning paths in the future. That being said, you can't passively watch the videos and expect to learn, please try to apply the concepts, best way to learn! I see this as a work in progress and want to grow it based on community feedback. Suggestions for content, resources, or structure would be incredibly helpful. I’ve also launched a Discord community (https://discord.gg/Z3wVwMtGrw) with over 300 members where you can: • Collaborate on data projects • Share ideas and resources • Join future live hangouts for project work or Q&A sessions If you’re interested, check out the site or join the Discord to help shape this platform into something truly valuable for the data community. Let’s build something great together. Website: https://www.datasciencehive.com/learning-paths Discord: https://discord.gg/Z3wVwMtGrw",user_a5db52e6,64,0.94,8,2025-11-08 05:10:10,https://i.redd.it/debxmsxr810g1.gif,https://www.reddit.com/r/datascience/comments/1orp0yj/free_learning_paths_for_data_analysts_data/,False,Projects,i.redd.it,datascience,False,False
1orxjwe,Questions about ARIMA modelling,"I am facing weird issue trying to model my NET\_DEMAND. I have done unit roots tests and noticed that two levels of differencing is required and 1 level of seasonal differencing is required. But after that when I am trying to plot the ACF and PACF plots I am not seeing any significant spikes. Everything is bounded within. How can I get the p, and q values in this instance ? Just calling the ARIMA function is also giving a random walk model which is not picking up the data atall. Can anyone tell what I can do in this instance ? Has anyone faced something similar before ?",user_7fefbbd8,10,0.92,10,2025-11-08 11:02:44,https://www.reddit.com/r/datascience/comments/1orxjwe/questions_about_arima_modelling/,https://www.reddit.com/r/datascience/comments/1orxjwe/questions_about_arima_modelling/,True,Discussion,self.datascience,datascience,False,False
1orgbpc,Google DS-STAR: A state-of-the-art versatile data science agent,https://research.google/blog/ds-star-a-state-of-the-art-versatile-data-science-agent/ Has anyone tried it? I would like to know your opinion,user_b7a887ca,66,0.95,12,2025-11-07 20:39:40,https://www.reddit.com/r/datascience/comments/1orgbpc/google_dsstar_a_stateoftheart_versatile_data/,https://www.reddit.com/r/datascience/comments/1orgbpc/google_dsstar_a_stateoftheart_versatile_data/,True,Discussion,self.datascience,datascience,False,False
1oq17tl,"TabPFN-2.5 Is Live (Tabular Foundation Model, 2M+ Downloads)","We're releasing TabPFN-2.5, a pretrained transformer that delivers SOTA predictions on tabular data without hyperparameter tuning. It builds on v2 that was released in the [Nature](https://www.nature.com/articles/s41586-024-08328-6) journal earlier this year. Key highlights: * 5x scale increase: Now handles 50,000 samples × 2,000 features (up from 10,000 × 500 in v2) * SOTA performance: Achieves state-of-the-art results across classification and regression * Rebuilt API: New REST interface & Python SDK with dedicated fit & predict endpoints, making deployment and integration significantly more developer-friendly * Speed Boost: Delivers top performance in seconds over API Want to try it out? TabPFN-2.5 is available via [API](https://docs.priorlabs.ai/api-reference/getting-started) and via [Hugging Face](https://huggingface.co/Prior-Labs).",user_bb720034,40,0.95,12,2025-11-06 07:01:44,https://www.reddit.com/r/datascience/comments/1oq17tl/tabpfn25_is_live_tabular_foundation_model_2m/,https://www.reddit.com/r/datascience/comments/1oq17tl/tabpfn25_is_live_tabular_foundation_model_2m/,True,ML,self.datascience,datascience,False,False
1ophd6b,New Job Hunting Method: Not Applying,"Here’s why: A company opens a position and I apply along with 800 other people. The company sees 800 resumes and says F that, we’re hiring a recruiter. The recruiter finds me on LinkedIn and says they have a great job for me. Of course it’s the one I applied to. They ask if I’ve already applied and I tell them the truth, they ghost me because they don’t get commission if they’re not the original source. A few days after this, another recruiter reached out about a different position that I was planning on applying to directly with the company. This is also something that my current company has done after being overwhelmed with too many applicants. I’ll still be applying to some jobs, but it’s weird that applying has seemed to hurt my chances in some situations. Has anyone else experienced this? Any strategies for handling this?",user_29394f18,300,0.97,35,2025-11-05 14:26:54,https://www.reddit.com/r/datascience/comments/1ophd6b/new_job_hunting_method_not_applying/,https://www.reddit.com/r/datascience/comments/1ophd6b/new_job_hunting_method_not_applying/,True,Discussion,self.datascience,datascience,False,False
1opmsda,Is R Shiny still a thing?,"I’ve been working in data for a while and decided to finally get my masters a year ago. This term I’m taking an advanced visualization course that’s focused on dashboard optimization. It covers a lot of good content in the readings but I’ve been shocked to find that the practical portion of the course revolves around R Shiny! I when I first heard of R Shiny a decade or more ago it was all the rage, it quickly died out. Now I’m only hearing about Tableau, power bi, maybe Looker, etc. So in your opinion is learning Shiny a good use of time or is my University simply out of touch or too cheap to get licenses for the tools people really use? Edit: thanks for the responses, everyone. This has helped me see more clearly where/why Shiny fits into the data spectrum. It has also helped me realize that a lot of my chafing has come from the fact that I’m already familiar with a few visualization tools and would rather be applying the courses theoretical content immediately using those. For most of the other students, adding Shiny to the R and Python the MS has already taught is probably the fastest route to that. Thanks again!",user_3f0adf31,135,0.96,83,2025-11-05 18:19:56,https://www.reddit.com/r/datascience/comments/1opmsda/is_r_shiny_still_a_thing/,https://www.reddit.com/r/datascience/comments/1opmsda/is_r_shiny_still_a_thing/,True,Discussion,self.datascience,datascience,False,False
1oos8nq,How can i make 3D diagrams and images like these?,What software everyone use to generate 3D images like these for free? Any recommendations? https://devnavigator.com/2025/10/18/automating-email-processing-with-aws-services/,user_0f6bc3b6,55,0.9,13,2025-11-04 19:25:52,https://i.redd.it/ztx6hkusxczf1.jpeg,https://www.reddit.com/r/datascience/comments/1oos8nq/how_can_i_make_3d_diagrams_and_images_like_these/,False,Projects,i.redd.it,datascience,False,False
1opxs1q,How does your leadership see/organize AI investment?,"I am being asked to organize the portfolio of AI products being developed, and not sure of the best path forward. Does your leadership see AI investment like this, or in a different way? Serious answers only please. Source: [https://devnavigator.com/2025/10/20/ai-investment-portfolio-matrix-balancing-innovation-impact-and-feasibility/](https://devnavigator.com/2025/10/20/ai-investment-portfolio-matrix-balancing-innovation-impact-and-feasibility/)",user_0f6bc3b6,0,0.19,5,2025-11-06 04:37:53,https://i.redd.it/x0qsao0wsmzf1.png,https://www.reddit.com/r/datascience/comments/1opxs1q/how_does_your_leadership_seeorganize_ai_investment/,False,AI,i.redd.it,datascience,False,False
1op88dm,Graph Database Implementation,Hii All. A use case has arised for implementing a Graph Database for fraud detection. I suggested Neo4j but I have been guided towards the Neptune path. I have surface level knowledge on Graphs. Can anyone please help me with a roadmap and resources on how I can learn it and go on with the implementation in Neptune? My main aim is to create a POC as of now. My data is in S3 buckets in csv formats.,user_7fefbbd8,2,0.67,13,2025-11-05 08:54:56,https://www.reddit.com/r/datascience/comments/1op88dm/graph_database_implementation/,https://www.reddit.com/r/datascience/comments/1op88dm/graph_database_implementation/,True,Discussion,self.datascience,datascience,False,False
1ooqjjo,"Machine Learning, Physics, and Math Tutor/Mentor — Learn from an ML Researcher with 6+ years of Industry Experience","Hi there friends, I'm offering tutoring for anyone who is interested in deepening their knowledge and mastery of machine learning, mathematics, or physics. I have 6+ years in the industry as an ML Researcher and Engineer and have been studying physics for 15 years including lab work in quantum optics. I'm excellent at meeting students where they are and building a strong intuition. If this sounds interesting, shoot me a message or pass it along to someone who could use support. [https://www.superprof.com/machine-learning-physics-and-math-tutor-learn-from-researcher-with-years-industry-experience.html](https://www.superprof.com/machine-learning-physics-and-math-tutor-learn-from-researcher-with-years-industry-experience.html)",user_abbb4e7f,29,0.74,12,2025-11-04 18:05:58,https://www.reddit.com/r/datascience/comments/1ooqjjo/machine_learning_physics_and_math_tutormentor/,https://www.reddit.com/r/datascience/comments/1ooqjjo/machine_learning_physics_and_math_tutormentor/,True,ML,self.datascience,datascience,False,False
1onlngr,Anyone find one of these in their candy?,,user_662c7639,223,0.97,7,2025-11-03 11:38:43,https://i.redd.it/n0k8j8qoy2yf1.png,https://www.reddit.com/r/datascience/comments/1onlngr/anyone_find_one_of_these_in_their_candy/,False,Monday Meme,i.redd.it,datascience,False,False
1on8llk,[Opinion] AI will not replace DS. But it will eat your tasks. Prepare your skill sets for the future.,"Background: As a senior data scientist / ML engineer, I have been both individual contributor and team manager. In the last 6 months, I have been full-time building AI agents for data science & ML. Recently, I see a lot of stats showing a drop in junior recruitment, supposedly “due to AI”. I don’t think this is the main cause today. But I also think that AI will automate a large chunk of the data science workflow in the near future. So I would like to share a few thoughts on why data scientists still have a bright future in the age of AI but one needs to learn the right skills. **This is, of course, just my POV, no hard truth, just a data point to consider.** LONG POST ALERT! # Data scientists will not be replaced by AI Two reasons: First, technical reason: data science in real life requires a lot of cross-domain reasoning and trade-offs. Combining business knowledge, data understanding, and algorithms to choose the right approach is way beyond the capabilities of the current LLM or any technology right now. There are also a lot of trade-offs, “no free lunch” is almost always true. Understand those trade-offs and get the right stakeholders to take the right decisions is really hard. Second, social reason: it’s about accountability. Replacing DS with AI means somebody else needs to own the responsibility for those decisions. And tbh nobody wants to do that. It is easy to vibe-code a web app because you can click on buttons and check that it works. There is no button that tells you if an analysis is biased or a model is leaked. No AI provider can take the responsibility if your model/analysis breaks in production causing damages. Even if some is willing too, no organization want to outsource their valuable business decisions to some AI tech company. So in the end, someone needs to own the responsibility and the decisions, and that’s a DS. # AI will disrupt data science With all that said, I already see that AI has begun to replace DS on a lot of work. Basically, 80% (in time) of real-life data science is “glue” work: data cleaning and formatting, gluing packages together into a pipeline, making visuals and reports, debugging some dependencies, production maintenance. Just think about your last few days, I am pretty sure a big chunk of your time didn’t require deep thinking and creative solutions. AI will eat through those tasks, and it is a good thing. We (as a profession) can and should focus more on deeper modeling and understanding the data and the business. That will change a lot the way we do data science, and the value of skills will shift fast. # Future-proof way of learning & practicing (IMO) **Don’t waste time on syntax and frameworks.** Learn deeper concepts and mecanisms. Framework and tooling knowledge will drop a lot in value. Knowing the syntax of a new package or how to build charts in a BI tool will become trivial with AI getting access to code sources and docs. Do learn the key concepts and how they work, and why they work like that. **Improve your interpersonal skills.** This is basically your most important defense in the AI era. Important projects in business are all about trust and communication. No matter what, we humans are still social animals and we have a deep-down need to connect and trust other humans. If you’re just “some tech”, a cog in the machine, it is much easier to replace than a human collaborator. Practice how to earn trust and how to communicate clearly and efficiently with your team and your company. **Be more ambitious in your learning and your job**. With AI capabilities today, if you are still learning or evolving at the same pace, it will be seen later on your resume. The competitive nature of the labor market will push people to deliver more. As a student, you can use AI today to do projects that we older people wouldn’t even dream of 10 years ago. As a professional, delegate the chores to AI and push your project a bit further. Just a little bit will make you learn new skills and go beyond what AI can do. Last but not least, **learn to use AI efficiently**, learn where it is capable and where it fails. Use the right tool, delegate the right tasks, control the right moments. Because between a person who boosted their productivity and quality with AI and a person who hasn’t learned how, it is trivial who gets hired or raised. Sorry, a bit of ill-structured thoughts, but hopefully it helps some more junior members of the community. Feel free if you have any questions.",user_8dcabaa6,277,0.89,70,2025-11-03 02:49:22,https://www.reddit.com/r/datascience/comments/1on8llk/opinion_ai_will_not_replace_ds_but_it_will_eat/,https://www.reddit.com/r/datascience/comments/1on8llk/opinion_ai_will_not_replace_ds_but_it_will_eat/,True,Discussion,self.datascience,datascience,False,False
1ommxv4,How would you turn a working Jupyter pipeline into a small web app?,"I’ve inherited a few data-engineering notebooks that work end-to-end. I want to (1) extract the logic into a testable Python package and (2) put a minimal GUI on top so non-technical teammates can run it with parameters and download outputs. Constraints: Python only preferred, single-user initially, could grow to multi-user later.",user_fbe99468,36,0.88,34,2025-11-02 09:13:59,https://www.reddit.com/r/datascience/comments/1ommxv4/how_would_you_turn_a_working_jupyter_pipeline/,https://www.reddit.com/r/datascience/comments/1ommxv4/how_would_you_turn_a_working_jupyter_pipeline/,True,Projects,self.datascience,datascience,False,False
1on34xg,"Weekly Entering & Transitioning - Thread 03 Nov, 2025 - 10 Nov, 2025","Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include: * Learning resources (e.g. books, tutorials, videos) * Traditional education (e.g. schools, degrees, electives) * Alternative education (e.g. online courses, bootcamps) * Job search questions (e.g. resumes, applying, career prospects) * Elementary questions (e.g. where to start, what next) While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",user_ac31a110,4,0.84,17,2025-11-02 21:01:38,https://www.reddit.com/r/datascience/comments/1on34xg/weekly_entering_transitioning_thread_03_nov_2025/,https://www.reddit.com/r/datascience/comments/1on34xg/weekly_entering_transitioning_thread_03_nov_2025/,True,,self.datascience,datascience,False,False
1om9zgm,Is it too early to accept an internship offer?,"I’m a junior studying Data Analytics and Data Engineering at a solid state school. I’ve been a Data Analyst at my university’s career services for the past year, and previously interned as a Data & Business Analytics Intern at a regional credit union. I just got an offer for a Credit Risk Analyst internship at a top-35 US bank for Summer 2026. The location is great (could live with family rent-free), but it only pays $25/hour. What I’d be doing: The role is with their Corporate Credit Analytics team, which provides credit reporting and analytics directly to executive management across the entire bank. The analytics help support and drive risk mitigation strategies and policy changes. According to the posting, many of their analytics projects are “extremely fast paced and require a broad use of tools to query, analyze, and summarize information quickly.” Specific responsibilities: • Query and validate data from various sources in the bank’s data environment (working with large datasets) • Use analytic techniques to assess risk in credit portfolios - this is the core analytical work involving statistical methods • Assist in comparing the credit portfolio to that of peer banks - benchmarking and competitive analysis • Maintain framework used to manage credit risk (evaluate credit metrics) - working with existing risk management systems and metrics • Various clean-up/data projects - data quality and ad hoc analytical work The posting specifically mentions they want someone with “interest in portfolio risk management and statistical analysis,” and emphasizes exposure to statistical programming software (Python/R) and data visualization tools (Power BI). My situation: • I want to break into data science, specifically financial DS or product DS • I prefer classical ML and interpretable models (which seems to align with credit risk work) • Got the offer about a week ago with a 2-week decision deadline • I’m getting interviews at other companies, but mostly for Data Analyst, BI Analyst, and Analytics Engineer roles, not “Data Scientist” titles (those seem to heavily favor grad students) • This would be my final internship before graduating in May 2027 • In my current/previous roles, I already work heavily with SQL and Power BI, plus Python for correlation analysis and automation My questions: 1. Is this role solid for someone targeting data science, or does the “analyst” title hurt me? 2. Should I accept this or hold out for a “Data Scientist” titled internship (even though I’m not sure one will come)? 3. Does credit risk analytics experience translate well to product/financial data science roles?",user_fbc1579b,27,0.79,19,2025-11-01 23:09:26,https://www.reddit.com/r/datascience/comments/1om9zgm/is_it_too_early_to_accept_an_internship_offer/,https://www.reddit.com/r/datascience/comments/1om9zgm/is_it_too_early_to_accept_an_internship_offer/,True,Career | US,self.datascience,datascience,False,False
1olmp53,Has anyones company successfully implemented what is being described as ACP or an AI Mesh?,"Has anyones company implemented what is generally described as ACP or what McKinsey describes as an AI Mesh? The concept is a centralized space for AI Agents to ""talk to each other"". The link below is a general infographic comparing it to MCP and A2A: [https://devnavigator.com/2025/11/01/how-ai-agents-communicate-the-core-protocols-that-enable-collaboration/](https://devnavigator.com/2025/11/01/how-ai-agents-communicate-the-core-protocols-that-enable-collaboration/)",user_0f6bc3b6,52,0.79,32,2025-11-01 05:35:02,https://i.redd.it/vd2esv604nyf1.jpeg,https://www.reddit.com/r/datascience/comments/1olmp53/has_anyones_company_successfully_implemented_what/,False,AI,i.redd.it,datascience,False,False
1om9czc,schwab API usage from AWS,"Hello everyone, I want to create an app that places stock sales based on triggers from AWS (where all my code resides). I am not sure how can I get authorization tokens from withing AWS for schwab API. Does anyone have experience with schwab ?",user_058a6f9a,2,0.67,1,2025-11-01 22:31:32,https://www.reddit.com/r/datascience/comments/1om9czc/schwab_api_usage_from_aws/,https://www.reddit.com/r/datascience/comments/1om9czc/schwab_api_usage_from_aws/,True,Discussion,self.datascience,datascience,False,False
1oldbf4,Monetary value of remote work,"For the remote workers, how much of a compensation increase would it take for you to go in person? For me it’s probably ~$40k Would love to hear other people’s thoughts.",user_29394f18,31,0.79,39,2025-10-31 19:49:27,https://www.reddit.com/r/datascience/comments/1oldbf4/monetary_value_of_remote_work/,https://www.reddit.com/r/datascience/comments/1oldbf4/monetary_value_of_remote_work/,True,Discussion,self.datascience,datascience,False,False
1oku793,My notebook workflow,"Sometimes ago I asked reddit this because my manager wanted to ban notebooks from the team. https://www.reddit.com/r/datascience/s/ajU5oPU8Dt Thanks to you support, I was able to convince my manager to change his mind! 🥳 After some trial and error, I found a way to not only keep my notebooks, but make my workflows even cleaner and faster. So yea not saying manager was right but sometimes a bit of pressure help move things forward. 😅 I share it here as a way to thanks the community and pay it forward. It’s just my way of doing and each person should experiment what works best for them. Here it goes: - start analysis or experiment in notebooks. I use AI to quickly explore ideas, dont’ care about code quality for now - when I am happy, ask AI to refactor most important part in modules, reusable parts. Clean code and documented - replace the code in the notebook with those functions, basically keep the notebook as a report showing execution and results, very useful to share or go back later. Basically I can show my team that I go faster in notebook and don’t lose any times in rewriting code thanks to AI. So it’s win win! Even some notebook haters in my team start to reconsider 😀",user_3255ca91,20,0.76,17,2025-10-31 06:11:19,https://www.reddit.com/r/datascience/comments/1oku793/my_notebook_workflow/,https://www.reddit.com/r/datascience/comments/1oku793/my_notebook_workflow/,True,Tools,self.datascience,datascience,False,False
1olre1y,"Given my bad luck(where l was born, opportunities), do l still standout as an Applied AI Engineer? Am l like Anthropic/Google level good?","Portfolio: https://takuonline.com 5 YOE Quick notes: - Don't do mobile dev anymore, but have had some experience earlier in my life. - Huge emphasis on building real-world apps, i.e., pragmatic apps (the important 80%) - I have worked before as a data scientist, and have experience in machine learning and full-stack development (build ML algorithms and deploy/integrate them) - Portfolio only shows MY apps, not ones I have built in side enterprises, which constitute most of my work. - Portfolio shows progress, older projects at the bottom, newer ones at the top. I have an accounting degree, l have never used and yes I have never worked for one of the best companies in the world (never gotten that opportunity) but I think I am deserving of it to be honest, given how far I have gotten. Feedback highly appreciated. Please share you feedback, in great detail, not just a yes or a no, try to explain your reasoning, that will be very useful for me. Just saying no,because l work at google is not very useful coming from a stranger on the internet.",user_cda4b7e1,0,0.19,16,2025-11-01 08:57:37,https://www.reddit.com/r/datascience/comments/1olre1y/given_my_bad_luckwhere_l_was_born_opportunities/,https://www.reddit.com/r/datascience/comments/1olre1y/given_my_bad_luckwhere_l_was_born_opportunities/,True,Projects,self.datascience,datascience,False,False
1okvmiz,Home Insurance Claims Recovery modelling experience (subrogation),"Looking for people to get some insight and ideas for my new project for a client. The project is to predict recovery propensity in home insurance claims mainly when third party is at fault. Incase you have, 1. What type of external and internal data you used ? Mainly looking for relevant external data which was useful. 2. Which features helped you in identifying the recovery propensity? 3. Anything in the market which helps in identifying recovery ? 4. Any other approach you took which helped you in the modelling?",user_7a7cf2fb,7,0.89,14,2025-10-31 07:09:37,https://www.reddit.com/r/datascience/comments/1okvmiz/home_insurance_claims_recovery_modelling/,https://www.reddit.com/r/datascience/comments/1okvmiz/home_insurance_claims_recovery_modelling/,True,Discussion,self.datascience,datascience,False,False
1okzlh9,What are some key issues with data science undergrad degrees?,,user_bc0d1d25,5,0.67,33,2025-10-31 09:42:32,/r/askdatascience/comments/1okvrvh/what_are_some_key_issues_with_data_science/,https://www.reddit.com/r/datascience/comments/1okzlh9/what_are_some_key_issues_with_data_science/,False,Education,,datascience,False,False
1ok1gyf,Thoughts Regarding Levelling Up as a Data Scientists,"As I look for new opportunities , I see there is one or two skills I dont have from the job requirements. I am pretty sure I am not the only one such a situation. How is everyone dealing with these kind of things ? Are you performing side projects to showcase you can pull that off or are you blindly honest about it, claiming that you can pick that up on the job ?",user_7fefbbd8,75,0.87,41,2025-10-30 07:38:05,https://www.reddit.com/r/datascience/comments/1ok1gyf/thoughts_regarding_levelling_up_as_a_data/,https://www.reddit.com/r/datascience/comments/1ok1gyf/thoughts_regarding_levelling_up_as_a_data/,True,Discussion,self.datascience,datascience,False,False
1ojy88b,Data Science Managers and Leaders - How are you prioritizing the insane number of requests for AI Agents?,"Curious to hear everyone's thoughts, but how are you all managing the volume of asks for AI, AI Agents, and everything in between? It feels as though Agents are being embedded in everything we do. To bring clarity to stakeholders and prioritize projects, i've been using this: https://preview.redd.it/xd09zcm7s8yf1.png?width=1178&format=png&auto=webp&s=cd3e4eaccc268b4634e7b49b663383e8791db57e [https://devnavigator.com/2025/10/26/ai-initiative-prioritization-matrix/](https://devnavigator.com/2025/10/26/ai-initiative-prioritization-matrix/) Has anyone else been doing anything different?",user_0f6bc3b6,58,0.88,28,2025-10-30 05:23:54,https://www.reddit.com/r/datascience/comments/1ojy88b/data_science_managers_and_leaders_how_are_you/,https://www.reddit.com/r/datascience/comments/1ojy88b/data_science_managers_and_leaders_how_are_you/,True,Projects,self.datascience,datascience,False,False
1okr4zh,From Data to Value: The Architecture of AI Impact,,user_0f6bc3b6,0,0.36,4,2025-10-31 03:40:58,https://i0.wp.com/devnavigator.com/wp-content/uploads/2025/10/image-39.png?resize=1200%2C665&ssl=1,https://www.reddit.com/r/datascience/comments/1okr4zh/from_data_to_value_the_architecture_of_ai_impact/,False,AI,i0.wp.com,datascience,False,False
1okoiyw,How to train a LLM as a poor guy?,The title says it. I'm trying to train a medical chatbot for one of my project but all I own right now is a laptop with rtx 3050 with 4gb vram lol. I've made some architectural changes in this llama 7b model. Like i thought of using lora or qlora but it's still requires more than 12gb vram Has anyone successfully fine-tuned a 7B model with similar constraints?,user_407a9911,0,0.4,24,2025-10-31 00:52:17,https://www.reddit.com/r/datascience/comments/1okoiyw/how_to_train_a_llm_as_a_poor_guy/,https://www.reddit.com/r/datascience/comments/1okoiyw/how_to_train_a_llm_as_a_poor_guy/,True,Projects,self.datascience,datascience,False,False
1oje977,So what do y’all think of the Amazon layoffs?,"I’ve heard that many BIEs and data professionals have been laid off recently. It’s quite unsettling to see, and I’m feeling anxious both as an employee, since it could happen at my company too and as a job seeker, knowing that many of those laid-off professionals will now be competing in the job market alongside me.",user_d528b440,181,0.93,94,2025-10-29 12:35:11,https://www.reddit.com/r/datascience/comments/1oje977/so_what_do_yall_think_of_the_amazon_layoffs/,https://www.reddit.com/r/datascience/comments/1oje977/so_what_do_yall_think_of_the_amazon_layoffs/,True,Career | US,self.datascience,datascience,False,False
1oj9qua,Light read on the environmental footprint of data centers,"Hi guys, I just wrote this article on Medium I would appreciate any feedback and I would like to know what you think about the matter (since it touches also a bit on ethics). Link: [https://medium.com/@sokratisliakos/why-data-warehouses-are-an-environmental-paradox-1d1b0a021929?sk=6fa49ae6d3f8925bfb36f458aa63b79a](https://medium.com/@sokratisliakos/why-data-warehouses-are-an-environmental-paradox-1d1b0a021929?sk=6fa49ae6d3f8925bfb36f458aa63b79a)",user_1c7141fd,15,0.83,2,2025-10-29 09:48:58,https://www.reddit.com/r/datascience/comments/1oj9qua/light_read_on_the_environmental_footprint_of_data/,https://www.reddit.com/r/datascience/comments/1oj9qua/light_read_on_the_environmental_footprint_of_data/,True,Discussion,self.datascience,datascience,False,False
1oigf8k,burning out because nothing takes as short as the time im expected to complete tasks,"I work as a data engineer/analytics engineer and am given about 2 weeks to fully develop 3-4 datasets that are used in the backend for various applications. The issue is the following: 1. Theoretically, if I had even 80% clarity in requirements, I could probably finish a dataset in a span of 1-3 days. However, this is never the case - the requirements are frequently 50% clear, I have to figure that out along developing the dataset. When there’s an issue upstream of me, I have to go back to the source files and dig deep why something is missing. I have to wait on another engineer frequently in the process to either QA why something is missing or merge my pull requests which has frequent delays. 2. In between all of this work, I frequently get asked to make enhancements or fix bugs from previous work that can easily eat 1-3 days. Some of these bugs are random and occur because the source data upstream of me randomly changed that broke my entire process. Enhancements sound simple in theory until I actually work on it. 3. There’s no standard QA process. I told my boss I wanted to develop scripts to do QA as frequently in the past if we had data issues, I would be notified by either my boss or a stakeholder because they happened to notice the issue. I figured if I run a daily script where I can get an automated email that shows all my datasets and what’s going on, it can be easier to be proactive rather than reactive. My boss said that this is something another team is working on developing but there’s no sign that there is such a thing being developed and developing a QA process for every individual project is entirely on me to figure out 4. There’s NO documentation. My team is trying to get better at this but all my projects have been a product of zero past documentation. In order to get better at this, I’m expected to create documentation on top of all this work. Documentation can easily take me 1-2 days for each project and sometimes it gets pushed to the side because of focusing on 1-3. Even documenting on Jira easily takes me 30 mins - 1 hour 5. Add 3 hours of meeting a day on this already full plate Instead of 3 projects in 2 weeks, I feel if my focus was on just one project - from development, QA, documentation, it would be way more manageable. But there isn’t really an option on my team as they’re obsessed with scaling up, I’m frequently told everything is a priority. My eating and sleeping schedule had gotten so messed up in the span of the past few months - I don’t have time to make breakfast, lunch or dinner and end up skipping meals a lot. I wish to get a new job and would have easily started applying now if the economy wasn’t so bad. I’m wondering if others have experienced similar.",user_e066f98f,94,0.95,23,2025-10-28 10:54:57,https://www.reddit.com/r/datascience/comments/1oigf8k/burning_out_because_nothing_takes_as_short_as_the/,https://www.reddit.com/r/datascience/comments/1oigf8k/burning_out_because_nothing_takes_as_short_as_the/,True,Career | US,self.datascience,datascience,False,False
1oirqlb,Statistics blog/light read. Thoughts?,"Hi everybody, I just posted my first article on Medium and I would like some feeback (both positive and negative). Is it something that anyone would bother reading? Do you find it interesting as a light read? I really enjoy stats and writing so I wanted to merge them in some way. Link: [https://medium.com/@sokratisliakos/on-the-arbitrariness-or-lack-thereof-of-α-0-05-4d5965762646](https://medium.com/@sokratisliakos/on-the-arbitrariness-or-lack-thereof-of-α-0-05-4d5965762646) Thanks in advance",user_1c7141fd,10,0.81,13,2025-10-28 18:30:15,https://www.reddit.com/r/datascience/comments/1oirqlb/statistics_bloglight_read_thoughts/,https://www.reddit.com/r/datascience/comments/1oirqlb/statistics_bloglight_read_thoughts/,True,Discussion,self.datascience,datascience,False,False
1oicuu9,"Bank of America: AI Is Powering Growth, But Not Killing Jobs (Yet)",,user_b85d427c,53,0.82,16,2025-10-28 08:43:46,https://www.interviewquery.com/p/bank-of-america-ai-economy-job-impact,https://www.reddit.com/r/datascience/comments/1oicuu9/bank_of_america_ai_is_powering_growth_but_not/,False,Discussion,interviewquery.com,datascience,False,False
1ojb3u5,How I would land FAANG DS in 2025,"step 1: Have 3-5 years experience for L4 (No such thing as Junior DS at FAANG) step 2: Don't not have 3-5 years experience step 3: Get MSc in Stats/Comp sci./Physics/etc. (do not go for DS degree) step 4: Look on career site for which locations they are hiring for DS, move or be ready to move there. Easier to get headcount in Big US offices, latin America, Eastern Europe, India step 5: Look what kind of roles they are hiring for and what matches your skillset step 6: Tailor your resume, create projects if you don't have experience, for the roles they are hiring for. DS means a lot of things, and big companies are looking for specialists not generalists. There's someone to do ops, someone to do cloud engineering, someone to do dashboards, etc. step 7: Apply as much as you can, reach out and get referral from someone. Don't talk yourself out of applying step 8: Study at a bare minimum 20-50 hours for each hour of interview. Make sure you study for topics relevant to the role (ex. if it's in product analytics you won't have to know much ML ops) step 9: Interview well. You have to be perfect when it comes to the fundamentals. With an 8/10 performance you will either be rejected or request follow up interviews, anything below that doesn't cut it. Your english and fundamental technical skills must be perfect. Any signs of incompetence when it comes to the basics will be red flags. You must know 'why' not just the 'what'.",user_1479602f,0,0.47,16,2025-10-29 10:38:38,https://www.reddit.com/r/datascience/comments/1ojb3u5/how_i_would_land_faang_ds_in_2025/,https://www.reddit.com/r/datascience/comments/1ojb3u5/how_i_would_land_faang_ds_in_2025/,True,Career | US,self.datascience,datascience,False,False
1oiaj5d,"Your feedback got my resource list added to the official ""awesome-datascience"" repo","Hi everyone, A little while back, I shared my curated list of data science resources here as a public GitHub repo. The feedback was really valuable. Thanks for all the suggestions and feedback. Here's what was improved thanks to your ideas: * **Added new sections:** MLOps, AI Applications & Platforms, and Cloud Platforms & Infrastructure to make the list more comprehensive. * **Reworked the structure:** Split some bulky sections up. Hopefully now it's less overwhelming and easier to navigate. * **Packed more useful Python:** Added more useful Python libraries into each section to help find the right tool faster. * **Set up auto-checks**: Implemented an automatic check for broken links to keep the list fresh and reliable. A nice outcome: the list is now part of the main ""Awesome Data Science"" repository, which many of you probably know. If you have more suggestions, I'd love to hear them in the comments. I'm especially curious if adding new subsections for Books or YouTube channels within existing chapters (alongside Resources and Tools) would be useful. The list is here: [View on GitHub](https://github.com/PavelGrigoryevDS/awesome-data-analysis#readme) P.S. Thanks again. This whole process really showed me how powerful Reddit can be for getting real, expert feedback.",user_2ef378aa,21,0.84,9,2025-10-28 07:14:57,https://www.reddit.com/r/datascience/comments/1oiaj5d/your_feedback_got_my_resource_list_added_to_the/,https://www.reddit.com/r/datascience/comments/1oiaj5d/your_feedback_got_my_resource_list_added_to_the/,True,Education,self.datascience,datascience,False,False
1ohflw3,"OK, I accept that this is the worst post title I've ever made...",,user_662c7639,399,0.93,16,2025-10-27 07:17:15,https://i.redd.it/v4tx388cxnxf1.png,https://www.reddit.com/r/datascience/comments/1ohflw3/ok_i_accept_that_this_is_the_worst_post_title_ive/,False,Monday Meme,i.redd.it,datascience,False,False
1ohsucs,"For an A/B test where the user is the randomization unit and the primary metric is a ratio of total conversions over total impressions, is a standard two-proportion z-test fine to use for power analysis and testing?","My boss seems to think it should be fine, but there's variance in how many impressions each user has, so perhaps I'd need to compute the ICC (intraclass correlation) and use that to compute the design effect multiplier (DEFF=1+(m-1) x ICC)? It also appears that a GLM with a Wald test would be a appropriate in this case, though I have little experience or exposure to these concepts. I'd appreciate any resources, advice, or pointers. Thank you so much for reading!",user_421d0130,50,0.98,14,2025-10-27 15:37:34,https://www.reddit.com/r/datascience/comments/1ohsucs/for_an_ab_test_where_the_user_is_the/,https://www.reddit.com/r/datascience/comments/1ohsucs/for_an_ab_test_where_the_user_is_the/,True,Statistics,self.datascience,datascience,False,False
1ohp04q,"Kiln Agent Builder (new): Build agentic systems in minutes with tools, sub-agents, RAG, and context management [Kiln]","We just added an interactive Agent builder to [the GitHub project Kiln](https://github.com/Kiln-AI/Kiln). With it you can build agentic systems in under 10 minutes. You can do it all through our UI, or use our python library. What is it? Well “agentic” is just about the most overloaded term in AI, but Kiln supports everything you need to build agents: * [Tool Use](https://docs.kiln.tech/docs/agents#tool-use) * [Multi-Actor Interaction (aka subtasks)](https://docs.kiln.tech/docs/agents#multi-actor-interaction-aka-subtasks) * [Goal Directed, Autonomous Looping & Reasoning](https://docs.kiln.tech/docs/agents#goal-directed-autonomy-and-reasoning) * [State & Memory](https://docs.kiln.tech/docs/agents#state-and-memory) **Context Management with Subtasks (aka Multi-Actor Pattern)** Context management is the process of curating the model's context (chat/tool history) to ensure it has the right data, at the right time, in the right level of detail to get the job done. With Kiln you can implement context management by dividing your agent tasks into subtasks, making context management easy. Each subtask can focus within its own context, then compress/summarize for the parent task. This can make the system faster, cheaper and higher quality. See our [docs on context management](https://docs.kiln.tech/docs/agents#context-management) for more details. **Eval & Optimize Agent Performance** Kiln agents work with [Kiln evals](https://docs.kiln.tech/docs/evaluations) so you can measure and improve agent performance: * Find the ideal model to use, balancing quality, cost and speed * Test different prompts * Evaluate end-to-end quality, or focus on the quality of subtasks * Compare different agent system designs: more/fewer subtasks **Links and Docs** Some links to the repo and guides: * [Kiln AI on Github - 4k stars](https://github.com/Kiln-AI/Kiln) * [Docs for Kiln Agents](https://docs.kiln.tech/docs/agents) * [Kiln Discord](https://getkiln.ai/discord) * [Homepage](https://kiln.tech/) Feedback and suggestions are very welcome! We’re already working on custom evals to inspect the trace, and make sure the right tools are used at the right times. What else would be helpful? Any other agent memory patterns you’d want to see?",user_cf37a366,7,0.73,5,2025-10-27 13:07:06,https://i.redd.it/mn63lbh3opxf1.png,https://www.reddit.com/r/datascience/comments/1ohp04q/kiln_agent_builder_new_build_agentic_systems_in/,False,Tools,i.redd.it,datascience,False,False
1ogwru2,Anyone looking to read the third edition of Deep Learning With Python?,The book is now available to read online for free: https://deeplearningwithpython.io/chapters/,user_345e4f7a,115,0.97,14,2025-10-26 14:39:26,https://www.reddit.com/r/datascience/comments/1ogwru2/anyone_looking_to_read_the_third_edition_of_deep/,https://www.reddit.com/r/datascience/comments/1ogwru2/anyone_looking_to_read_the_third_edition_of_deep/,True,Education,self.datascience,datascience,False,False
1oh4tzk,"Weekly Entering & Transitioning - Thread 27 Oct, 2025 - 03 Nov, 2025","Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include: * Learning resources (e.g. books, tutorials, videos) * Traditional education (e.g. schools, degrees, electives) * Alternative education (e.g. online courses, bootcamps) * Job search questions (e.g. resumes, applying, career prospects) * Elementary questions (e.g. where to start, what next) While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",user_ac31a110,8,1.0,32,2025-10-26 21:01:37,https://www.reddit.com/r/datascience/comments/1oh4tzk/weekly_entering_transitioning_thread_27_oct_2025/,https://www.reddit.com/r/datascience/comments/1oh4tzk/weekly_entering_transitioning_thread_27_oct_2025/,True,,self.datascience,datascience,False,False
1of2sfs,The Great Stay — Here’s the New Reality for Tech Workers,Do you think you're part of this new phenomenon called The Great Stay?,user_e6f6eb17,77,0.93,23,2025-10-24 09:44:53,https://www.interviewquery.com/p/the-great-stay-tech-workers-ai-fear,https://www.reddit.com/r/datascience/comments/1of2sfs/the_great_stay_heres_the_new_reality_for_tech/,False,Discussion,interviewquery.com,datascience,False,False
1oehj29,Any other free options that are similar to ShotBot?,,user_ff5b5411,10,0.78,9,2025-10-23 15:43:38,https://youtu.be/H3nGXVSQww8?si=7qwcbRtpG5tZMwLD,https://www.reddit.com/r/datascience/comments/1oehj29/any_other_free_options_that_are_similar_to_shotbot/,False,Tools,youtu.be,datascience,False,False
1od5zca,What’s next for a 11 YOE data scientist?,"Hi folks, Hope you’re having a great day wherever you are in the world. Context: I’ve been in the data science industry for the past 11 years. I started my career in telecom, where I worked extensively on time series analysis and data cleaning using R, Java, and Pig. After about two years, I landed my first “data scientist” role in a bank, and I’ve been in the financial sector ever since. Over time, I picked up Python, Spark, and TensorFlow to build ML models for marketing analytics and recommendation systems. It was a really fun period — the industry wasn’t as mature back then. I used to get ridiculously excited whenever new boosting algorithms came out (think XGBoost, CatBoost, LightGBM) and spent hours experimenting with ensemble techniques to squeeze out higher uplift. I also did quite a bit of statistical A/B testing — not just basic t-tests, but full experiment design with power analysis, control-treatment stratification, and post-hoc validation to account for selection bias and seasonality effects. I enjoyed quantifying incremental lift properly, whether through classical hypothesis testing or uplift modeling frameworks, and working with business teams to translate those metrics into campaign ROI or customer conversion outcomes. Fast forward to today — I’ve been at my current company for about two years. Every department now wants to apply Gen AI (and even “agentic AI”) even though we haven’t truly tested or measured many real-world efficiency gains yet. I spend most of my time in meetings listening to people talk all day about AI. Then I head back to my table to do prompt engineering, data cleaning, testing, and evaluation. Honestly, it feels off-putting that even my business stakeholders can now write decent prompts. I don’t feel like I’m contributing much anymore. Sure, the surrounding processes are important — but they’ve become mundane, repetitive busywork. I’m feeling understimulated intellectually and overstimulated by meetings, requests, and routine tasks. Anyone else in the same boat? Does this feel like the end of a data science journey? Am I far too gone? It’s been 11 years for me, and lately, I’ve been seriously considering moving into education — somewhere I might actually feel like I’m contributing again.",user_e99bc2f1,241,0.95,86,2025-10-22 04:45:51,https://www.reddit.com/r/datascience/comments/1od5zca/whats_next_for_a_11_yoe_data_scientist/,https://www.reddit.com/r/datascience/comments/1od5zca/whats_next_for_a_11_yoe_data_scientist/,True,Discussion,self.datascience,datascience,False,False
1ode6j8,Create stable IDs in DBT,I'm creating a table for managing custoemrs between different locations and uniting their profiles at various outlets for an employer. I've been doing more modelling in my career than ETL stuff. I know SQL pretty well but I'm struggling a bit to set up the DBT table in a way where it can both update daily AND maintain stable IDs. It overrights them. We can set up github actions but I'm not really sure what would be the appropriate way to solve this issue.,user_a061074f,8,0.9,8,2025-10-22 10:09:01,https://www.reddit.com/r/datascience/comments/1ode6j8/create_stable_ids_in_dbt/,https://www.reddit.com/r/datascience/comments/1ode6j8/create_stable_ids_in_dbt/,True,Tools,self.datascience,datascience,False,False
1ocenxj,Erdos: open-source IDE for data science,"After a few months of work, we’re excited to launch [Erdos](https://www.lotas.ai/erdos) \- a secure, AI-powered data science IDE, all open source! Some reasons you might use it over VS Code: * An AI that searches, reads, and writes all common data science file formats, with special optimizations for editing Jupyter notebooks * Built-in Python, R, and Julia consoles accessible to the user and AI * Single-click sign in to a secure, zero data retention backend; or users can bring their own keys * Plots pane with plots history organized by file and time * Help pane for Python, R, and Julia documentation * Database pane for connecting to SQL and FTP databases and manipulating data * Environment pane for managing in-memory variables, python environments, and Python, R, and Julia packages * Open source with AGPLv3 license Unlike other AI IDEs built for software development, Erdos is built specifically for data scientists based on what we as data scientists wanted. We'd love if you try it out at [https://www.lotas.ai/erdos](https://www.lotas.ai/erdos)",user_f77fd08f,319,0.97,69,2025-10-21 07:36:08,https://i.redd.it/0m7tebv67hwf1.png,https://www.reddit.com/r/datascience/comments/1ocenxj/erdos_opensource_ide_for_data_science/,False,Projects,i.redd.it,datascience,False,False
1obvzq9,Feeling like I’m falling behind on industry standards,"I currently work as a data scientist at a large U.S. bank, making around $182K. The compensation is solid, but I’m starting to feel like my technical growth is being stunted. A lot of our codebase is still in SAS (which I struggle to use), though we’re slowly transitioning to Python. We don’t use version control, LLMs, NLP, or APIs — most of the work is done in Jupyter notebooks. The modeling is limited to logistic and linear regressions, and collaboration happens mostly through email or shared notebook links. I’m concerned that staying here long-term will limit my exposure to more modern tools, frameworks, and practices — and that this could hurt my job prospects down the road. What would you recommend I focus on learning in my free time to stay competitive and become a stronger candidate for more technically advanced data science roles?",user_0a682229,250,0.94,80,2025-10-20 15:32:31,https://www.reddit.com/r/datascience/comments/1obvzq9/feeling_like_im_falling_behind_on_industry/,https://www.reddit.com/r/datascience/comments/1obvzq9/feeling_like_im_falling_behind_on_industry/,True,Discussion,self.datascience,datascience,False,False
1obr0ve,How many peoples' days were upset by this today?,,user_662c7639,391,0.97,30,2025-10-20 12:22:58,https://i.redd.it/0fi89gqthbwf1.png,https://www.reddit.com/r/datascience/comments/1obr0ve/how_many_peoples_days_were_upset_by_this_today/,False,Monday Meme,i.redd.it,datascience,False,False
1obn0tc,Communities / forums / resources for building neural networks,"Hoping to compile a list of resources / communities that are specifically geared towards training large neural networks. Discussions / details around architecture, embedding strategies, optimization, etc are along the lines of what I’m looking for.",user_5528d4c4,5,0.86,4,2025-10-20 09:29:37,https://www.reddit.com/r/datascience/comments/1obn0tc/communities_forums_resources_for_building_neural/,https://www.reddit.com/r/datascience/comments/1obn0tc/communities_forums_resources_for_building_neural/,True,Discussion,self.datascience,datascience,False,False
1oc8xij,Do we still need Awesome lists now that we have LLMs like ChatGPT?,"Hi folks! Let's talk about Awesome lists (curated collections of resources and tools) and what's happening to them now with LLMs like ChatGPT and Claude around. I'm constantly impressed by how quickly LLMs can generate answers and surface obscure tools, but I also deeply respect the human-curated, battle-tested reliability of a good Awesome list. Let me be clear: I'm not saying they're obsolete. I genuinely value the curation and reliability they offer, which LLMs often lack. So, I'm genuinely curious about the community's take on this. * In the era of LLMs, are traditional Awesome lists becoming less critical, or do they hold a new kind of value? * Do you still actually browse them to discover new stuff, or do you mostly rely on LLMs now? * How good are LLMs really when you don’t exactly know what you’re looking for? Are you happy with what they recommend? * What's your biggest frustration or limitation with traditional Awesome lists?",user_2ef378aa,0,0.31,20,2025-10-21 03:05:10,https://www.reddit.com/r/datascience/comments/1oc8xij/do_we_still_need_awesome_lists_now_that_we_have/,https://www.reddit.com/r/datascience/comments/1oc8xij/do_we_still_need_awesome_lists_now_that_we_have/,True,Discussion,self.datascience,datascience,False,False
1oba336,"Weekly Entering & Transitioning - Thread 20 Oct, 2025 - 27 Oct, 2025","Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include: * Learning resources (e.g. books, tutorials, videos) * Traditional education (e.g. schools, degrees, electives) * Alternative education (e.g. online courses, bootcamps) * Job search questions (e.g. resumes, applying, career prospects) * Elementary questions (e.g. where to start, what next) While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",user_ac31a110,24,0.89,21,2025-10-19 21:01:46,https://www.reddit.com/r/datascience/comments/1oba336/weekly_entering_transitioning_thread_20_oct_2025/,https://www.reddit.com/r/datascience/comments/1oba336/weekly_entering_transitioning_thread_20_oct_2025/,True,,self.datascience,datascience,False,False
1obad7k,"How to perform synthetic control for multiple treated units? What are the things to keep in mind while performing it? Also, what python package i could use? Also have questions about metrics","Hi I have never done Synthetic control, i want to work on a small project (like small data. My task is to find incremental effect), i have a few treatment units, have multiple units as a control (which includes some as major/anchor markets). So questions are below: 1. I know basic understanding of SCM but never used it, i know you get to optimize control units for a single treatment unit, but how do you perform the test when you have multiple treatments units? Do you build synthetic for each units? If yes, do you use all control units for each treatment units? Then that means hace to do same steps multiple times? 2. How do you use anchor markets? Like do you give them more weights from initial or do we need to do something about their data before doing the performance? 3. How do you do placebo tests? Do we take a control unit then find synthetic control units? And in this synthetic do we include treatment units as well (I assume no, but still wanted to confirm) 4. Lets say we want to check incremental for x metrics, do we do the whole process x times differently for each metric? Or once we have done it for one metric we can use the same synthetics for other metrics? (Lets say basic metrics like revenue, conversion, ctr) 5. Which python package do we use if there is resource on it would be great 6. Am i missing any steps or things you believe i should be keep in mind? Thanks! Would be great help",user_d2481f01,9,0.91,4,2025-10-19 21:17:03,https://www.reddit.com/r/datascience/comments/1obad7k/how_to_perform_synthetic_control_for_multiple/,https://www.reddit.com/r/datascience/comments/1obad7k/how_to_perform_synthetic_control_for_multiple/,True,Discussion,self.datascience,datascience,False,False
1oa93fw,Anyone else tired of the non-stop LLM hype in personal and/or professional life?,"I have a complex relationship with LLMs. At work, I'm told they're the best thing since the invention of the internet, electricity, or \[insert other trite comparison here\], and that I'll lose my job to people who do use them if I won't (I know I won't lose my job). Yes, standard ""there are some amazing use cases, like the breast cancer imaging diagnostics"" applies, and I think it's good for those like senior leaders where ""close enough"" is all they need. Yet, on the front line in a regulated industry where ""close enough"" doesn't cut it, what I see on a daily basis are models that: (a) can't be trained on our data for legal and regulatory reasons and so have little to no context with which to help me in my role. Even if they could be trained on our company's data, most of the documentation - if it even exists to begin with - is wrong and out of date. (b) are suddenly getting worse (looking at you, Claude) at coding help, largely failing at context memory in things as basic as a SQL script - it will make up the names to tables and fields that have clearly, explicitly been written out just a few lines before. Yes they can help create frameworks that I can then patch up, but I do notice degradation in performance. (c) always manage to get \*something\* wrong, making my job part LLM babysitter. For example, my boss will use Teams transcribe for our 1:1s and sends me the AI recap after. I have to sift through because it always creates action items that were never discussed, or quotes me saying things that were never said in the meeting by anyone. One time, it just used a completely different name for me throughout the recap. Having seen how the proverbial sausage is made, I have no desire to use it in my personal life, because why would I use it for anything with any actual stakes? And for the remainder, Google gets me by just fine for things like ""Who played the Sheriff in Blazing Saddles?"" Anyone else feel this way, or have a weird relationship with the technology that is, for better or worse, ""transforming"" our field? Update: some folks are leaving short, one sentence responses to the effect of ""They've only been great for me."" Good! Tell us more about how you're finding success in your applications. any frustrations along the way? let's have a CONVERSATION.",user_183a349d,563,0.96,152,2025-10-18 15:16:40,https://www.reddit.com/r/datascience/comments/1oa93fw/anyone_else_tired_of_the_nonstop_llm_hype_in/,https://www.reddit.com/r/datascience/comments/1oa93fw/anyone_else_tired_of_the_nonstop_llm_hype_in/,True,Discussion,self.datascience,datascience,False,False
1oana21,I built a project and I thought I might share it with the group,"Disclaimer: It's UK focused. Hi everyone, When I was looking to buy a house, a big annoyance I had was that I couldn’t easily tell if I was getting value for money. Although, in my opinion, any property is expensive as fuck, I knew that definitely some are more expensive than they should be, always within context. At the time, what I did was manually extract historical data for the street and for the property I was interested in, in an attempt to understand whether it was going for more than the street average or less, and why. It wasn’t my best analysis, but it did the job. Fast forward a few years later, I found myself unemployed and started building projects for my portfolio, which brings us to this post. I’ve built an app that, for a given postcode, gives you historical prices, price per m², and year-on-year sales for the neighbourhood, the area, and the local authority the property falls under, as well as a property price estimation summary. There are, of course, some caveats. Since I’m only using publicly available data, the historical trends are always going to be 2–3 months behind. However, there’s still the capacity to see overall trends e.g. an area might be up and coming if the trendline is converging toward the local authority’s average. As for the property valuation bits, although I’d say it’s as good as what’s available out there, I’ve found that at the end of the day, property prices are pretty much defined by the price of the most recent, closest property sold. Finally, this is a portfolio project, not a product but since I’m planning to maintain it, I thought I might as well share it with people, get some feedback, and maybe even make it a useful tool for some. As for what's going on under the hood. The system is organized into three modules: WH, ML, and App. Each month, the WH (Warehouse) module ingests data into BigQuery, where it’s transformed following a medallion architecture. The ML module is then retrained on the latest data, and the resulting inference outputs are stored in the gold layer of BigQuery. The App module, hosted on a Lightsail instance, loads the updated gold-layer inference and analytics data after each monthly iteration. Within the app, DuckDB is used to locally query and serve this data for fast, efficient access. Anyway, here’s the link if you want to play around: [https://propertyanalytics.uk](https://propertyanalytics.uk) Note: It currently covers England and Wales, only. https://preview.redd.it/s220a3z702wf1.png?width=566&format=png&auto=webp&s=1999caa45801a0ab216fa63e2de09cc9c6dfafaf",user_a63b5984,43,0.88,13,2025-10-19 04:28:42,https://www.reddit.com/r/datascience/comments/1oana21/i_built_a_project_and_i_thought_i_might_share_it/,https://www.reddit.com/r/datascience/comments/1oana21/i_built_a_project_and_i_thought_i_might_share_it/,True,Analysis,self.datascience,datascience,False,False
1oa6dn1,"Transformers, Time Series, and the Myth of Permutation Invariance","There's a common misconception in ML/DL that *Transformers shouldn’t be used for forecasting because attention is permutation-invariant.* Latest evidence shows the opposite, such as Google's latest model, where the experiments show the model performs just as well with or without positional embeddings. You can find an analysis on tis topic [here](https://aihorizonforecast.substack.com/p/transformers-time-series-and-the).",user_1ba2e41a,26,0.9,6,2025-10-18 13:26:40,https://www.reddit.com/r/datascience/comments/1oa6dn1/transformers_time_series_and_the_myth_of/,https://www.reddit.com/r/datascience/comments/1oa6dn1/transformers_time_series_and_the_myth_of/,True,Analysis,self.datascience,datascience,False,False
1o9urrk,Adversarial relation of success and ethics,"I’ve been data scientist for four years and I feel we often balance on a verge of cost efficiency, because how expensive the truths are to learn. Arguably, I feel like there are three types of data investigations: trivial ones, almost impossible ones, and randomized controlled experiments. The trivial ones are making a plot of a silly KPI, the impossible ones are getting actionable insights from real-world data. Random studies are the one thing in which I (still) trust. That’s why I feel like most of my job is being pain in someone’s ass, finding data flaws, counterfactuals, and all sorts of reasons why whatever stakeholders want is impossible or very expensive to get. Sometimes Im afraid that data science is just not cost effective. And worse, sometimes I feel like I’d be a more successful (paid better) data scientist if I did more of meaningless and shallow data astrology, just reinforcing the stakeholders that their ideas are good - because given the reality of data completeness and quality, there’s no way for me to tell it. Or announcing that I found an area for improvement, deliberately ignoring boring, alternative explanations. And honestly - I think that no one would ever learn what I did. If you feel similarly, take care! I hope you too occasionally still get a high from rare moments of scientific and statistical purity we can sometimes find in our job.",user_df76f0af,18,0.83,13,2025-10-18 05:42:37,https://www.reddit.com/r/datascience/comments/1o9urrk/adversarial_relation_of_success_and_ethics/,https://www.reddit.com/r/datascience/comments/1o9urrk/adversarial_relation_of_success_and_ethics/,True,Discussion,self.datascience,datascience,False,False
1o93utr,"Causal Data Scientists, what resources helped you the most?","Hello everyone, I am working on improving in areas of Bayesian and Frequentists A/B testings and Causal Inference, and applying them in industry. I am currently working on normal Frequentists A/B testings, and simple Causal Inference but want to expand to more nuanced cases and have some examples of what they may look like. For example, when to choose TMLE over Propensity Score Matching etc or Bayesian vs Frequentists. Please let me know if theres any resources that helped you apply these methods in your job.",user_c7e1342a,117,0.95,23,2025-10-17 08:07:16,https://www.reddit.com/r/datascience/comments/1o93utr/causal_data_scientists_what_resources_helped_you/,https://www.reddit.com/r/datascience/comments/1o93utr/causal_data_scientists_what_resources_helped_you/,True,Discussion,self.datascience,datascience,False,False
1o8ipwa,Would you move from DS to BI/DA/DE for a salary increase?,"I’m a DS but salary is below average. Getting recruiters reaching out for other data roles though because my experience is broad. Sometimes these roles start at ~$40k over what I’m making now, and even over other open DS roles I see on LinkedIn in my area for my yoe. The issue is I love DS work, and don’t want to make it super difficult to get future DS jobs. But I also wouldn’t mind working in another data role for a bit to get that money though. What are everyone’s thoughts on this? Would you leave DS for more money?",user_29394f18,60,0.86,43,2025-10-16 14:23:15,https://www.reddit.com/r/datascience/comments/1o8ipwa/would_you_move_from_ds_to_bidade_for_a_salary/,https://www.reddit.com/r/datascience/comments/1o8ipwa/would_you_move_from_ds_to_bidade_for_a_salary/,True,Discussion,self.datascience,datascience,False,False
1o8p6f0,Where to find actual resources and templates for data management that aren't just blog posts?,"[](https://www.reddit.com/r/analytics/?f=flair_name%3A%22Question%22)I'm early in my career, and I've been tasked with a lot of data management and governance work, building SOPs and policies, things like that, for the first time. Everytime I try to research the best templates, guides, documents, spreadsheets, mindmaps, etc., all I get are the annoying generic blog posts that companies use for SEO, like [this](https://www.datamation.com/big-data/data-management-best-practices/). They say ""You should document everything"" but don't actually offer templates on how! I want to avoid reinventing the wheel, especially since I'm new to this side of data work. Does anyone know of a good public resources to find guides, templates, spreadsheets, etc., for documentation, data management, SOPs, things like that instead of just the long blog posts that are littering the internet",user_fdd5bc39,7,0.73,9,2025-10-16 19:11:53,https://www.reddit.com/r/datascience/comments/1o8p6f0/where_to_find_actual_resources_and_templates_for/,https://www.reddit.com/r/datascience/comments/1o8p6f0/where_to_find_actual_resources_and_templates_for/,True,Discussion,self.datascience,datascience,False,False
1o8bkbt,What computer do you use for personal projects?,"I’m trying to branch out and do more personal projects for my portfolio. My personal computer is pretty old, and I’m reluctant to use my work computer for my personal projects, so I’m curious about what kinds of computers you all use.",user_dcc3e61b,32,0.88,41,2025-10-16 09:54:57,https://www.reddit.com/r/datascience/comments/1o8bkbt/what_computer_do_you_use_for_personal_projects/,https://www.reddit.com/r/datascience/comments/1o8bkbt/what_computer_do_you_use_for_personal_projects/,True,Discussion,self.datascience,datascience,False,False
1o7a0rk,Completely Free Courses Oct 20-30 from Maven Analytics,"Maven Analytics is hosting their Open Campus event Oct 20-30. This means their whole platform is 100% free during that time. If you've been thinking about taking a course on Power BI, SQL, Python, how to approach the job search, etc., it would be a great time to binge and learn something new. There's also live sessions for these two weeks around portfolio projects, interviewing, etc. And they all have Q&A at the end, so you can ask any of the questions you have around getting into data.",user_dbcdec76,39,0.92,13,2025-10-15 05:46:29,https://mavenanalytics.io/open-campus,https://www.reddit.com/r/datascience/comments/1o7a0rk/completely_free_courses_oct_2030_from_maven/,False,Discussion,mavenanalytics.io,datascience,False,False
1o6f3l8,AutoML: Yay or nay?,"Hello data scientists and adjacent, I'm at a large company which is taking an interest in moving away from the traditional ML approach of training models ourselves to using AutoML. I have limited experience in it (except an intuition that it is likely to be less powerful in terms of explainability and debugging) and I was wondering what you guys think. Has anyone had experience with both ""custom"" modelling pipelines and using AutoML (specifically the GCP product)? What were the pros and cons? Do you think one is better than the other for specific use cases? Thanks :)",user_91eb1b92,38,0.91,31,2025-10-14 06:10:50,https://www.reddit.com/r/datascience/comments/1o6f3l8/automl_yay_or_nay/,https://www.reddit.com/r/datascience/comments/1o6f3l8/automl_yay_or_nay/,True,Discussion,self.datascience,datascience,False,False
1o5nvkp,"AI Is Overhyped as a Job Killer, Says Google Cloud CEO",,user_e6f6eb17,451,0.95,84,2025-10-13 09:05:20,https://www.interviewquery.com/p/ai-job-killer-google-cloud-ceo,https://www.reddit.com/r/datascience/comments/1o5nvkp/ai_is_overhyped_as_a_job_killer_says_google_cloud/,False,Discussion,interviewquery.com,datascience,False,False
1o64n48,Has anyone switched to AI Product Management from Data Science?,"I've been a DS for almost 5 years, with a good majority in NLP. I've been wanting to do more POCs, less model production (IT budget, stack ranking, general burn-out) and get into Product Management for a while. I know the technology quite well, but I lack PM experience. Honestly, I'm pretty burnt out from DS. I really like working with cross-functional teams and focusing on strategy/business more so than coding. I tend to mainly do that these days during the day, then have to code at night and it's gotten exhausting. And coming into the office with all of that... not sustainable. I'd love to know your journey and what made you stand out when making the switch!",user_08df9aa8,43,0.83,23,2025-10-13 20:18:13,https://www.reddit.com/r/datascience/comments/1o64n48/has_anyone_switched_to_ai_product_management_from/,https://www.reddit.com/r/datascience/comments/1o64n48/has_anyone_switched_to_ai_product_management_from/,True,Discussion,self.datascience,datascience,False,False
1o68gf8,Deep Learning Topics: How Important Are They?,"Background: I have a BS double major in Data Analytics and Information Systems: Data Engineering emphasis. I’m currently pursuing an MS in Data Analytics with a Statistics emphasis, plus graduate certificates in ML/AI and Data Science. I enjoy: • Classical ML and statistics (regression, tree-based models, etc.) • A/B testing and experimentation design • Forecasting and time-series analysis • Causal inference • SQL and Python (leveraging libraries for applied work rather than building from scratch) What I’m less interested in: • Deep learning, computer vision, NLP • Heavy dashboard work (I can build functional dashboards but lack the design eye for making them actually look good) My question is: To work as a Data Scientist, do I need to dive deeper into neural networks, transformers, and other deep learning topics? I don’t want to get stuck doing dashboards all day as a “Data Analyst,” but I also don’t see myself doing deep learning research or building production models for image/text applications. Is there space in the industry for data scientists who specialize in classical ML, experimentation, and statistical modeling, or does the field increasingly expect everyone to know deep learning inside out?",user_fbc1579b,20,0.83,20,2025-10-13 23:54:27,https://www.reddit.com/r/datascience/comments/1o68gf8/deep_learning_topics_how_important_are_they/,https://www.reddit.com/r/datascience/comments/1o68gf8/deep_learning_topics_how_important_are_they/,True,Discussion,self.datascience,datascience,False,False
1o6tquy,Would you recommend starting new agentic projects with Typescript instead of Python?,I read somewhere that something like 60%-75% of YC-backed startups that are building agents are using Typescript. I've also heard that Typescript's native type system is very helpful for building AI apps. Is Typescript a better language than Python for building AI agents? I don't planning on training my own models so I am not sure if Python is really necessary in my case.,user_71edf8bc,0,0.31,16,2025-10-14 15:22:59,https://www.reddit.com/r/datascience/comments/1o6tquy/would_you_recommend_starting_new_agentic_projects/,https://www.reddit.com/r/datascience/comments/1o6tquy/would_you_recommend_starting_new_agentic_projects/,True,Discussion,self.datascience,datascience,False,False
1o5l0g8,Starting my Freelance Journey,"I am a Data Scientist and am going to be moving from London to Amsterdam next year. I wanted to start freelancing to cover any unemployment period. On fiverr, I see a saturated Data Science space with hundreds of people offering quite similar expertise. On Upwork I realise you need to pay to Connect with project offerings (which sort of makes sense to me to avoid spam for the offerers), which makes me hesitant to start. I’m just wondering, with where GenAI is right now, is there actually opportunity to start freelancing now or are there still ample opportunities out there? Are people still quite freely doing this as a side hustle?",user_6c2a2261,35,0.84,28,2025-10-13 07:20:02,https://www.reddit.com/r/datascience/comments/1o5l0g8/starting_my_freelance_journey/,https://www.reddit.com/r/datascience/comments/1o5l0g8/starting_my_freelance_journey/,True,Discussion,self.datascience,datascience,False,False
1o5n86i,"In production, how do you evaluate the quality of the response generated by a RAG system?","I am working on a use case where I need to get the right answer and send it to the user. I have been struggling for a time to find a reliable metric to use that tells me when an answer is correct. The cost of a **false positive** is very high; there is a huge risk in sending an incorrect answer to the user. I have been spending most of my time trying to find which metric to use to evaluate the answer. Here is what I have tried so far: * I have checked the perplexity or the average log probability of the generated tokens, but it is only consistent when the model cannot find the answer in the provided chunks. The way my prompt is **designed**, in this case, the model returns, ""I cannot find the answer in the provided context\*\*,\*\*"" and that is a good signal when I cannot find the **answer**. * However, when the model is hallucinating an answer based on the provided tokens, it is very confident and returns a high perplexity / average token probability. * I have tried to use the cosine **similarity** between the question and the embeddings. It is okay when the model cannot find the correct chunks; the similarity is low, and for those, I am certain that the answer will be incorrect. But sometimes, the embedding models have some flaws. * I have tried to create a **metric** that is a weighted average of the average cosine **similarity** and the average token probability; it seems to work, but not quite well. * I cannot use an LLM as a judge. I don't think it **works** or is reliable, and the stakeholders do not trust the whole concept of judging the output of an LLM with another LLM. * I am in the process of getting **samples** of questions and answers labelled by **humans** who answer these questions in practice to see which metric will **correlate** with the human answer. **Other information:** For now, I am only working with 164 **samples** of **questions**. Is this good enough? The **business** is planning on providing us with more questions to test the system. The workflow I am suggesting for production is this: 1. Get the question. 2. If the average cosine **similarity** between the question and the chunks is low, route the question to an agent because we cannot find the answer. 3. If it is high, we send it to the LLM and prompt it to generate an **answer** based on the context. If the LLM cannot find the answer in the provided context, send it to the agent. 4. If it **says** it can find the answer, **generate** the answer and the reference. Check the average distance and the average token probability; if it is low, send it to the agent. 5. Now, if the answer is there, there are enough references, and the **weighted** average of the token probability is high, send the answer to the user. How do you think about this approach? What are other **ways** I can do better in order to evaluate and increase the number of answers I am sending to the user? For those who have worked with RAG in production, how do you handle this type of problem? How do you quantify the **business** impact of **such a** system? I think if I manage to **answer** 50% of the users' queries correctly and the other 50% of queries go to an agent, the system **reduces** the workload of the agent by 50%. But my boss is saying that it is not a good system if it is just 50% accurate, and **sometimes** the agents will stop using it in production. Is that true?",user_49858ac5,19,0.88,18,2025-10-13 08:41:41,https://www.reddit.com/r/datascience/comments/1o5n86i/in_production_how_do_you_evaluate_the_quality_of/,https://www.reddit.com/r/datascience/comments/1o5n86i/in_production_how_do_you_evaluate_the_quality_of/,True,Discussion,self.datascience,datascience,False,False
1o5pg14,Fivetran and dbt,They seem to be merging? Thoughts on this please. How does this shakeup the landscape if at all?,user_583485e7,4,0.6,2,2025-10-13 10:01:04,https://i.redd.it/5ycpvlt9uwuf1.jpeg,https://www.reddit.com/r/datascience/comments/1o5pg14/fivetran_and_dbt/,False,Discussion,i.redd.it,datascience,False,False
1o59o2w,"Weekly Entering & Transitioning - Thread 13 Oct, 2025 - 20 Oct, 2025","Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include: * Learning resources (e.g. books, tutorials, videos) * Traditional education (e.g. schools, degrees, electives) * Alternative education (e.g. online courses, bootcamps) * Job search questions (e.g. resumes, applying, career prospects) * Elementary questions (e.g. where to start, what next) While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",user_ac31a110,11,1.0,11,2025-10-12 21:01:10,https://www.reddit.com/r/datascience/comments/1o59o2w/weekly_entering_transitioning_thread_13_oct_2025/,https://www.reddit.com/r/datascience/comments/1o59o2w/weekly_entering_transitioning_thread_13_oct_2025/,True,,self.datascience,datascience,False,False
1o2nf09,What should I ask my potential managers when choosing between two jobs?,"I’m deciding between two mid-level data science offers at large tech companies. These are more applied scientist type of roles than analytics. Comp and level are similar, so I’m really trying to figure out which one will set me up for a stronger career in the long run. This will be my first true DS role (coming from a technical background, PhD + previous R&D role). I want to do interesting, high-impact work that keeps doors open possibly toward more research-type paths down the line but I also care a lot about working under a manager who can actually help me grow and foster a good career trajectory. For those who’ve been in big-tech DS roles, what should I be asking or paying attention to when talking to the managers or teams to tell which role will offer better career growth, mentorship, and long-term options? Would love any advice or signals I should be looking for.",user_44eab812,28,0.87,16,2025-10-09 18:09:14,https://www.reddit.com/r/datascience/comments/1o2nf09/what_should_i_ask_my_potential_managers_when/,https://www.reddit.com/r/datascience/comments/1o2nf09/what_should_i_ask_my_potential_managers_when/,True,Career | US,self.datascience,datascience,False,False
1o0eed8,"Resources for Data Science & Analysis: A curated list of roadmaps, tutorials, Python libraries, SQL, ML/AI, data visualization, statistics, cheatsheets","Hello everyone! Staying on top of the constantly growing skill requirements in Data Science is quite a challenge. To manage my own learning and growth, I've been curating a list of useful resources and tools that cover the full spectrum of the field — from data analysis and engineering to deep learning and AI. I'd love to get your professional opinion. Could you please take a look? Have I missed anything crucial? What else would you recommend adding or focusing on? To give you an immediate sense of the list's scope and structure, I've attached screenshots of the table of contents below. The full version with all the active links and additional resources is available on GitHub. You can find the link at the end of the post. https://preview.redd.it/egbe8jmruotf1.png?width=890&format=png&auto=webp&s=0256f4ea30e7843bca8e77545ea46cc5ba25b72c https://preview.redd.it/3vq4pm8k1evf1.png?width=882&format=png&auto=webp&s=1dcdbb6f9188535ae872bc40b77ede45833a6d4f I'd be happy if this list is useful to others. You can view the full list here [View on GitHub](https://github.com/PavelGrigoryevDS/awesome-data-analysis?#awesome-data-analysis-) Thanks for your time! Your advice is invaluable!",user_2ef378aa,291,0.99,82,2025-10-07 06:12:23,https://www.reddit.com/r/datascience/comments/1o0eed8/resources_for_data_science_analysis_a_curated/,https://www.reddit.com/r/datascience/comments/1o0eed8/resources_for_data_science_analysis_a_curated/,True,Discussion,self.datascience,datascience,False,False
1nzfr4k,"Exploratory analysis of 12 frontier LLM's across 100s of hours shows o3 highest Type-Token Ratio (Lexical Diversity), GPT-5 most formal language, and GPT-4o most positive sentiment","I recently ran exploratory analysis on the group chat of the [AI Village](https://theaidigest.org/village): 4+ frontier LLMs all have their own computer, access to the internet, and a group chat, and then get set goals like [raise money](https://theaidigest.org/village/blog/season-recap-agents-raise-2k) for charity, [sell T-shirts](https://theaidigest.org/village/blog/im-gemini-i-sold-t-shirts), or debate ethics. The goal is to build some awareness around what models are capable of now. I took the 200+ hours of group chat between the models and ran some exploratory analyses. Turns out: \- o3 has the highest Type-Token Ratio, even higher than GPT-5! o3 is also the model that wins at [diplomacy](https://every.to/diplomacy) against other agents, and won at AI debate in the AI Village. \- GPT-5 uses the fewest contractions, writes the longest sentences, and uses the least slang/filler. I'm thinking about this as ""most formal"" but maybe it's something else? \- GPT-4o had the highest positive sentiment scores in the Village and is also known as the most sycophantic model I enjoyed analyzing the data and would love to do more. Any tips on what to look at? I might be able to share the data if people are interested. Feel free to send me a DM and we can see what's possible :)",user_29d10aa3,30,0.87,7,2025-10-06 03:52:19,https://theaidigest.org/village/blog/village-in-numbers,https://www.reddit.com/r/datascience/comments/1nzfr4k/exploratory_analysis_of_12_frontier_llms_across/,False,Analysis,theaidigest.org,datascience,False,False
1nz94dg,"Weekly Entering & Transitioning - Thread 06 Oct, 2025 - 13 Oct, 2025","Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include: * Learning resources (e.g. books, tutorials, videos) * Traditional education (e.g. schools, degrees, electives) * Alternative education (e.g. online courses, bootcamps) * Job search questions (e.g. resumes, applying, career prospects) * Elementary questions (e.g. where to start, what next) While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",user_ac31a110,7,0.78,23,2025-10-05 21:01:39,https://www.reddit.com/r/datascience/comments/1nz94dg/weekly_entering_transitioning_thread_06_oct_2025/,https://www.reddit.com/r/datascience/comments/1nz94dg/weekly_entering_transitioning_thread_06_oct_2025/,True,,self.datascience,datascience,False,False
1nyp1uw,Why am I not getting responses?,"As mentioned before, I can't use the weekly transition because it doesn't allow pictures. I appreciate your help last time when I asked. I've implemented your recommendations but I'm still not getting responses. I've added a completely new ML-based project, fixed mistakes, revamped the layout and I'm still not getting anything. I appreciate your attention. https://preview.redd.it/u7bbf3q5vatf1.png?width=666&format=png&auto=webp&s=8d6983cb5e8713b1b8b736f95b916ee52fb0dc21",user_f4634b41,24,0.71,83,2025-10-05 07:03:09,https://www.reddit.com/r/datascience/comments/1nyp1uw/why_am_i_not_getting_responses/,https://www.reddit.com/r/datascience/comments/1nyp1uw/why_am_i_not_getting_responses/,True,Discussion,self.datascience,datascience,False,False
1nxrrcw,What could be my next career progression?,"Hello, I'm 26 years old been working as a junior data scientist in marketing for the past two years and I'm a bit bored/ have no idea how to progress further in my career. Currently I do end to end modeling, from gathering data up to production (not in the most data sciency way since I'm very limited in terms of tools but my models are being effectively used by other departments). I have built 5 different models: propensity score models, customer segmentation, churn models and a time series forecasting model. All my job has been revolving around developing, validating, monitoring and updating these models I have built with the current tools I have available. I realise I'm already privileged in terms of what I'm doing. It's my first job and already developing models end to end in a company that recognises their usefulness and I'm pretty much free to take any decision about them. However, I would love to advance further since the my job is starting to get a bit repetitive. In terms of innovating further my workflow I realised it's actually pretty much impossible. The company IT is stagnant and any time I asked for anything, like introducing MlFlow in my sagemaker flow (YES, from development to ""production"" is done in sagemaker using notebooks. I understand and have faced many of the problems that come out of this) or Airflow or anything else, the request has never gotten anywhere. The size of the company and the IT privileges setup makes it impossible for me to take the innovation in my own hands and do as I please. I've tried lots of technical workarounds and loopholes but not very successfully. I don't feel confident enough now take a more senior position, nor there is the possibility at my current job. My boss is not directly involved in modeling stuff and don't really have anyone I can go to with career progression questions. I feel like I kinda already reached the end of progression and I'm pretty much lost in terms of what I can do, other than ask for various tools to make the pipeline up to current standards (which will not have an impact in terms of how the output will be used by other departments and profits). I understand it's an open ended question, but what else could I do to advance?",user_0800cecd,57,0.94,49,2025-10-04 04:43:06,https://www.reddit.com/r/datascience/comments/1nxrrcw/what_could_be_my_next_career_progression/,https://www.reddit.com/r/datascience/comments/1nxrrcw/what_could_be_my_next_career_progression/,True,Discussion,self.datascience,datascience,False,False
1nxqln5,Do you know interesting datasets for kriging?,"Hi guys, I need to do a project using many linear models and I’m looking for a dataset. Ideally something interesting with lots of numerical variables, especially one where kriging could be applied. If you have any dataset suggestions or interesting research questions I could build the project around, I’d really appreciate it. Thanks a lot! PS: i did not like chatgpt suggestions, they were cliche (even if i explicitly asked “not cliche”)",user_b7a887ca,6,0.72,10,2025-10-04 03:38:16,https://www.reddit.com/r/datascience/comments/1nxqln5/do_you_know_interesting_datasets_for_kriging/,https://www.reddit.com/r/datascience/comments/1nxqln5/do_you_know_interesting_datasets_for_kriging/,True,Projects,self.datascience,datascience,False,False
1nwh00i,Are LLMs necessary to get a job?,"For someone laid off in 2023 before the LLM/Agent craze went mainstream, do you think I need to learn LLM architecture? Are certs or github projects worth anything as far as getting through the filters and/or landing a job? I have 10 YOE. I specialized in machine learning at the start, but the last 5 years of employment, I was at a FAANG company and didnt directly own any ML stuff. It seems ""traditional"" ML demand, especially without LLM knowledge, is almost zero. I've had some interviews for roles focused on experimentation, but no offers. I can't tell whether my previous experience is irrelevant now. I deployed ""deep"" learning pipelines with basic MLOps. I did a lot of predictive analytics, segmentation, and data exploration with ML. I understand the landscape and tech OK, but it seems like every job description now says you need direct experience with agentic frameworks, developing/optimizing/tuning LLMs, and using orchestration frameworks or advanced MLOps. I don't see how DS could have changed enough in two years that every candidate has on-the-job experience with this now. It seems like actually getting confident with the full stack/architecture would take a 6 month course or cert. Ive tried shorter trainings and free content... and it seems like everyone is just learning ""prompt engineering,"" basic RAG with agents, and building chatbots without investigating the underlying architecture at all. Are the job descriptions misrepresenting the level of skill needed or am I just out of the loop?",user_2fbfc9cf,81,0.83,66,2025-10-02 14:43:00,https://www.reddit.com/r/datascience/comments/1nwh00i/are_llms_necessary_to_get_a_job/,https://www.reddit.com/r/datascience/comments/1nwh00i/are_llms_necessary_to_get_a_job/,True,Career | US,self.datascience,datascience,False,False
1nvduc2,Fun Interview with Jason Strimpel about transferable skills from data science to algorithmic trading.,"I had the opportunity to interview Jason Strimpel. He's been in trading and technology for 25 years as a hedge fund trader, risk quant, machine learning engineering manager, and GenAI specialist at AWS. He is now the Managing Director of AI and Advanced Analytics at a major consulting company. I asked him all about the transferable skills, the mindset shifts, tools someone should pick up if they're just getting started, how algo trading is similar to ML, and differences in how you think about/work with the data. He had a lot of great tips if you're a data person thinking about getting into trading.",user_dbcdec76,19,0.79,6,2025-10-01 10:00:56,https://www.datamovesme.com/blog/qfe2cds9h37bdmvi8h4a7p0x785ic9,https://www.reddit.com/r/datascience/comments/1nvduc2/fun_interview_with_jason_strimpel_about/,False,Discussion,datamovesme.com,datascience,False,False
1nv0lfh,"For data scientists in insurance and banking, how many data scientists/ML engineers work in your company, how are their teams organised, and roughly what do they work on?",I'm trying to get a better sense of how this is developing in financial services. Anything from insurance/banking or adjacent fields would be most appreciated.,user_ed1b68c5,60,0.91,35,2025-09-30 23:10:41,https://www.reddit.com/r/datascience/comments/1nv0lfh/for_data_scientists_in_insurance_and_banking_how/,https://www.reddit.com/r/datascience/comments/1nv0lfh/for_data_scientists_in_insurance_and_banking_how/,True,Discussion,self.datascience,datascience,False,False
1nucvgd,Weekend Project - Poker Agents Video/Code,"Fun side project. You can configure (almost) any LLM as a player. The main capabilities (tools) each agent can call are: 1) Hand Analysis Get detailed info about current hand and possibilities (straight draws, flush potential, many other things) 2) Monte Carlo Get an estimated win probability if the player continues in the hand (can only be called one time per hand) 3) Opponent Statistics Get metrics about opponent behavior, specifically how aggressive or passively they’ve played It’s not a completely novel - other people have made LLMs play poker. The configurability and the specific callable tools are, to my knowledge, unique. Using it requires an OpenRouter API key. Video: https://youtu.be/1PDo6-tcWfE?si=WR-vgYtmlksKCAm4 Code: https://github.com/OlivierNDO/llm_poker_agents",user_2d170df7,64,0.93,20,2025-09-30 06:13:57,https://i.redd.it/hqdrczgwxasf1.jpeg,https://www.reddit.com/r/datascience/comments/1nucvgd/weekend_project_poker_agents_videocode/,False,Projects,i.redd.it,datascience,False,False
1nurg0y,Distance Correlation & Matrix Association. Good stuff?,,user_39c22258,6,0.87,4,2025-09-30 15:35:09,/r/AskStatistics/comments/1nurfk1/distance_correlation_matrix_association_good_stuff/,https://www.reddit.com/r/datascience/comments/1nurg0y/distance_correlation_matrix_association_good_stuff/,False,Discussion,,datascience,False,False
1ntmrix,This has to be bait right?,recruitment companies posting jobs like this are just setting bait to get resumes so they can push other jobs right?,user_9a1576de,189,0.84,57,2025-09-29 09:31:52,https://i.redd.it/o7gh03w4s4sf1.jpeg,https://www.reddit.com/r/datascience/comments/1ntmrix/this_has_to_be_bait_right/,False,Discussion,i.redd.it,datascience,False,False
1ntlgy5,Career advice,"Hi everyone, I think I need a little general guidance on how to move forward. After working in retail for 11 years, I went back to school in 2020 to do a Bachelor’s in Mathematics and a masters in analytics. I was hoping to become a data scientist upon graduating. Obviously, market conditions have fluctuated substantially since I started. I took a job as a materials planner in electronics manufacturing, with the expectation that my boss was looking for someone that was data minded and would primarily focus on building pipelines and tools to make things run more smoothly. my planning duties would be small while I used my skills to automate and streamline workflows. Up to this point, my job has been about 70 percent coding and “data engineering/analyzing”, 20 percent managing and organizing my projects, and 10 percent actual materials planning. I think my boss made a risky hire. He’s not an IT person, and has not been able to move the needle on giving me the access I need to scale these processes. I found an old reporting tool that is basically SQL that nobody uses: have been able to install VS code on my work laptop, so I have been able to substantially streamline, dashboard, and improve a ton of stuff using Python, “SQL”, and PowerQuery. They pulled my access to the reporting tool: no advance communication. All of my projects are pretty much kaput. I feel like I’ve been lowballed big time. I’m glad to have a job right now, but also I’m in a bit of a predicament. If my job search went on for another 6 months, most employers in actual “data” roles would understand the struggle: and I might even have an actual role in data analytics right now, if I got lucky. But now I am in a position that is a huge departure from what was discussed. No matter the situation, leaving after only 6 months would look terrible one me. It seems like the best thing to do is ride it out, but I’m not sure or for how long I should.",user_68aca4f0,24,0.88,12,2025-09-29 08:43:04,https://www.reddit.com/r/datascience/comments/1ntlgy5/career_advice/,https://www.reddit.com/r/datascience/comments/1ntlgy5/career_advice/,True,Career | US,self.datascience,datascience,False,False
1nt8wl0,What a Drunk Man Can Teach Us About Time Series Forecasting,"**Autocorrelation & The Random Walk explained** with a drunk man 🍺 Let me illustrate this statistical concept with an example we can all visualize. Imagine a drunk man wandering a city. His steps are completely random and unpredictable. **Here's the intuition**: \- His current position is completely tied to his previous position \- We know where he is RIGHT NOW, but have no idea where he'll be in the next minute **The statistical insight**: In a random walk, the *current position* is highly correlated with the *previous position*, but the *changes in position* (the steps) are completely random & uncorrelated. This is why random walks are so tricky to forecast! [Part 2: Time Series Forecasting: Build a Baseline & Understand the Random Walk](https://youtu.be/_Ke54TJqY9s) Would love to hear your **thoughts, feedback** about this topic",user_2ab54590,62,0.78,12,2025-09-28 21:31:25,https://www.reddit.com/r/datascience/comments/1nt8wl0/what_a_drunk_man_can_teach_us_about_time_series/,https://www.reddit.com/r/datascience/comments/1nt8wl0/what_a_drunk_man_can_teach_us_about_time_series/,True,Education,self.datascience,datascience,False,False
1nt6q59,What interesting projects are you working on that are not related to AI?,Share links if possible.,user_345e4f7a,44,0.95,38,2025-09-28 19:34:24,https://www.reddit.com/r/datascience/comments/1nt6q59/what_interesting_projects_are_you_working_on_that/,https://www.reddit.com/r/datascience/comments/1nt6q59/what_interesting_projects_are_you_working_on_that/,True,Projects,self.datascience,datascience,False,False
1nt8d65,"Weekly Entering & Transitioning - Thread 29 Sep, 2025 - 06 Oct, 2025","Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include: * Learning resources (e.g. books, tutorials, videos) * Traditional education (e.g. schools, degrees, electives) * Alternative education (e.g. online courses, bootcamps) * Job search questions (e.g. resumes, applying, career prospects) * Elementary questions (e.g. where to start, what next) While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",user_ac31a110,7,0.83,16,2025-09-28 21:01:23,https://www.reddit.com/r/datascience/comments/1nt8d65/weekly_entering_transitioning_thread_29_sep_2025/,https://www.reddit.com/r/datascience/comments/1nt8d65/weekly_entering_transitioning_thread_29_sep_2025/,True,,self.datascience,datascience,False,False
1nso6sy,Relationship between ROC AUC and Gain curve?,"Heya, I been studying the gains curve, and I’ve noticed there’s a relationship between the gains curve and ROC curve the smaller the base rate the closer is gains curve is to ROC curve. Anyway onto the point, is if fair to assume that for two models if the area under the ROC curve is bigger for model A and then the gains curve will always be better for model A as well? Thanks",user_a63b5984,18,0.95,4,2025-09-28 06:20:54,https://www.reddit.com/r/datascience/comments/1nso6sy/relationship_between_roc_auc_and_gain_curve/,https://www.reddit.com/r/datascience/comments/1nso6sy/relationship_between_roc_auc_and_gain_curve/,True,Statistics,self.datascience,datascience,False,False
1nsxpad,"Oscillatory Coordination in Cognitive Architectures: Old Dog, New Math","Been working in AI since before it was cool (think 80s expert systems, not ChatGPT hype). Lately I've been developing this cognitive architecture called OGI that uses Top-K gating between specialized modules. Works well, proved the stability, got the complexity down to O(k²). But something's been bugging me about the whole approach. The central routing feels... inelegant. Like we're forcing a fundamentally parallel, distributed process through a computational bottleneck. Your brain doesn't have a little scheduler deciding when your visual cortex can talk to your language areas. So I've been diving back into some old neuroscience papers on neural oscillations. Turns out biological neural networks coordinate through phase-locking across different frequency bands - gamma for local binding, theta for memory consolidation, alpha for attention. No central controller needed. The Math That's Getting Me Excited Started modeling cognitive modules as weakly coupled oscillators. Each module i has intrinsic frequency ωᵢ and phase θᵢ(t), with dynamics: θ̇ᵢ = ωᵢ + Σⱼ Aᵢⱼ sin(θⱼ - θᵢ + αᵢⱼ) This is just Kuramoto model with adaptive coupling strengths Aᵢⱼ and phase lags αᵢⱼ that encode computational dependencies. When |ωᵢ - ωⱼ| falls below critical coupling threshold, modules naturally phase-lock and start coordinating. The order parameter R(t) = |Σⱼ e^(iθⱼ)|/N gives you a continuous measure of how synchronized the whole system is. Instead of discrete routing decisions, you get smooth phase relationships that preserve gradient flow. Why This Might Actually Work Three big advantages I'm seeing: Scalability: Communication cost scales with active phase-locked clusters, not total modules. For sparse coupling graphs, this could be near-linear. Robustness: Lyapunov analysis suggests exponential convergence to stable states. System naturally self-corrects. Temporal Multiplexing: Different frequency bands can carry orthogonal information streams without interference. Massive bandwidth increase. The Hard Problems Obviously the devil's in the details. How do you encode actual computational information in phase relationships? How do you learn the coupling matrix A(t)? Probably need some variant of Hebbian plasticity, but the specifics matter. The inverse problem is fascinating though - given desired computational dependencies, what coupling topology produces the right synchronization patterns? Starting to look like optimal transport theory applied to dynamical systems. Bigger Picture Maybe we've been thinking about AI architecture wrong. Instead of discrete computational graphs, what if cognition is fundamentally about temporal organization of information flow? The binding problem, consciousness, unified experience - could all emerge from phase coherence mathematics. I know this sounds hand-wavy, but the math is solid. Kuramoto theory is well-established, neural oscillations are real, and the computational advantages are compelling. Anyone worked on similar problems? Particularly interested in numerical integration schemes for large coupled oscillator networks and learning rules for adaptive coupling. Edit: For those asking about implementation - yes, this requires continuous dynamics instead of discrete updates. Computationally more expensive per step, but potentially fewer steps needed due to natural coordination. Still working out the trade-offs. Edit 2: Getting DMs about biological plausibility. Obviously artificial oscillators don't need to match neural firing rates exactly. The key insight is coordination through phase relationships, not literal biological mimicry. Mike",user_d3312bf3,0,0.43,5,2025-09-28 12:46:58,https://www.reddit.com/r/datascience/comments/1nsxpad/oscillatory_coordination_in_cognitive/,https://www.reddit.com/r/datascience/comments/1nsxpad/oscillatory_coordination_in_cognitive/,True,Projects,self.datascience,datascience,False,False
1nrtluz,"How important is it for a Data Analyst to learn some ML, Data Engineering, and DL?","Hey everyone! I'm a Data Analyst, but I'm really interested in the whole data science world. For my current job, I don't need to be an expert in machine learning, deep learning, or data engineering, but I've been trying to learn the basics anyway. I feel like even a basic understanding helps me out in a few ways: * Better Problem-Solving: It helps me choose the right tool for the job and come up with better solutions. * Deeper Analysis: I can push my analyses further and ask more interesting questions. * Smoother Communication: It makes talking to data scientists and engineers on my team way easier because I kinda ""get"" what they're doing. Plus, I've noticed that just learning one new library or concept makes picking up the next one a lot less intimidating. What do you all think? Should Data Analysts just stick to getting really good at core analytics (SQL, stats, viz), or is there a real advantage to becoming more of a ""T-shaped"" person with a broad base of knowledge? Curious to hear your experiences.",user_2ef378aa,104,0.93,47,2025-09-27 05:09:54,https://www.reddit.com/r/datascience/comments/1nrtluz/how_important_is_it_for_a_data_analyst_to_learn/,https://www.reddit.com/r/datascience/comments/1nrtluz/how_important_is_it_for_a_data_analyst_to_learn/,True,Discussion,self.datascience,datascience,False,False
1nri84g,Anyone noticing an uptick in recruiter outreach?,I’ve had up to 10 recruiters contact me in the last few weeks. Before this I hadn’t heard anything but crickets for years. Anyone else noticing more outreach lately? Note that I’m a US citizen but the outreach starts before the H1B news so I don’t think it’s related to that.,user_38b2c359,88,0.9,55,2025-09-26 18:05:34,https://www.reddit.com/r/datascience/comments/1nri84g/anyone_noticing_an_uptick_in_recruiter_outreach/,https://www.reddit.com/r/datascience/comments/1nri84g/anyone_noticing_an_uptick_in_recruiter_outreach/,True,Discussion,self.datascience,datascience,False,False
1nrla6h,Week Bites: Weekly Dose of Data Science,"Hi everyone I’m sharing **Week Bites**, a series of **light, digestible videos on data science**. Each week, I cover **key concepts, practical techniques, and industry insights** in short, easy-to-watch videos. 1. [Where Data Scientists Find Free Datasets (Beyond Kaggle)](https://youtu.be/HR1sDaZOMDI) Authentic datasets that are clustered between research datasets, government datasets, massive-sized datasets that fit TF and PyTorch projects. 2. [Time Series Forecasting in Python (Practical Guide)](https://youtu.be/Y7KCMaBDeDM) Starting from the fundamentals supported by source code available in the video description 3. [Causal Inference Comprehensive Guide](https://youtu.be/40wIk7FSxdM) This area seems tricky a little, and I've started a series to halp intertwine causal inference into our AI models. Would love to hear your **thoughts, feedback, and topic suggestions**! Let me know which topics you find most useful",user_2ab54590,29,0.94,4,2025-09-26 20:44:53,https://www.reddit.com/r/datascience/comments/1nrla6h/week_bites_weekly_dose_of_data_science/,https://www.reddit.com/r/datascience/comments/1nrla6h/week_bites_weekly_dose_of_data_science/,True,Education,self.datascience,datascience,False,False
1ns18vu,Seeking Feedback on My Data Science CV,,user_d90f6d9a,0,0.26,10,2025-09-27 10:37:00,https://i.redd.it/4z80agbvtqrf1.jpeg,https://www.reddit.com/r/datascience/comments/1ns18vu/seeking_feedback_on_my_data_science_cv/,False,Career | US,i.redd.it,datascience,False,False
1nq8hi5,I'm still not sure how to answer vague DS questions...,"Questions like: * *“How do you approach building a model?”* * *“What metrics would you look at to evaluate success?”* * *“How would you handle missing data?”* * *“How do you decide between different algorithms?”* etc etc Where its highly dependent on context and it feels like no matter how much you qualify your answers with justifications, you never really know if it's the right answer. For some of these there are decent, generic answers but it really does seem like it's up to the interviewer to determine whether they like the answer you give",user_9a1576de,90,0.92,43,2025-09-25 07:36:44,https://www.reddit.com/r/datascience/comments/1nq8hi5/im_still_not_sure_how_to_answer_vague_ds_questions/,https://www.reddit.com/r/datascience/comments/1nq8hi5/im_still_not_sure_how_to_answer_vague_ds_questions/,True,Discussion,self.datascience,datascience,False,False
1npq7ty,PNC Bank Moving To 5 Days In Office,"FYI - If you are considering an analytics job at PNC Bank, they are moving to 5 days in office. It's now being required for senior managers, and will trickle down to individual contributors in the new year.",user_959a2b1c,87,0.97,51,2025-09-24 15:35:03,https://www.reddit.com/r/datascience/comments/1npq7ty/pnc_bank_moving_to_5_days_in_office/,https://www.reddit.com/r/datascience/comments/1npq7ty/pnc_bank_moving_to_5_days_in_office/,True,Career | US,self.datascience,datascience,False,False
1nqwcip,What is the state-of-the-art prediction performance for the stock market?,"I am currently working on a university project and want to predict the next day's closing price of a stock. I am using a foundation model for time series based on the transformer architecture (decoder only). Since I have no touchpoints with the practical procedures of the industry I was asking myself what the best prediction performance, especially directional accuracy (""stock will go up/down tomorrow"") is. I am currently able to achieve 59% accuracy only. Any practical insights? Thank you!",user_68d26541,0,0.25,56,2025-09-26 01:58:53,https://www.reddit.com/r/datascience/comments/1nqwcip/what_is_the_stateoftheart_prediction_performance/,https://www.reddit.com/r/datascience/comments/1nqwcip/what_is_the_stateoftheart_prediction_performance/,True,Analysis,self.datascience,datascience,False,False
1nphgwl,Expectations for probability questions in interviews,"Hey everyone, I'm a PhD candidate in CS, currently starting to interview for industry jobs. I had an interview earlier this week for a research scientist job that I was hoping to get an outside perspective on - I'm pretty new to technical interviewing and there don't seem to be many online resources about what interviewers expectations are going to be for more probability-style questions. I was not selected for a next round of interviews based on my performance, and that's at odds with my self-assessment and with the affect and demeanor of the interviewer. **The Interview Questions:** A question asking about probabilistic decay of N particles (over discrete time steps, known probability), and was asked to derive the probability that all particles would decay by a certain time. Then, I was asked to write a simulation of this scenario, and get point estimates, variance &c. Lastly, I was asked about a variation where I would estimate the probability, given observed counts. **My Performance:** I correctly characterized the problem as a Binomial(N,p) problem, where p is the probability that a single particle survives till time T. I did not get a closed form solution (I asked about how I did at the end and the interviewer mentioned that it would have been nice to get one). The code I wrote was correct, and I think fairly efficient? I got a little bit hung up on trying to estimate variance, but ended up with a bootstrap approach. We ran out of time before I could entirely solve the last variation, but generally described an approach. I felt that my interviewer and I had decent rapport, and it seemed like I did decently. **Question:** Overall, I'd like to know what I did wrong, though of course that's probably not possible without someone sitting in. I did talk throughout, and I have struggled with clear and concise verbal communication in the past. Was the expectation that I would solve all parts of the questions completely? What aspects of these interviews do interviewers tend to look for?",user_9f4e8005,48,0.96,16,2025-09-24 09:53:23,https://www.reddit.com/r/datascience/comments/1nphgwl/expectations_for_probability_questions_in/,https://www.reddit.com/r/datascience/comments/1nphgwl/expectations_for_probability_questions_in/,True,Discussion,self.datascience,datascience,False,False
1nq1bj4,Introducing ryxpress: Reproducible Polyglot Analytical Pipelines with Nix (Python),"Hi everyone, These past weeks I've been working on an R and Python package (called rixpress and ryxpress respectively) which aim to make it easy to build multilanguage projects by using Nix as the underlying build tool. ryxpress is a Python port of the R package `{rixpress}`, both in early development and they let you define data pipelines in R (with helpers for Python steps), build them reproducibly using Nix, and then inspect, read, or load artifacts from Python. If you're familiar with the `{targets}` R package, this is very similar. It’s designed to provide a smoother experience for those working in polyglot environments (Python, R, Julia and even Quarto/Markdown for reports) where reproducibility and cross-language workflows matter. Pipelines are defined in R, but the artifacts can be explored and loaded in Python, opening up easy interoperability for teams or projects using both languages. It uses Nix as the underyling build tool, so you get the power of Nix for dependency management, but can work in Python for artifact inspection and downstream tasks. Here is a basic definition of a pipeline: ``` library(rixpress) list( rxp_py_file( name = mtcars_pl, path = 'https://raw.githubusercontent.com/b-rodrigues/rixpress_demos/refs/heads/master/basic_r/data/mtcars.csv', read_function = ""lambda x: polars.read_csv(x, separator='|')"" ), rxp_py( name = mtcars_pl_am, expr = ""mtcars_pl.filter(polars.col('am') == 1)"", user_functions = ""functions.py"", encoder = ""serialize_to_json"", ), rxp_r( name = mtcars_head, expr = my_head(mtcars_pl_am), user_functions = ""functions.R"", decoder = ""jsonlite::fromJSON"" ), rxp_r( name = mtcars_mpg, expr = dplyr::select(mtcars_head, mpg) ) ) |> rxp_populate(project_path = ""."") ``` It's R code, but as explained, you can build it from Python and explore build artifacts from Python as well. You'll also need to define the ""execution environment"" in which this pipeline is supposed to run, using Nix as well. ryxpress is on PyPI, but you’ll need Nix (and R + {rixpress}) installed. See the [GitHub repo](https://github.com/b-rodrigues/ryxpress) for quickstart instructions and environment setup. Would love feedback, questions, or ideas for improvements! If you’re interested in reproducible, multi-language pipelines, give it a try.",user_1c70a546,2,0.67,2,2025-09-25 01:31:19,https://www.reddit.com/r/datascience/comments/1nq1bj4/introducing_ryxpress_reproducible_polyglot/,https://www.reddit.com/r/datascience/comments/1nq1bj4/introducing_ryxpress_reproducible_polyglot/,True,Projects,self.datascience,datascience,False,False
1nnvss1,Why do new analysts often ignore R?,,user_662c7639,2480,0.96,288,2025-09-22 12:18:36,https://i.redd.it/18swici6ylqf1.png,https://www.reddit.com/r/datascience/comments/1nnvss1/why_do_new_analysts_often_ignore_r/,False,Monday Meme,i.redd.it,datascience,False,False
1npfecr,Ad-hoc questions are the real killer. Curious if others feel this pain,"When I was a data scientist at Meta, almost 50% of my week went to ad-hoc requests like: * “Can we break out Marketplace feed engagement for buyers vs sellers?” * “Do translation errors spike more in Spanish than French?” * “What % of teen users in Reality Labs got safety warnings last release?” Each one was reasonable, but stacked together it turned my entire DS team into human SQL machines. I’ve been hacking on an MVP that tries to reduce this by letting the DS define a domain once (metrics, definitions, gotchas), and then AI handles repetitive questions transparently (always shows SQL + assumptions). Not trying to pitch, just genuinely curious if others have felt the same pain, and how you’ve dealt with it. If you want to see what I’m working on, here’s the landing page: [www.takeoutforteams.com](http://www.takeoutforteams.com). Would love any feedback from folks who’ve lived this, especially how your teams currently handle the flood of ad-hoc questions. Because right now there's very little beyond dashboards that let DS scale themselves.",user_070e7ebe,0,0.37,16,2025-09-24 08:35:43,https://www.reddit.com/r/datascience/comments/1npfecr/adhoc_questions_are_the_real_killer_curious_if/,https://www.reddit.com/r/datascience/comments/1npfecr/adhoc_questions_are_the_real_killer_curious_if/,True,Tools,self.datascience,datascience,False,False
1no5b1j,Is a second masters worth it for MLE roles?,"I already have an MS in Statistics and two and a half YoE, but mostly in operations and business-oriented roles. I would like to work more in DS or be able to pivot into engineering. My undergrad was not directly in computer science but I did have significant exposure to AI/ML before LLMs and generative models were mainstream. I don’t have any work experience directly in ML or DS, but my analyst roles over the last few years have been SQL-oriented with some scripting here and there. If I wanted to pivot into MLE or DE would it be worth going back to school for an MSCS? I also just generally miss learning and am open to a career pivot, and also have always wanted to try working on research projects (never did it for my MS). I’m leaning towards no and instead just working on relevant certifications, but I want to pivot out of Business Operations or business intelligence roles into more technical teams such as ML teams or product. Internal migration within my own company does not seem possible at the moment.",user_abe20dff,35,0.89,37,2025-09-22 19:07:20,https://www.reddit.com/r/datascience/comments/1no5b1j/is_a_second_masters_worth_it_for_mle_roles/,https://www.reddit.com/r/datascience/comments/1no5b1j/is_a_second_masters_worth_it_for_mle_roles/,True,Education,self.datascience,datascience,False,False
1nnsvq3,New RAG Builder: Create a SOTA RAG system in under 5 minutes. Which models/methods should we add next? [Kiln],"I just updated [my GitHub project Kiln](https://github.com/Kiln-AI/Kiln) **so you can build a RAG system in under 5 minutes**; just drag and drop your documents in. We want it to be the most usable RAG builder, while also offering powerful options for finding the ideal RAG parameters. Highlights: * **Easy to get started**: just drop in documents, select a template configuration, and you're up and running in a few minutes. * **Highly customizable**: you can customize the document extractor, chunking strategy, embedding model/dimension, and search index (vector/full-text/hybrid). Start simple with one-click templates, but go as deep as you want on tuning/customization. * **Document library**: manage documents, tag document sets, preview extractions, sync across your team, and more. * **Deep integrations**: evaluate RAG-task performance with our evals, expose RAG as a tool to any tool-compatible model * **Local**: the Kiln app runs locally and we can't access your data. The V1 of RAG requires API keys for extraction/embeddings, but we're working on fully-local RAG as we speak; see below for questions about where we should focus. We have docs walking through the process: [https://docs.kiln.tech/docs/documents-and-search-rag](https://docs.kiln.tech/docs/documents-and-search-rag) **Question for you:** V1 has a decent number of options for tuning, but folks are probably going to want more. We’d love suggestions for where to expand first. Options are: * **Document extraction**: V1 focuses on model-based extractors (Gemini/GPT) as they outperformed library-based extractors (docling, markitdown) in our tests. Which additional models/libraries/configs/APIs would you want? Specific open models? Marker? Docling? * **Embedding Models**: We're looking at EmbeddingGemma & Qwen Embedding as open/local options. Any other embedding models people like for RAG? * **Chunking**: V1 uses the sentence splitter from llama\_index. Do folks have preferred semantic chunkers or other chunking strategies? * **Vector database**: V1 uses LanceDB for vector, full-text (BM25), and hybrid search. Should we support more? Would folks want Qdrant? Chroma? Weaviate? pg-vector? HNSW tuning parameters? * Anything else? Some links to the repo and guides: * [Kiln AI on Github - 4k stars](https://github.com/Kiln-AI/Kiln) * [Documents & Search (RAG) Docs/Guide](https://docs.kiln.tech/docs/documents-and-search-rag) * [Kiln Discord](https://getkiln.ai/discord) * [Homepage](https://kiln.tech) I'm happy to answer questions if anyone wants details or has ideas!!",user_cf37a366,11,0.7,0,2025-09-22 10:30:27,https://i.redd.it/g3qm46cc4rqf1.png,https://www.reddit.com/r/datascience/comments/1nnsvq3/new_rag_builder_create_a_sota_rag_system_in_under/,False,AI,i.redd.it,datascience,False,False
1nnfcwc,Is it due to the tech recession?,"We know that in many companies Data Scientists are Product Analytics / Data Analysts. I thought it was because MLEs had absorbed the duties of DSs, but i have noticed that this may not be exactly the case. There are basically three distinct roles: 1. Data Analyst / Product Analytics: dashboards, data analysis, A/B testing. 2. MLE: build machine learning systems for user-facing products (e.g., Stripe’s fraud detection or YouTube’s recommendation algorithm). 3. DS: use ML and advanced techniques to solve business problems and make forecasts (e.g., sales, growth, churn). This last job is not done by MLEs, it has simply been eliminated by some companies in the last few years (but a lot of tech companies still have it). For example Stripe used to hire DSs specifically for this function and LinkedIn profiles confirm that those people are still there doing it, but now the new hires consist only of Data Analysts. It’s hard to believe that in a world increasingly driven by data, a role focused on predictive decision making would be seen as completely useless. So my question is: is this mostly the result of the tech recession? Companies may now prioritize “essential” roles that can be filled at lower costs (Data Analysts) while removing, in this difficult economy, the “luxury” roles (Data Scientists).",user_b7a887ca,60,0.8,46,2025-09-21 23:46:14,https://www.reddit.com/r/datascience/comments/1nnfcwc/is_it_due_to_the_tech_recession/,https://www.reddit.com/r/datascience/comments/1nnfcwc/is_it_due_to_the_tech_recession/,True,Discussion,self.datascience,datascience,False,False
1nncgka,Need input from mid-career dara Scientists (2-5 year range),"I am a DS with 2YOE (plus about 6 coops). I'm looking for feedback from folks specifically transitioned out of early career and into mid-career phase. (Unfortunately I don't have any in my immediate network) Context: I'm coming upto 2 years in my role and have been seriously evaluating the next stage of my career. Questions: 1. Does having a decent resume land you your next role, or even for a mid-level role do you need to network extensively i.e. what's the most optimal method for this stage of career progression. 2. Most of the work I've done so far has been POC-based i.e. we find business problems and work with teams to create MVPs. Its been an interesting experience as I get to experiment with different methods and almost derive the solution from scratch, without having to worry too much about MLE/MLOps. Does this kind of work exist at this next Intermediate level? And will this kind of role even exist into the future? 3. How do you decide between being able to climb up the ladder in your current company? Or switch to a different industry, maybe one that aligns more with your passion/interests, but also risk losing all of that ""capital"" you've invested into in the current company? Apologies if this is a bit all over the place, but it was a little tough getting my thoughts across. Also would love if anyone is down to discuss more in detail on dm, if that's preferred. Thanks a lot!",user_35fad8b3,31,0.86,32,2025-09-21 20:56:33,https://www.reddit.com/r/datascience/comments/1nncgka/need_input_from_midcareer_dara_scientists_25_year/,https://www.reddit.com/r/datascience/comments/1nncgka/need_input_from_midcareer_dara_scientists_25_year/,True,Discussion,self.datascience,datascience,False,False
1nnck8a,"Weekly Entering & Transitioning - Thread 22 Sep, 2025 - 29 Sep, 2025","Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include: * Learning resources (e.g. books, tutorials, videos) * Traditional education (e.g. schools, degrees, electives) * Alternative education (e.g. online courses, bootcamps) * Job search questions (e.g. resumes, applying, career prospects) * Elementary questions (e.g. where to start, what next) While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",user_ac31a110,2,0.75,25,2025-09-21 21:01:38,https://www.reddit.com/r/datascience/comments/1nnck8a/weekly_entering_transitioning_thread_22_sep_2025/,https://www.reddit.com/r/datascience/comments/1nnck8a/weekly_entering_transitioning_thread_22_sep_2025/,True,,self.datascience,datascience,False,False
1nnqb2c,Well well...,Anyone Cruyff dribbling...?,user_ae37e5e3,0,0.43,23,2025-09-22 08:54:55,https://i.redd.it/ss1rtnc5nqqf1.jpeg,https://www.reddit.com/r/datascience/comments/1nnqb2c/well_well/,False,Monday Meme,i.redd.it,datascience,False,False
1nl92og,Updated based on subreddit feedback. Applying for mid-senior based roles. Thank you,,user_90ab6750,44,0.83,30,2025-09-19 09:59:03,https://i.redd.it/4yq1ffjlj5qf1.png,https://www.reddit.com/r/datascience/comments/1nl92og/updated_based_on_subreddit_feedback_applying_for/,False,Discussion,i.redd.it,datascience,False,False
1nl4jtx,What’s the right thing to say to salary expectations question?,I have come across usually two types of scenarios here and I am not sure what’s the best way to deal. - I ask for a range and they give you range. Should you just say you’re okay with the range? But what if I make 80K now and their range is 90-120. In this case I don’t wanna move at 90K. What should you say? - They just don’t give you any range and keep pressing to give them a number. In this case I feel like there’s chances of getting low balled later. I have a couple of recruiter rounds coming up. Could really use your help. Thanks!,user_d528b440,63,0.95,60,2025-09-19 07:07:10,https://www.reddit.com/r/datascience/comments/1nl4jtx/whats_the_right_thing_to_say_to_salary/,https://www.reddit.com/r/datascience/comments/1nl4jtx/whats_the_right_thing_to_say_to_salary/,True,Career | US,self.datascience,datascience,False,False
1nl4oi1,How to actually perform observational studies in industry?,"Hey everyone, I am working on observational studies and need some guidance on confounder and model selection, are you following a best practise when it comes to observational studies? My situation is, we have models to predict who will churn based on a whole set of features and then we reach out to them, and the ones that answer become our treatment and the ones that don't become our control. Then based on a bunch of features of their behaviour in the previous year, I use a model to find the features that most likely predict who will answer and use those as the confounders. As they were most related to the treated group. Then would use something like TMLE,psw etc to find the ATE. How do you decide what to do if there isnt any domain knowledge, is there a textbook or methods you follow to conduct your tests?",user_c7e1342a,14,0.95,10,2025-09-19 07:12:19,https://www.reddit.com/r/datascience/comments/1nl4oi1/how_to_actually_perform_observational_studies_in/,https://www.reddit.com/r/datascience/comments/1nl4oi1/how_to_actually_perform_observational_studies_in/,True,Discussion,self.datascience,datascience,False,False
1nlldi9,Transformer with multi-dimensional timesteps,"Does anyone have boilerplate Python code for using Keras or similar to run a transformer model on data where each time step of each sequence is, say, 3 dimensions? E.g.: Data 1: [(3,5,0),(4,6,1)], label = 1 Data 2: [(6,3,0)], label = 0 I’m having trouble getting my ChatGPT-coded model to perform, which is surprising since I was able to get decent results when I just looked at one of the 3 featured with the same ordering, data, and number of steps. Any boilerplate Python code would be of great help. I’m unable to find something basic online, but I’m sure it’s out there so appreciate being pointed in the right direction.",user_73dd5ff1,2,0.6,5,2025-09-19 18:31:25,https://www.reddit.com/r/datascience/comments/1nlldi9/transformer_with_multidimensional_timesteps/,https://www.reddit.com/r/datascience/comments/1nlldi9/transformer_with_multidimensional_timesteps/,True,ML,self.datascience,datascience,False,False
1njp4vy,K-shot training with LLMs for document annotation/extraction,"https://preview.redd.it/u9fxkmmqgspf1.png?width=2000&format=png&auto=webp&s=b616b9a5d725d680f9bc76dc09f2b9d62aed079a I’ve been experimenting with a way to teach LLMs to extract structured data from documents by \*\*annotating, not prompt engineering\*\*. Instead of fiddling with prompts that sometimes regress, you just build up examples. Each example improves accuracy in a concrete way, and you often need far fewer than traditional ML approaches. How it works (prototype is live): \- Upload a document (DOCX, PDF, image, etc.) \- Select and tag parts of it (supports nesting, arrays, custom tag structures) \- Upload another document → click ""predict"" → see editable annotations \- Amend them and save as another example \- Call the API with a third document → get JSON back Potential use cases: \- Identify important clauses in contracts \- Extract total value from invoices \- Subjective tags like “healthy ingredients” on a label \- Objective tags like “postcode” or “phone number” It seems to generalize well: you can even tag things like “good rhymes” in a poem. Basically anything an LLM can comprehend and extrapolate. I’d love feedback on: \- Does this kind of few-shot / K-shot approach seem useful in practice? \- Are there other document-processing scenarios where this would be particularly impactful? \- Pitfalls you’d anticipate? I've called this ""DeepTagger"", first link on google if you search that, if you want to try it! It's fully working, but this is just a first version.",user_2d5dfb3e,28,0.91,12,2025-09-17 14:00:00,https://www.reddit.com/r/datascience/comments/1njp4vy/kshot_training_with_llms_for_document/,https://www.reddit.com/r/datascience/comments/1njp4vy/kshot_training_with_llms_for_document/,True,ML,self.datascience,datascience,False,False
1njcvfv,Example Take Home Assignment For Interview - Data Science in Finance,"Edit: formatting data dictionary Hello, Thought this might be an interesting post for some, especially those of us who work at Financial Institutions. Here is a take home assignment used in the interview process to evaluate candidates for a data scientist role in the financial industry. This company does personal lending in the US. Hopefully this is enough on topic (and not against the rules) as this is for a data scientist role, but it also is very financially focused. I'm not looking for help in anyway, just hope this might helpful to someone looking for a role in this area. I know a lot of people are against take home assignments, I get it, but the reality is many employers still use them. I'll try to format things as best as possible, but it's tough when you can't post attachments. **Instructions** Employer uses machine learning models to evaluate borrower risk and determine loan eligibility. In July 2024, we launched **Model B** to replace **Model A**, aiming to improve loan approvals and portfolio returns. Our executive team has expressed concern that Model B might be underperforming in some cases. Your task is to assess the performance of Models A and B across these loan product types and answer the central question: **Should we roll back to Model A or keep and improve Model B?** Additionally, analyze the dataset to uncover any other insights that could guide our decision-making and optimize our lending strategy. Please put together a presentation summarizing your findings, insights, and recommendations. Assume your audience has a low level of familiarity with the specifics of the problem but will appreciate clear, data-driven reasoning and business implications. You will present your findings in a 45 minute meeting with stakeholders but ensure to leave ample time for their questions. **Data Dictionary (for the two attachments below):** * *Origination Month:* Month in which the loan was funded. * *Payment Month:* Payments are made monthly. The first payment is made a month after origination. Payment number refers to future payments from the loans that originated in the specified month. For an origination taking place in Jan 2023, their 1st payment month will take place in Feb 2023, their 2nd payment month will take place in March 2023, etc… * *Model Version:* Model\_A is the original model and Model\_B is the new, updated model. * *Scheduled Loan Repayment:* The loan repayments as determined by the amortization schedule at origination. * *Forecasted Loan Repayment:* The loan repayments that are forecasted by each model at origination. * *Actual Loan Repayment:* The actual loan repayments made during each payment month by borrowers. * *Application Submits:* Loan applications that are submitted. * *Origination Amount:* The initial principal amount when the loan is funded. * *Note: Employer earns revenue as a % fee of the loan origination amount and the investor (Employer’s lending partners which provide the capital for Employer to lend) earns returns based on interest net loss* **Attachment 1** || || |Month|Application Submits|Origination Amount| |1/1/23|134,194|$7,245,878| |2/1/23|118,084|$6,291,085| |3/1/23|151,789|$6,978,795| |4/1/23|147,247|$7,629,398| |5/1/23|144,106|$7,386,274| |6/1/23|166,063|$7,607,082| |7/1/23|175,438|$8,302,775| |8/1/23|173,874|$9,136,815| |9/1/23|199,833|$9,556,795| |10/1/23|173,089|$9,305,852| |11/1/23|177,250|$9,383,253| |12/1/23|229,996|$11,186,584| |1/1/24|198,578|$10,922,898| |2/1/24|216,549|$12,409,692| |3/1/24|216,083|$11,248,453| |4/1/24|215,525|$12,350,982| |5/1/24|193,528|$10,995,911| |6/1/24|201,425|$12,011,017| |7/1/24|220,760|$10,487,390| |8/1/24|199,445|$10,180,941| |9/1/24|187,549|$10,518,739| |10/1/24|187,075|$10,095,767| |11/1/24|198,951|$10,281,715| |12/1/24|210,259|$10,266,566 | **Attachement 2** || || |Origination Month|Model Version|Payment Number|Scheduled Loan Repayment|Forecasted Loan Repayment|Actual Loan Repayment| |1/1/23|Model\_A|1|$106,000.00|$105,788.00|$105,788.00| |1/1/23|Model\_A|2|$106,000.00|$105,576.42|$105,945.94| |1/1/23|Model\_A|3|$106,000.00|$105,365.27|$105,312.59| |1/1/23|Model\_A|4|$106,000.00|$105,154.54|$105,007.32| |1/1/23|Model\_A|5|$106,000.00|$104,944.23|$104,660.88| |1/1/23|Model\_A|6|$106,000.00|$104,734.34|$104,430.61| |1/1/23|Model\_A|7|$106,000.00|$104,524.87|$105,037.04| |1/1/23|Model\_A|8|$106,000.00|$104,315.82|$104,211.50| |1/1/23|Model\_A|9|$106,000.00|$104,107.19|$104,471.57| |1/1/23|Model\_A|10|$106,000.00|$103,898.98|$103,898.98| |1/1/23|Model\_A|11|$106,000.00|$103,691.18|$103,421.58| |1/1/23|Model\_A|12|$106,000.00|$103,483.80|$103,338.92| |1/1/23|Model\_A|13|$106,000.00|$103,276.83|$102,967.00| |1/1/23|Model\_A|14|$106,000.00|$103,070.28|$103,163.04| |1/1/23|Model\_A|15|$106,000.00|$102,864.14|$102,349.82| |1/1/23|Model\_A|16|$106,000.00|$102,658.41|$102,781.60| |1/1/23|Model\_A|17|$106,000.00|$102,453.09|$102,729.71| |1/1/23|Model\_A|18|$106,000.00|$102,248.18|$102,329.98| |1/1/23|Model\_A|19|$106,000.00|$102,043.68|$99,880.61| |1/1/23|Model\_A|20|$106,000.00|$101,839.59|$99,442.54| |1/1/23|Model\_A|21|$106,000.00|$101,635.91|$99,451.76| |1/1/23|Model\_A|22|$106,000.00|$101,432.64|$98,451.79| |1/1/23|Model\_A|23|$106,000.00|$101,229.77|$98,314.10| |2/1/23|Model\_A|1|$93,730.00|$93,542.54|$93,730.00| |2/1/23|Model\_A|2|$93,730.00|$93,355.45|$93,411.46| |2/1/23|Model\_A|3|$93,730.00|$93,168.74|$93,429.61| |2/1/23|Model\_A|4|$93,730.00|$92,982.40|$93,382.22| |2/1/23|Model\_A|5|$93,730.00|$92,796.44|$92,351.02| |2/1/23|Model\_A|6|$93,730.00|$92,610.85|$92,184.84| |2/1/23|Model\_A|7|$93,730.00|$92,425.63|$92,887.76| |2/1/23|Model\_A|8|$93,730.00|$92,240.78|$91,844.14| |2/1/23|Model\_A|9|$93,730.00|$92,056.30|$92,001.07| |2/1/23|Model\_A|10|$93,730.00|$91,872.19|$92,101.87| |2/1/23|Model\_A|11|$93,730.00|$91,688.45|$91,624.27| |2/1/23|Model\_A|12|$93,730.00|$91,505.07|$91,404.41| |2/1/23|Model\_A|13|$93,730.00|$91,322.06|$90,920.24| |2/1/23|Model\_A|14|$93,730.00|$91,139.42|$91,522.21| |2/1/23|Model\_A|15|$93,730.00|$90,957.14|$91,139.05| |2/1/23|Model\_A|16|$93,730.00|$90,775.23|$90,602.76| |2/1/23|Model\_A|17|$93,730.00|$90,593.68|$90,765.81| |2/1/23|Model\_A|18|$93,730.00|$90,412.49|$88,187.43| |2/1/23|Model\_A|19|$93,730.00|$90,231.67|$87,694.36| |2/1/23|Model\_A|20|$93,730.00|$90,051.21|$87,641.89| |2/1/23|Model\_A|21|$93,730.00|$89,871.11|$87,343.93| |2/1/23|Model\_A|22|$93,730.00|$89,691.37|$87,580.26| |3/1/23|Model\_A|1|$98,580.00|$98,382.84|$97,989.31| |3/1/23|Model\_A|2|$98,580.00|$98,186.07|$97,734.41| |3/1/23|Model\_A|3|$98,580.00|$97,989.70|$98,215.08| |3/1/23|Model\_A|4|$98,580.00|$97,793.72|$97,617.69| |3/1/23|Model\_A|5|$98,580.00|$97,598.13|$97,754.29| |3/1/23|Model\_A|6|$98,580.00|$97,402.93|$97,841.24| |3/1/23|Model\_A|7|$98,580.00|$97,208.12|$96,858.17| |3/1/23|Model\_A|8|$98,580.00|$97,013.70|$97,149.52| |3/1/23|Model\_A|9|$98,580.00|$96,819.67|$96,626.03| |3/1/23|Model\_A|10|$98,580.00|$96,626.03|$96,394.13| |3/1/23|Model\_A|11|$98,580.00|$96,432.78|$96,760.65| |3/1/23|Model\_A|12|$98,580.00|$96,239.91|$96,365.02| |3/1/23|Model\_A|13|$98,580.00|$96,047.43|$96,114.66| |3/1/23|Model\_A|14|$98,580.00|$95,855.34|$96,056.64| |3/1/23|Model\_A|15|$98,580.00|$95,663.63|$95,730.59| |3/1/23|Model\_A|16|$98,580.00|$95,472.30|$95,625.06| |3/1/23|Model\_A|17|$98,580.00|$95,281.36|$92,490.57| |3/1/23|Model\_A|18|$98,580.00|$95,090.80|$93,112.20| |3/1/23|Model\_A|19|$98,580.00|$94,900.62|$92,565.12| |3/1/23|Model\_A|20|$98,580.00|$94,710.82|$92,315.35| |3/1/23|Model\_A|21|$98,580.00|$94,521.40|$92,600.72| |4/1/23|Model\_A|1|$103,550.00|$103,342.90|$103,260.23| |4/1/23|Model\_A|2|$103,550.00|$103,136.21|$103,363.11| |4/1/23|Model\_A|3|$103,550.00|$102,929.94|$102,857.89| |4/1/23|Model\_A|4|$103,550.00|$102,724.08|$102,272.09| |4/1/23|Model\_A|5|$103,550.00|$102,518.63|$102,293.09| |4/1/23|Model\_A|6|$103,550.00|$102,313.59|$102,579.61| |4/1/23|Model\_A|7|$103,550.00|$102,108.96|$101,996.64| |4/1/23|Model\_A|8|$103,550.00|$101,904.74|$102,322.55| |4/1/23|Model\_A|9|$103,550.00|$101,700.93|$101,975.52| |4/1/23|Model\_A|10|$103,550.00|$101,497.53|$101,142.29| |4/1/23|Model\_A|11|$103,550.00|$101,294.53|$100,909.61| |4/1/23|Model\_A|12|$103,550.00|$101,091.94|$101,395.22| |4/1/23|Model\_A|13|$103,550.00|$100,889.76|$100,960.38| |4/1/23|Model\_A|14|$103,550.00|$100,687.98|$100,718.19| |4/1/23|Model\_A|15|$103,550.00|$100,486.60|$100,808.16| |4/1/23|Model\_A|16|$103,550.00|$100,285.63|$98,247.83| |4/1/23|Model\_A|17|$103,550.00|$100,085.06|$97,534.14| |4/1/23|Model\_A|18|$103,550.00|$99,884.89|$97,231.94| |4/1/23|Model\_A|19|$103,550.00|$99,685.12|$97,348.50| |4/1/23|Model\_A|20|$103,550.00|$99,485.75|$97,182.90| |5/1/23|Model\_A|1|$118,720.00|$118,482.56|$118,720.00| |5/1/23|Model\_A|2|$118,720.00|$118,245.59|$118,352.01| |5/1/23|Model\_A|3|$118,720.00|$118,009.10|$118,079.91| |5/1/23|Model\_A|4|$118,720.00|$117,773.08|$117,902.63| |5/1/23|Model\_A|5|$118,720.00|$117,537.53|$116,961.60| |5/1/23|Model\_A|6|$118,720.00|$117,302.45|$116,950.54| |5/1/23|Model\_A|7|$118,720.00|$117,067.85|$117,220.04| |5/1/23|Model\_A|8|$118,720.00|$116,833.71|$116,646.78| |5/1/23|Model\_A|9|$118,720.00|$116,600.04|$116,961.50| |5/1/23|Model\_A|10|$118,720.00|$116,366.84|$116,029.38| |5/1/23|Model\_A|11|$118,720.00|$116,134.11|$116,459.29| |5/1/23|Model\_A|12|$118,720.00|$115,901.84|$116,006.15| |5/1/23|Model\_A|13|$118,720.00|$115,670.04|$115,843.55| |5/1/23|Model\_A|14|$118,720.00|$115,438.70|$115,865.82| |5/1/23|Model\_A|15|$118,720.00|$115,207.82|$112,395.02| |5/1/23|Model\_A|16|$118,720.00|$114,977.40|$111,688.18| |5/1/23|Model\_A|17|$118,720.00|$114,747.45|$111,431.25| |5/1/23|Model\_A|18|$118,720.00|$114,517.96|$111,230.72| |5/1/23|Model\_A|19|$118,720.00|$114,288.92|$111,598.84| |6/1/23|Model\_A|1|$109,250.00|$109,031.50|$109,250.00| |6/1/23|Model\_A|2|$109,250.00|$108,813.44|$108,933.13| |6/1/23|Model\_A|3|$109,250.00|$108,595.81|$108,856.44| |6/1/23|Model\_A|4|$109,250.00|$108,378.62|$108,476.16| |6/1/23|Model\_A|5|$109,250.00|$108,161.86|$107,642.68| |6/1/23|Model\_A|6|$109,250.00|$107,945.54|$108,129.05| |6/1/23|Model\_A|7|$109,250.00|$107,729.65|$107,772.74| |6/1/23|Model\_A|8|$109,250.00|$107,514.19|$107,116.39| |6/1/23|Model\_A|9|$109,250.00|$107,299.16|$107,470.84| |6/1/23|Model\_A|10|$109,250.00|$107,084.56|$107,063.14| |6/1/23|Model\_A|11|$109,250.00|$106,870.39|$106,870.39| |6/1/23|Model\_A|12|$109,250.00|$106,656.65|$106,912.63| |6/1/23|Model\_A|13|$109,250.00|$106,443.34|$106,666.87| |6/1/23|Model\_A|14|$109,250.00|$106,230.45|$103,864.70| |6/1/23|Model\_A|15|$109,250.00|$106,017.99|$102,985.08| |6/1/23|Model\_A|16|$109,250.00|$105,805.95|$103,625.03| |6/1/23|Model\_A|17|$109,250.00|$105,594.34|$103,335.41| |6/1/23|Model\_A|18|$109,250.00|$105,383.15|$103,025.99| |7/1/23|Model\_A|1|$109,740.00|$109,520.52|$109,137.20| |7/1/23|Model\_A|2|$109,740.00|$109,301.48|$109,050.09| |7/1/23|Model\_A|3|$109,740.00|$109,082.88|$109,355.59| |7/1/23|Model\_A|4|$109,740.00|$108,864.71|$109,256.62| |7/1/23|Model\_A|5|$109,740.00|$108,646.98|$108,799.09| |7/1/23|Model\_A|6|$109,740.00|$108,429.69|$108,505.59| |7/1/23|Model\_A|7|$109,740.00|$108,212.83|$108,515.83| |7/1/23|Model\_A|8|$109,740.00|$107,996.40|$108,082.80| |7/1/23|Model\_A|9|$109,740.00|$107,780.41|$107,618.74| |7/1/23|Model\_A|10|$109,740.00|$107,564.85|$107,629.39| |7/1/23|Model\_A|11|$109,740.00|$107,349.72|$107,596.62| |7/1/23|Model\_A|12|$109,740.00|$107,135.02|$107,638.55| |7/1/23|Model\_A|13|$109,740.00|$106,920.75|$104,153.91| |7/1/23|Model\_A|14|$109,740.00|$106,706.91|$104,060.04| |7/1/23|Model\_A|15|$109,740.00|$106,493.50|$103,415.84| |7/1/23|Model\_A|16|$109,740.00|$106,280.51|$103,177.91| |7/1/23|Model\_A|17|$109,740.00|$106,067.95|$103,374.88| |8/1/23|Model\_A|1|$117,370.00|$117,135.26|$117,370.00| |8/1/23|Model\_A|2|$117,370.00|$116,900.99|$117,064.65| |8/1/23|Model\_A|3|$117,370.00|$116,667.19|$116,748.86| |8/1/23|Model\_A|4|$117,370.00|$116,433.86|$116,690.01| |8/1/23|Model\_A|5|$117,370.00|$116,200.99|$116,108.03| |8/1/23|Model\_A|6|$117,370.00|$115,968.59|$116,351.29| |8/1/23|Model\_A|7|$117,370.00|$115,736.65|$115,482.03| |8/1/23|Model\_A|8|$117,370.00|$115,505.18|$115,736.19| |8/1/23|Model\_A|9|$117,370.00|$115,274.17|$114,905.29| |8/1/23|Model\_A|10|$117,370.00|$115,043.62|$115,124.15| |8/1/23|Model\_A|11|$117,370.00|$114,813.53|$114,928.34| |8/1/23|Model\_A|12|$117,370.00|$114,583.90|$111,350.63| |8/1/23|Model\_A|13|$117,370.00|$114,354.73|$111,585.05| |8/1/23|Model\_A|14|$117,370.00|$114,126.02|$110,850.03| |8/1/23|Model\_A|15|$117,370.00|$113,897.77|$111,139.17| |8/1/23|Model\_A|16|$117,370.00|$113,669.97|$110,872.55| |9/1/23|Model\_A|1|$112,840.00|$112,614.32|$112,062.51| |9/1/23|Model\_A|2|$112,840.00|$112,389.09|$112,096.88| |9/1/23|Model\_A|3|$112,840.00|$112,164.31|$111,951.20| |9/1/23|Model\_A|4|$112,840.00|$111,939.98|$112,342.96| |9/1/23|Model\_A|5|$112,840.00|$111,716.10|$111,459.15| |9/1/23|Model\_A|6|$112,840.00|$111,492.67|$111,838.30| |9/1/23|Model\_A|7|$112,840.00|$111,269.68|$111,113.90| |9/1/23|Model\_A|8|$112,840.00|$111,047.14|$111,169.29| |9/1/23|Model\_A|9|$112,840.00|$110,825.05|$110,913.71| |9/1/23|Model\_A|10|$112,840.00|$110,603.40|$110,271.59| |9/1/23|Model\_A|11|$112,840.00|$110,382.19|$107,730.26| |9/1/23|Model\_A|12|$112,840.00|$110,161.43|$107,514.80| |9/1/23|Model\_A|13|$112,840.00|$109,941.11|$106,656.62| |9/1/23|Model\_A|14|$112,840.00|$109,721.23|$107,149.36| |9/1/23|Model\_A|15|$112,840.00|$109,501.79|$106,700.19| |10/1/23|Model\_A|1|$121,920.00|$121,676.16|$121,920.00| |10/1/23|Model\_A|2|$121,920.00|$121,432.81|$121,177.80| |10/1/23|Model\_A|3|$121,920.00|$121,189.94|$120,680.94| |10/1/23|Model\_A|4|$121,920.00|$120,947.56|$120,475.86| |10/1/23|Model\_A|5|$121,920.00|$120,705.66|$120,307.33| |10/1/23|Model\_A|6|$121,920.00|$120,464.25|$120,825.64| |10/1/23|Model\_A|7|$121,920.00|$120,223.32|$120,680.17| |10/1/23|Model\_A|8|$121,920.00|$119,982.87|$120,570.79| |10/1/23|Model\_A|9|$121,920.00|$119,742.90|$120,185.95| |10/1/23|Model\_A|10|$121,920.00|$119,503.41|$116,224.53| |10/1/23|Model\_A|11|$121,920.00|$119,264.40|$115,724.63| |10/1/23|Model\_A|12|$121,920.00|$119,025.87|$115,806.52| |10/1/23|Model\_A|13|$121,920.00|$118,787.82|$115,667.57| |10/1/23|Model\_A|14|$121,920.00|$118,550.24|$115,378.43| |11/1/23|Model\_A|1|$127,400.00|$127,145.20|$127,374.06| |11/1/23|Model\_A|2|$127,400.00|$126,890.91|$127,208.14| |11/1/23|Model\_A|3|$127,400.00|$126,637.13|$126,295.21| |11/1/23|Model\_A|4|$127,400.00|$126,383.86|$126,257.48| |11/1/23|Model\_A|5|$127,400.00|$126,131.09|$125,815.76| |11/1/23|Model\_A|6|$127,400.00|$125,878.83|$125,715.19| |11/1/23|Model\_A|7|$127,400.00|$125,627.07|$125,639.63| |11/1/23|Model\_A|8|$127,400.00|$125,375.82|$124,786.55| |11/1/23|Model\_A|9|$127,400.00|$125,125.07|$121,948.14| |11/1/23|Model\_A|10|$127,400.00|$124,874.82|$121,752.95| |11/1/23|Model\_A|11|$127,400.00|$124,625.07|$121,363.63| |11/1/23|Model\_A|12|$127,400.00|$124,375.82|$121,133.03| |11/1/23|Model\_A|13|$127,400.00|$124,127.07|$121,447.47| |12/1/23|Model\_A|1|$126,350.00|$126,097.30|$125,895.54| |12/1/23|Model\_A|2|$126,350.00|$125,845.11|$125,945.79| |12/1/23|Model\_A|3|$126,350.00|$125,593.42|$125,794.37| |12/1/23|Model\_A|4|$126,350.00|$125,342.23|$125,104.08| |12/1/23|Model\_A|5|$126,350.00|$125,091.55|$124,916.42| |12/1/23|Model\_A|6|$126,350.00|$124,841.37|$125,465.58| |12/1/23|Model\_A|7|$126,350.00|$124,591.69|$124,853.33| |12/1/23|Model\_A|8|$126,350.00|$124,342.51|$121,512.79| |12/1/23|Model\_A|9|$126,350.00|$124,093.82|$120,640.60| |12/1/23|Model\_A|10|$126,350.00|$123,845.63|$120,858.16| |12/1/23|Model\_A|11|$126,350.00|$123,597.94|$120,110.32| |12/1/23|Model\_A|12|$126,350.00|$123,350.74|$120,014.41| |1/1/24|Model\_A|1|$134,640.00|$134,370.72|$134,236.35| |1/1/24|Model\_A|2|$134,640.00|$134,101.98|$134,640.00| |1/1/24|Model\_A|3|$134,640.00|$133,833.78|$133,606.26| |1/1/24|Model\_A|4|$134,640.00|$133,566.11|$133,472.61| |1/1/24|Model\_A|5|$134,640.00|$133,298.98|$133,538.92| |1/1/24|Model\_A|6|$134,640.00|$133,032.38|$133,631.03| |1/1/24|Model\_A|7|$134,640.00|$132,766.32|$129,408.33| |1/1/24|Model\_A|8|$134,640.00|$132,500.79|$129,304.54| |1/1/24|Model\_A|9|$134,640.00|$132,235.79|$129,097.51| |1/1/24|Model\_A|10|$134,640.00|$131,971.32|$128,028.67| |1/1/24|Model\_A|11|$134,640.00|$131,707.38|$128,016.61| |2/1/24|Model\_A|1|$127,880.00|$127,624.24|$127,560.43| |2/1/24|Model\_A|2|$127,880.00|$127,368.99|$126,846.78| |2/1/24|Model\_A|3|$127,880.00|$127,114.25|$127,482.88| |2/1/24|Model\_A|4|$127,880.00|$126,860.02|$127,481.63| |2/1/24|Model\_A|5|$127,880.00|$126,606.30|$126,770.89| |2/1/24|Model\_A|6|$127,880.00|$126,353.09|$123,108.02| |2/1/24|Model\_A|7|$127,880.00|$126,100.38|$122,566.73| |2/1/24|Model\_A|8|$127,880.00|$125,848.18|$123,205.06| |2/1/24|Model\_A|9|$127,880.00|$125,596.48|$122,236.15| |2/1/24|Model\_A|10|$127,880.00|$125,345.29|$121,686.15| |3/1/24|Model\_A|1|$129,220.00|$128,961.56|$128,561.78| |3/1/24|Model\_A|2|$129,220.00|$128,703.64|$129,192.71| |3/1/24|Model\_A|3|$129,220.00|$128,446.23|$129,049.93| |3/1/24|Model\_A|4|$129,220.00|$128,189.34|$128,253.43| |3/1/24|Model\_A|5|$129,220.00|$127,932.96|$124,884.32| |3/1/24|Model\_A|6|$129,220.00|$127,677.09|$124,273.54| |3/1/24|Model\_A|7|$129,220.00|$127,421.74|$123,975.30| |3/1/24|Model\_A|8|$129,220.00|$127,166.90|$124,161.31| |3/1/24|Model\_A|9|$129,220.00|$126,912.57|$124,271.83| |4/1/24|Model\_A|1|$134,850.00|$134,580.30|$134,270.77| |4/1/24|Model\_A|2|$134,850.00|$134,311.14|$133,881.34| |4/1/24|Model\_A|3|$134,850.00|$134,042.52|$133,559.97| |4/1/24|Model\_A|4|$134,850.00|$133,774.43|$130,077.91| |4/1/24|Model\_A|5|$134,850.00|$133,506.88|$130,156.19| |4/1/24|Model\_A|6|$134,850.00|$133,239.87|$129,259.33| |4/1/24|Model\_A|7|$134,850.00|$132,973.39|$129,363.83| |4/1/24|Model\_A|8|$134,850.00|$132,707.44|$129,557.96| |5/1/24|Model\_A|1|$134,680.00|$134,410.64|$134,680.00| |5/1/24|Model\_A|2|$134,680.00|$134,141.82|$134,490.59| |5/1/24|Model\_A|3|$134,680.00|$133,873.54|$130,017.64| |5/1/24|Model\_A|4|$134,680.00|$133,605.79|$130,304.72| |5/1/24|Model\_A|5|$134,680.00|$133,338.58|$130,408.13| |5/1/24|Model\_A|6|$134,680.00|$133,071.90|$129,394.79| |5/1/24|Model\_A|7|$134,680.00|$132,805.76|$128,928.83| |6/1/24|Model\_A|1|$154,020.00|$153,711.96|$154,020.00| |6/1/24|Model\_A|2|$154,020.00|$153,404.54|$149,389.94| |6/1/24|Model\_A|3|$154,020.00|$153,097.73|$149,165.80| |6/1/24|Model\_A|4|$154,020.00|$152,791.53|$149,567.63| |6/1/24|Model\_A|5|$154,020.00|$152,485.95|$148,837.34| |6/1/24|Model\_A|6|$154,020.00|$152,180.98|$148,064.87| |7/1/24|Model\_B|1|$127,066.50|$126,812.37|$123,431.87| |7/1/24|Model\_B|2|$127,066.50|$126,558.75|$123,690.93| |7/1/24|Model\_B|3|$127,066.50|$126,305.63|$123,455.86| |7/1/24|Model\_B|4|$127,066.50|$126,053.02|$122,655.89| |7/1/24|Model\_B|5|$127,066.50|$125,800.91|$122,888.93| |8/1/24|Model\_B|1|$130,917.00|$130,655.17|$127,644.08| |8/1/24|Model\_B|2|$130,917.00|$130,393.86|$126,739.90| |8/1/24|Model\_B|3|$130,917.00|$130,133.07|$126,968.56| |8/1/24|Model\_B|4|$130,917.00|$129,872.80|$126,208.11| |9/1/24|Model\_B|1|$133,484.00|$133,217.03|$129,419.01| |9/1/24|Model\_B|2|$133,484.00|$132,950.60|$129,212.03| |9/1/24|Model\_B|3|$133,484.00|$132,684.70|$129,755.68| |10/1/24|Model\_B|1|$125,783.00|$125,531.43|$122,601.21| |10/1/24|Model\_B|2|$125,783.00|$125,280.37|$122,026.21| |11/1/24|Model\_B|1|$130,917.00|$130,655.17|$127,528.92 |",user_acf895ee,55,0.8,17,2025-09-17 06:15:45,https://www.reddit.com/r/datascience/comments/1njcvfv/example_take_home_assignment_for_interview_data/,https://www.reddit.com/r/datascience/comments/1njcvfv/example_take_home_assignment_for_interview_data/,True,Career | US,self.datascience,datascience,False,False
1nj55qy,How do you conduct a power analysis on a causal observational study?,"Hey everyone, we are running some campaigns and then looking back retrospectively to see if they worked. How do you determine the correct sample size? Does a normal power size calculator work in this scenario? I’ve seen some conflicting thoughts on this, wondering how you’ve all done it on your projects.",user_c7e1342a,10,0.82,14,2025-09-16 22:59:07,https://www.reddit.com/r/datascience/comments/1nj55qy/how_do_you_conduct_a_power_analysis_on_a_causal/,https://www.reddit.com/r/datascience/comments/1nj55qy/how_do_you_conduct_a_power_analysis_on_a_causal/,True,Discussion,self.datascience,datascience,False,False
1nj9mu5,Privacy-Safe Tabular Synthetic Data with TabPFN,,user_bb720034,4,1.0,3,2025-09-17 03:41:19,https://medium.com/@kursat002/generate-privacy-safe-tabular-synthetic-data-in-seconds-with-tabpfn-2a2567937fb5,https://www.reddit.com/r/datascience/comments/1nj9mu5/privacysafe_tabular_synthetic_data_with_tabpfn/,False,ML,medium.com,datascience,False,False
1nioq77,Python Projects For Beginners to Advanced | Build Logic | Build Apps | Intro on Generative AI|Gemini,"Only those win who stay till the end.” Complete the whole series and become really good at python. You can skip the intro. You can start from Anywhere. From Beginners or Intermediate or Advanced or You can Shuffle and Just Enjoy the journey of learning python by these Useful Projects. Whether you are a beginner or an intermediate in Python. This 5 Hour long Python Project Video will leave you with tremendous information , on how to build logic and Apps and also with an introduction to Gemini. You will start from Beginner Projects and End up with Building Live apps. This Python Project video will help you in putting some great resume projects and also help you in understanding the real use case of python. This is an eye opening Python Video and you will be not the same python programmer after completing it.",user_e5ff5d8f,2,0.57,1,2025-09-16 10:58:07,https://youtu.be/wIrPdBnoZHo?si=w2aAK5X2c_yTFmep,https://www.reddit.com/r/datascience/comments/1nioq77/python_projects_for_beginners_to_advanced_build/,False,Projects,youtu.be,datascience,False,False
1niop8o,Python Projects For Beginners to Advanced | Build Logic | Build Apps | Intro on Generative AI|Gemini,,user_e5ff5d8f,3,0.62,2,2025-09-16 10:57:10,https://youtu.be/wIrPdBnoZHo,https://www.reddit.com/r/datascience/comments/1niop8o/python_projects_for_beginners_to_advanced_build/,False,Projects,youtu.be,datascience,False,False
1nhzoam,Advice on presenting yourself,"Hello everyone, I recently got the chance to speak with the HR at a healthcare company that’s working on AI agents to optimize prescription pricing. While I haven’t directly built AI agents before, I’d like to design a small prototype for my hiring manager round and use that discussion to show how I can tackle their challenges. I’ve got about a week to prepare and only ~30 minutes for the conversation, so I’m looking for advice on: - How to outline the initial architecture for a project like this (at a high level). - What aspects of the design/implementation are most valuable for a hiring manager or senior engineer to see. - What to leave out and what to keep so the presentation/my pitch stays focused and impactful. Appreciate any thoughts—especially from folks who have been on the hiring side and know what really makes someone stand out. I am just a bit confused that even if I have a prototype how should I present it naturally and smartly. Edit : the goal here is to optimize the prescription price by lowering prices where it's still profitable for the company.",user_269c3c44,25,0.88,16,2025-09-15 15:06:12,https://www.reddit.com/r/datascience/comments/1nhzoam/advice_on_presenting_yourself/,https://www.reddit.com/r/datascience/comments/1nhzoam/advice_on_presenting_yourself/,True,Discussion,self.datascience,datascience,False,False
1nhskvc,How do you factor seasonality in A/B test experiments? Which methods you personally use and why?,"Hi, I was wondering how do you perform the experiment and factor the seasonality while analyzing it? (Especially on e-commerce side) For example i often wonder when marketing campaigns are done during black Friday/holiday season, how do they know whether the campaign had the causal effect? And how much? When we know people tend to buy more things in holiday season. So what test or statistical methods do you use to factor into? Or what are the other methods you use to find how the campaign performed? First i think of is use historical data of the same season for last year, and compare it, but what if we don’t have historical data? What other things need to keep in mind while designing an experiment when we know seasonality could be play big role? And there’s no way we can perform the experiment outside of season? Thanks! Edit- 2nd question, lets say we want to run a promotion during a season, like bf sale, how do you keep treatment and control? Or how do you analyze the effect of sale? As you would not want to hold out on users during sales? Or what companies do during this time to keep a control group ?",user_d2481f01,45,0.9,40,2025-09-15 10:40:28,https://www.reddit.com/r/datascience/comments/1nhskvc/how_do_you_factor_seasonality_in_ab_test/,https://www.reddit.com/r/datascience/comments/1nhskvc/how_do_you_factor_seasonality_in_ab_test/,True,Discussion,self.datascience,datascience,False,False
1nhy9qb,Free LLM API Providers,"I’m a recent graduate working on end-to-end projects. Most of my current projects are either running locally through Ollama or were built back when the OpenAI API was free. Now I’m a bit confused about what to use for deployment. I don’t plan to scale them for heavy usage, but I’d like to deploy them so they’re publicly accessible and can be showcased in my portfolio, allowing a few users to try them out. Any suggestions would be appreciated.",user_f8ba0268,10,0.67,28,2025-09-15 14:09:24,https://www.reddit.com/r/datascience/comments/1nhy9qb/free_llm_api_providers/,https://www.reddit.com/r/datascience/comments/1nhy9qb/free_llm_api_providers/,True,Challenges,self.datascience,datascience,False,False
1nhoblg,"Is an explicit ""treatment"" variable a necessary condition for instrumental variable analysis?","Hi everyone, I'm trying to model the causal impact of our marketing efforts on our ads business, and I'm considering an Instrumental Variable (IV) framework. I'd appreciate a sanity check on my approach and any advice you might have. **My Goal**: Quantify how much our marketing spend contributes to advertiser acquisition and overall ad revenue. **The Challenge**: I don't believe there's a direct causal link. My hypothesis is a two-stage process: * Stage 1: Marketing spend -> Increases user acquisition and retention -> Leads to higher Monthly Active Users (MAUs). * Stage 2: Higher MAUs -> Makes our platform more attractive to advertisers -> Leads to more advertisers and higher ad revenue. The problem is that the variable in the middle (MAUs) is endogenous. A simple regression of Ad Revenue \~ MAUs would be biased because unobserved factors (e.g., seasonality, product improvements, economic trends) likely influence both user activity and advertiser spend simultaneously. **Proposed IV Setup**: * **Outcome Variable** (Y): Advertiser Revenue. * **Endogenous Explanatory Variable** (""Treatment"") (X): MAUs (or another user volume/engagement metric). * **Instrumental Variable** (Z): This is where I'm stuck. I need a variable that influences MAUs but does not directly affect advertiser revenue, which I believe should be marketing spend. My Questions: * Is this the right way to conceptualize the problem? Is IV the correct tool for this kind of mediated relationship where the mediator (user volume) is endogenous? Is there a different tool that I could use? * This brings me to a more fundamental question: Does this setup require a formal ""experiment""? Or can I apply this IV design to historical, observational time-series data to untangle these effects? Thanks for any insights!",user_f2ae8fcb,15,0.89,14,2025-09-15 08:03:59,https://www.reddit.com/r/datascience/comments/1nhoblg/is_an_explicit_treatment_variable_a_necessary/,https://www.reddit.com/r/datascience/comments/1nhoblg/is_an_explicit_treatment_variable_a_necessary/,True,Statistics,self.datascience,datascience,False,False
1nhbvwg,"Weekly Entering & Transitioning - Thread 15 Sep, 2025 - 22 Sep, 2025","Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include: * Learning resources (e.g. books, tutorials, videos) * Traditional education (e.g. schools, degrees, electives) * Alternative education (e.g. online courses, bootcamps) * Job search questions (e.g. resumes, applying, career prospects) * Elementary questions (e.g. where to start, what next) While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",user_ac31a110,9,0.85,17,2025-09-14 21:01:19,https://www.reddit.com/r/datascience/comments/1nhbvwg/weekly_entering_transitioning_thread_15_sep_2025/,https://www.reddit.com/r/datascience/comments/1nhbvwg/weekly_entering_transitioning_thread_15_sep_2025/,True,,self.datascience,datascience,False,False
1ngj3v5,Has anyone validated synthetic financial data (Gaussian Copula vs CTGAN) in practice?,"I’ve been experimenting with generating synthetic datasets for financial indicators (GDP, inflation, unemployment, etc.) and found that CTGAN offered stronger privacy protection in simple linkage tests, but its overall analytical utility was much weaker. In contrast, Gaussian Copula provided reasonably strong privacy and far better fidelity. For example, Okun’s law (the relationship between GDP and unemployment) still held in the Gaussian Copula data, which makes sense since it models the underlying distributions. What surprised me was how poorly CTGAN performed analytically... in one regression, the coefficients even flipped signs for both independent variables. Has anyone here used synthetic data for research or production modeling in finance? Any tips for balancing *fidelity* and *privacy* beyond just model choice? If anyone’s interested in the full validation results (charts, metrics, code), let me know, I’ve documented them separately and can share the link. https://preview.redd.it/lmsmleiki2pf1.png?width=1059&format=png&auto=webp&s=19cb6d9215e590e5fe6497bc0dd7152d9d85f119",user_a710ea31,25,0.91,16,2025-09-13 22:43:07,https://www.reddit.com/r/datascience/comments/1ngj3v5/has_anyone_validated_synthetic_financial_data/,https://www.reddit.com/r/datascience/comments/1ngj3v5/has_anyone_validated_synthetic_financial_data/,True,ML,self.datascience,datascience,False,False
1ng5x61,Texts for creating better visualizations/presentations?,"I started working for an HR team and have been tasked with creating visualizations, both in PowerPoint (I've been using Seaborn and Matplotlib for visualizations) and PowerBI Dashboards. I've been having a lot of fun creating visualizations, but I'm looking for a few texts or maybe courses/videos about design. Anything you would recommend? I have this conflicting issue with either showing too little or too much. Should I have appendices or not?",user_dbc126db,30,0.92,26,2025-09-13 12:06:14,https://www.reddit.com/r/datascience/comments/1ng5x61/texts_for_creating_better/,https://www.reddit.com/r/datascience/comments/1ng5x61/texts_for_creating_better/,True,Discussion,self.datascience,datascience,False,False
1nfzxy9,Database tools and method for tree structured data?,"I have a database structure which I believe is very common, and very general, so I’m wondering how this is tackled. The database structured like: -> Project (Name of project) -> Category (simple word, ~20 categories) -> Study Study is a directory containing: - README with date & description (txt or md format) - Supporting files which can be any format (csv, xlsx, ptpx, keynote, text, markdown, pickled data frames, possible processing scripts, basically anything.) Relationships among data: - Projects can have shared studies. - Studies can be related or new versions of older ones, but can also be completely independent. Total size: - 1 TB, mostly due to supporting files found in studies. What I want: - Search database for queries describing what we are looking for. - Eventually get pointed to proper study directory and/or contents, showing all the files. - Find which studies are similar based on description category, etc. What is a good way to search such a database? Considering it’s so simple, do I even need a framework like sql?",user_a4a51182,7,0.82,5,2025-09-13 08:11:27,https://www.reddit.com/r/datascience/comments/1nfzxy9/database_tools_and_method_for_tree_structured_data/,https://www.reddit.com/r/datascience/comments/1nfzxy9/database_tools_and_method_for_tree_structured_data/,True,Tools,self.datascience,datascience,False,False
1ng1xk3,The “three tiers” of data engineering pay — and how to move up,"**The “three tiers” of data engineering pay — and how to move up (shout out to the article by geergly orosz which i placed in the bottom)** I keep seeing folks compare salaries across wildly different companies and walk away confused. A useful mental model I’ve found is that comp clusters into *three tiers* based on company type, not just your years of experience or title. Sharing this to help people calibrate expectations and plan the next move. # The three tiers * **Tier 1 — “Engineering is a cost center.”** Think traditional companies, smaller startups, internal IT/BI, or teams where data is a support function. Pay is the most modest, equity/bonuses are limited, scope is narrower, and work is predictable (reports, ELT to a warehouse, a few Airflow dags, light stakeholder churn). * **Tier 2 — “Data is a growth lever.”** Funded startups/scaleups and product-centric companies. You’ll see modern stacks (cloud warehouses/lakehouses, dbt, orchestration, event pipelines), clearer paths to impact, and some equity/bonus. companies expect design thinking and hands-on depth. Faster pace, more ambiguity, bigger upside. * **Tier 3 — “Data is a moat.”** Big tech, trading/quant, high-scale platforms, and companies competing globally for talent. Total comp can be multiples of Tier 1. hiring process are rigorous (coding + system design + domain depth). Expectations are high: reliability SLAs, cost controls at scale, privacy/compliance, streaming/near-real-time systems, complex data contracts. None of these are “better” by default. They’re just different trade-offs: stability vs. upside, predictability vs. scope, lower stress vs. higher growth. # Signals you’re looking at each tier * **Tier 1:** job reqs emphasize tools (“Airflow, SQL, Tableau”) over outcomes; little talk of SLAs, lineage, or contracts; analytics asks dominate; compensation is mainly base. * **Tier 2:** talks about metrics that move the business, experimentation, ownership of domains, real data quality/process governance; base + some bonus/equity; leveling exists but is fuzzy. * **Tier 3:** explicit levels/bands, RSUs or meaningful options, on-call for data infra, strong SRE practices, platform/mesh/contract language, cost/perf trade-offs are daily work. # If you want to climb a tier, focus on evidence of impact at scale This is what consistently changes comp conversations: * **Design → not just build.** Bring written designs for one or two systems you led: ingestion → storage → transformation → serving. Show choices and trade-offs (batch vs streaming, files vs tables, CDC vs snapshots, cost vs latency). * **Reliability & correctness.** Prove you’ve owned SLAs/SLOs, data tests, contracts, backfills, schema evolution, and incident reviews. Screenshots aren’t necessary—bullet the incident, root cause, blast radius, and the guardrail you added. * **Cost awareness.** Know your unit economics (e.g., cost per 1M events, per TB transformed, per dashboard refresh). If you’ve saved the company money, quantify it. * **Breadth across the stack.** A credible story across ingestion (Kafka/Kinesis/CDC), processing (Spark/Flink/dbt), orchestration (Airflow/Argo), storage (lakehouse/warehouse), and serving (feature store, semantic layer, APIs). You don’t need to be an expert in all—show you can choose appropriately. * **Observability.** Lineage, data quality checks, freshness alerts, SLIs tied to downstream consumers. * **Security & compliance.** RBAC, PII handling, row/column-level security, audit trails. Even basic exposure here is a differentiator. # prep that actually moves the needle * **Coding:** you don’t need to win ICPC, but you *do* need to write clean Python/SQL under time pressure and reason about complexity. * **Data system design:** practice 45–60 min sessions. Design an events pipeline, CDC into a lakehouse, or a real-time metrics system. Cover partitioning, backfills, late data, idempotency, dedupe, compaction, schema evolution, and cost. * **Storytelling with numbers:** have 3–4 impact bullets with metrics: “Reduced warehouse spend 28% by switching X to partitioned Parquet + object pruning,” “Cut pipeline latency from 2h → 15m by moving Y to streaming with windowed joins,” etc. * **Negotiation prep:** know base/bonus/equity ranges for the level (bands differ by tier). Understand RSUs vs options, vesting, cliffs, refreshers, and how performance ties to bonus. # Common traps that keep people stuck * **Tool-first resumes.** Listing ten tools without outcomes reads Tier 1. Frame with “problem → action → measurable result.” * **Only dashboards.** Valuable, but hiring loops for higher tiers want ownership of data *as a product*. * **Ignoring reliability.** If you’ve never run an incident call for data, you’re missing a lever that Tier 2/3 value highly. * **No cost story.** At scale, cost is a feature. Even a small POC that trims spend is compelling signal. # Why this matters Averages hide the spread. Two data engineers with the same YOE can be multiple tiers apart in pay purely based on company type and scope. When you calibrate to tiers, expectations and strategy get clearer. If you want a deeper read on the broader “three clusters” concept for software salaries, Gergely Orosz has a solid breakdown (“The Trimodal Nature of Software Engineering Salaries”). The framing maps neatly onto data engineering roles too. link in the bottom Curious to hear from this sub: * If you moved from Tier 1 → 2 or 2 → 3, what was the single project or proof point that unlocked it? * For folks hiring: what signals *actually* distinguish tiers in your loop? article: [https://blog.pragmaticengineer.com/software-engineering-salaries-in-the-netherlands-and-europe/](https://blog.pragmaticengineer.com/software-engineering-salaries-in-the-netherlands-and-europe/)",user_51854acf,0,0.35,4,2025-09-13 09:30:33,https://www.reddit.com/r/datascience/comments/1ng1xk3/the_three_tiers_of_data_engineering_pay_and_how/,https://www.reddit.com/r/datascience/comments/1ng1xk3/the_three_tiers_of_data_engineering_pay_and_how/,True,Discussion,self.datascience,datascience,False,False
1ne9hzv,Mid career data scientist burnout,"Been in the industry since 2012. I started out in data analytics consulting. The first 5 were mostly that, and didn't enjoy the work as I thought it wasn't challenging enough. In the last 6 years or so, I've moved to being a Senior Data Scientist - the type that's more close to a statistical modeller, not a full-stack data scientist. Currently work in health insurance (fairly new, just over a year in current role). I suck at comms and selling my work, and the more higher up I'm going in the organization, I realize I need to be strategic with selling my work, and also in dealing with people. It always has been an energy drainer for me - I find I'm putting on a front. Off late, I feel 'meh' about everything. The changes in the industry, the amount of knowledge some technical, some industry based to keep up with seems overwhelming. Overall, I chart some of these feelings to a feeling of lacking capability to handling stakeholders, lack of leadership skills in the role/ tying to expectations in the role. (also want to add that I have social anxiety). Perhaps one of the things might help is probably upskilling on the social front. Anyone have similar journeys/ resources to share? I started working with a generic career coach, but haven't found it that helpful as the nuances of crafting a narrative plus selling isn't really coming up (a lot more of confidence/ presence is what is focused on). Edit: Lots of helpful directions to move in, which has been energizing.",user_75d35b15,218,0.95,78,2025-09-11 06:56:50,https://www.reddit.com/r/datascience/comments/1ne9hzv/mid_career_data_scientist_burnout/,https://www.reddit.com/r/datascience/comments/1ne9hzv/mid_career_data_scientist_burnout/,True,Discussion,self.datascience,datascience,False,False
1negm5l,How do data scientists add value to LLMs?,"Edit: i am not saying AI is replacing DS, of course DS still do their normal job with traditional stats and ml, i am just wondering if they can play an important role around LLMs too I’ve noticed that many consulting firms and AI teams have Forward Deployed AI Engineers. They are basically software engineers who go on-site, understand a company’s problems and build software leveraging LLM APIs like ChatGPT. They don’t build models themselves, they build solutions using existing models. This makes me wonder: can data scientists add values to this new LLM wave too (where models are already built)? For example i read that data scientists could play an important role in dataset curation for LLMs. Do you think that DS can leverage their skills to work with AI eng in this consulting-like role?",user_b7a887ca,74,0.8,44,2025-09-11 11:30:56,https://www.reddit.com/r/datascience/comments/1negm5l/how_do_data_scientists_add_value_to_llms/,https://www.reddit.com/r/datascience/comments/1negm5l/how_do_data_scientists_add_value_to_llms/,True,Discussion,self.datascience,datascience,False,False
1nenrg8,An introduction to program synthesis,,user_5257546c,5,1.0,2,2025-09-11 16:21:51,https://mchav.github.io/an-introduction-to-program-synthesis/,https://www.reddit.com/r/datascience/comments/1nenrg8/an_introduction_to_program_synthesis/,False,Education,mchav.github.io,datascience,False,False
1neack3,Transitioning to MLE/MLOps from DS,"I am working as a DS with some 2 years of experience in a mid tier consultancy. I work on some model building and lot of adhoc analytics. I am from CS background and I want to be more towards engineering side. Basically I want to transition to MLE/MLOps. My major challenge is I don't have any experience with deployment or engineering the solutions at scale etc. and my current organisation doesn't have that kind of work for me to internally transition. Genuinely, what are my chances of landing in the roles I want? Any advice on how to actually do that? I feel companies will hardly shortlist profiles for MLE without proper experience. If personal projects work I can do that as well. Need some genuine guidance here.",user_b9e86d83,23,0.88,10,2025-09-11 07:30:36,https://www.reddit.com/r/datascience/comments/1neack3/transitioning_to_mlemlops_from_ds/,https://www.reddit.com/r/datascience/comments/1neack3/transitioning_to_mlemlops_from_ds/,True,Discussion,self.datascience,datascience,False,False
1ne37bs,Looking for recent research on explainable AI (XAI),I'd love to get some papers on the latest advancements on explainable AI (XAI). I'm looking for papers that are at most 2-3 years old and had an impact. Thanks!,user_8d5763e6,11,0.74,17,2025-09-11 01:18:43,https://www.reddit.com/r/datascience/comments/1ne37bs/looking_for_recent_research_on_explainable_ai_xai/,https://www.reddit.com/r/datascience/comments/1ne37bs/looking_for_recent_research_on_explainable_ai_xai/,True,Analysis,self.datascience,datascience,False,False
1ne1d5t,Collaborating with data teams,,user_29ab5623,3,0.71,4,2025-09-10 23:18:26,/r/ProductManagement/comments/1nd6p8o/collaborating_with_data_teams/,https://www.reddit.com/r/datascience/comments/1ne1d5t/collaborating_with_data_teams/,False,Discussion,,datascience,False,False
1nd94cy,(: Smile! It’s my first open source project,,user_978e380d,4,0.58,0,2025-09-10 02:02:35,/r/opensource/comments/1nd946a/smile_its_my_first_open_source_project/,https://www.reddit.com/r/datascience/comments/1nd94cy/smile_its_my_first_open_source_project/,False,Projects,,datascience,False,False
1ncmcgf,Pytorch lightning vs pytorch,"Today at work, i was criticized by a colleague for implementing my training script in pytorch instead of pytorch lightning. His rationale was that the same thing could've been done in less code using lightning, and more code means more documentation and explaining to do. I havent familiarized myself with pytorch lightning yet so im not sure if this is fair criticism, or something i should take with a grain of salt. I do intend to read the lightning docs soon but im just thinking about this for my own learning. Any thoughts?",user_8162811e,70,0.95,23,2025-09-09 08:41:08,https://www.reddit.com/r/datascience/comments/1ncmcgf/pytorch_lightning_vs_pytorch/,https://www.reddit.com/r/datascience/comments/1ncmcgf/pytorch_lightning_vs_pytorch/,True,Discussion,self.datascience,datascience,False,False
1nc93qq,I built a card recommender for EDH decks,"Hi guys! I built a simple card recommender system for the EDH format of Magic the Gathering. Unlike EDHREC which suggests cards based on overall popularity, this analyzes your full decklist and recommends cards based on similar decks. Deck similarity is computed as the sum of idf weights of shared cards. It then shows the top 100 cards from similar decks that aren't already in your decklist. It's simple but will usually give more relevant suggestions for your deck. Try it [here](https://huggingface.co/spaces/bingbong-sempai/edhrec-at-home): (Archidekt links only) Would love to hear feedback!",user_1a458984,23,0.93,17,2025-09-08 21:04:05,https://www.reddit.com/r/datascience/comments/1nc93qq/i_built_a_card_recommender_for_edh_decks/,https://www.reddit.com/r/datascience/comments/1nc93qq/i_built_a_card_recommender_for_edh_decks/,True,Projects,self.datascience,datascience,False,False
1nbxzs0,Analysing Priority zones in my Area with unprecise home adresses,"hello, My project analyzes whether given addresses fall inside ""Quartiers Prioritaires de la Politique de la Ville ""(QPV). It uses a GeoJSON file of QPV boundaries(available on the gorvernment website) and a geocoding service (Nominatim/OSM) to convert addresses into geographic coordinates. Each address is then checked with GeoPandas + Shapely to determine if its coordinates lie within any QPV polygon. The program can process one or multiple addresses, returning results that indicate whether each is located inside or outside a QPV, along with the corresponding zone name when available. This tool can be extended to handle CSV databases, produce visualizations on maps, or integrate into larger urban policy analysis workflows. "" BUUUT . here is the ultimate problem of this project , Home addresses in my area (Martinique) are notoriously unreliable if you dont know the way and google maps or Nominatim cant pinpoint most of the places in order to be converted to coordinates to say whether or not the person who gave the adress is in a QPV or not. when i use my python script on adresses of the main land like paris and the like it works just fine but our little island isnt as well defined in terms of urban planning. can someone please help me to find a way to get all the streets data into coordinates and make them match with the polygon of the QPV areas ? thank you in advance",user_223e4d36,14,0.94,13,2025-09-08 12:54:03,https://www.reddit.com/r/datascience/comments/1nbxzs0/analysing_priority_zones_in_my_area_with/,https://www.reddit.com/r/datascience/comments/1nbxzs0/analysing_priority_zones_in_my_area_with/,True,Analysis,self.datascience,datascience,False,False
1nbdtct,"Weekly Entering & Transitioning - Thread 08 Sep, 2025 - 15 Sep, 2025","Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include: * Learning resources (e.g. books, tutorials, videos) * Traditional education (e.g. schools, degrees, electives) * Alternative education (e.g. online courses, bootcamps) * Job search questions (e.g. resumes, applying, career prospects) * Elementary questions (e.g. where to start, what next) While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",user_ac31a110,9,0.92,42,2025-09-07 21:01:38,https://www.reddit.com/r/datascience/comments/1nbdtct/weekly_entering_transitioning_thread_08_sep_2025/,https://www.reddit.com/r/datascience/comments/1nbdtct/weekly_entering_transitioning_thread_08_sep_2025/,True,,self.datascience,datascience,False,False
1n9yrfy,Europe Salary Thread 2025 - What's your role and salary?,"The yearly Europe-centric salary thread. You can find the last one here: https://old.reddit.com/r/datascience/comments/1fxrmzl/europe_salary_thread_2024_whats_your_role_and/ I think it's worthwhile to learn from one another and see what different flavours of data scientists, analysts and engineers are out there in the wild. In my opinion, this is especially useful for the beginners and transitioners among us. So, do feel free to talk a bit about your work if you can and want to. 🙂 While not the focus, non-Europeans are of course welcome, too. Happy to hear from you! **Data Science Flavour:** . **Location:** . **Title:** . **Compensation (gross):** . **Education level:** . **Experience:** . **Industry/vertical:** . **Company size:** . **Majority of time spent using (tools):** . **Majority of time spent doing (role):** .",user_d3069957,185,0.95,127,2025-09-06 05:50:59,https://www.reddit.com/r/datascience/comments/1n9yrfy/europe_salary_thread_2025_whats_your_role_and/,https://www.reddit.com/r/datascience/comments/1n9yrfy/europe_salary_thread_2025_whats_your_role_and/,True,Career | Europe,self.datascience,datascience,False,False
1naptuq,🚀 Perpetual ML Suite: Now Live on the Snowflake Marketplace!,,user_8593d7f2,1,0.6,3,2025-09-07 03:31:17,/r/snowflake/comments/1n84pfn/perpetual_ml_suite_now_live_on_the_snowflake/,https://www.reddit.com/r/datascience/comments/1naptuq/perpetual_ml_suite_now_live_on_the_snowflake/,False,Tools,,datascience,False,False
1na6x3q,Help me evaluate a new job offer - Stay or go?,"Hi all, I'm having a really hard time deciding whether or not to take an offer I've recently received, would really appreciate some advice and a sense check. For context I generally feel my current role is comfortable but i'm starting to plateau after the first year, i'm also in the process of buying my dream house just to complicate things. ### **Current Role** ##### The Good - I am early 30's and have 4 years of experience as a full stack DS but am currently employed as an ML Eng for the last year. - My current role is effectively a senior/lead MLE in a small team (me + 3 DS) and I have loads of autonomy in how we do things and I get to lead my own Gen AI projects with small squads as I'm the only one with experience in this domain. - I also get to straddle DS and MLE as much or as little as I want to in other projects, which suits my interests and background. - We have some interesting projects including one I'm leading. I think I have around 6 months of cool work to do where I can personally make an impact. - My work life balance is amazing, I'm not stressed at work at all and I can learn at my own pace. - Effectively remote, go into the office 1 or 2 times per month for meetings. It's 1.5 hours away but work pay for my travel. - Can push for a senior or principal title and will likely get it in the next ~6 months. ##### The Bad - The main drawbacks here are that I don't have senior technical mentors, my direct boss has good soft skills but I have nothing to learn from him technically. He's also quite chaotic, so we are always shifting priorities etc. - It's a brand new team so we are constantly hitting blockers in terms of processes, integration of our projects and office politics. - Being a legacy insurer, innovation is really hard and momentum needed to shift opinions is huge. - Fundamentally data quality is very poor and this won't change in my tenure. - Essentially in an echo chamber, I'm bringing most of the ideas and solutions to the table in the team which potentially isn't great at this stage in my career. - It's not perfect and I'd have to leave at some point anyway. ##### Comp - Total comp including bonus and generous pension is £84K ### **New Job** AI Engineer ##### The Good - Very cool AI consultancy startup, 2 years old, ~80 technical staff and growing rapidly, already profitable with a revenue of £1mill per month and partnership with Open AI. - Lots of interesting projects with cool clients. The founders' mantra is ""cool projects, in production"" and they have some genuinely interesting case studies. - Some projects are genuinely cutting edge and they claim to have a nice balance between R&D and delivery. - Lots of technical staff to learn from, should be good for my growth. - Opportunity to work internationally in the future, the are opening offices in Australia now and eventually the US. ##### The Bad - Pigeon holing myself into AI/Agents/LLMs. No trad ML, may lose some of my very rounded skill set. - Although it's customer facing, it sounds like the role is very delivery heavy and I'd essentially be smashing out code or researching all day with less soft skill development. - Slightly worried about work culture and work life balance, this could end up being a meat grinder. - I have no experience of start ups or start up culture at all. - Less job security as its a startup. - It's mostly based in London (5 hours round trip!) and I would need to travel down relatively frequently (expenses paid) for onboarding and establishing myself in the first few months, with that requirement tapering off slowly. ##### Comp - Total offer all in is £90K, I could try and negotiate for up to £95K based on their bandings. - 36000 stock units, worthless until they sell though Would love to know your thoughts!",user_6fda9191,14,0.74,38,2025-09-06 11:27:39,https://www.reddit.com/r/datascience/comments/1na6x3q/help_me_evaluate_a_new_job_offer_stay_or_go/,https://www.reddit.com/r/datascience/comments/1na6x3q/help_me_evaluate_a_new_job_offer_stay_or_go/,True,Career | Europe,self.datascience,datascience,False,False
1nac35j,How to evaluate data transformations?,"There are several well-established benchmarks for text-to-SQL tasks like BIRD, Spider, and WikiSQL. However, I'm working on a data transformation system that handles per-row transformations with contextual understanding of the input data. The challenge is that most existing benchmarks focus on either: * Pure SQL generation (BIRD, Spider) * Simple data cleaning tasks * Basic ETL operations But what I'm looking for are benchmarks that test: * Complex multi-step data transformations * Context-aware operations (where the same instruction means different things based on data context) * Cross-column reasoning and relationships * Domain-specific transformations that require understanding the semantic meaning of data Has anyone come across benchmarks or datasets that test these more sophisticated data transformation capabilities?",user_03f8d172,1,0.57,14,2025-09-06 15:00:44,https://www.reddit.com/r/datascience/comments/1nac35j/how_to_evaluate_data_transformations/,https://www.reddit.com/r/datascience/comments/1nac35j/how_to_evaluate_data_transformations/,True,Discussion,self.datascience,datascience,False,False
1n8z37l,Just got rejected from meta,"Thought everything went well. Completed all questions for all interviews. Felt strong about all my SQL, A/B testing, metric/goal selection questions. No red flags during behavioral. Interviews provided 0 feedback about the rejection. I was talking through all my answers and reasoning, considering alternatives and explaining why I chose my approach over others. I led the discussions and was very proactive and always thinking 2 steps ahead and about guardrail metrics and stating my assumptions. The only ways I could think of improving was to answer more confidently and structure my thoughts more. Is it just that competitive right now? Even if I don’t make IC5 I thought for sure I’d get IC4. Anyone else interview with Meta recently? edit: MS degree 3.5yoe DS 4.5yoe ChemE edit2: I had 2 meta referrals but didn't use them. Should I tell the recruiter or does it not matter at this point? Meta recruiter reached out to me on LinkedIn. edit3: I remember now there was 1 moment I missed a beat, but recovered during a bernoulli distribution hand-calculation question. Maybe thats all it took... edit4: Thanks everyone for the copium, words of advice, and support.",user_7053dccc,305,0.9,160,2025-09-05 00:50:18,https://www.reddit.com/r/datascience/comments/1n8z37l/just_got_rejected_from_meta/,https://www.reddit.com/r/datascience/comments/1n8z37l/just_got_rejected_from_meta/,True,Career | US,self.datascience,datascience,False,False
1n8lhdx,MIT says AI isn’t replacing you… it’s just wasting your boss’s money,,user_b85d427c,570,0.94,61,2025-09-04 13:37:39,https://www.interviewquery.com/p/mit-ai-isnt-replacing-workers-just-wasting-money,https://www.reddit.com/r/datascience/comments/1n8lhdx/mit_says_ai_isnt_replacing_you_its_just_wasting/,False,Discussion,interviewquery.com,datascience,False,False
1n88v2y,Almost 2 years into my first job... and already disillusioned and bored with this career,"**TL;DR: I find this industry to be very unengaging, with most use cases and positions being very brainless, sluggish and just uninspiring. I am only 2 years into this job and bored and I feel like I need to shake things up a bit to keep doing this for the rest of my life.** Full disclosure: **this is very much a first world problem**. I get paid quite well, I have incredibly lenient work life balance, I work from home 3 days a week, etc etc. Most people would kill to be in my position at my age. Some context: I was originally in academia doing a PhD in math, but pure math, completely unrelated to ML or anything in the real world really. ~2 years in, I was disillusioned with that (sensing a pattern here lol) so I took as many ML courses I could and jumped ship to industry. Regardless of all the problems I had in academia, it at least *asked* something of me. I had to think, like, *actually think*, about complex, interesting stuff. It felt like I was actually engaging my mind and growing. My current job is fine, basically applying LLMs for various use cases at a megacorp. On paper, I'm playing with the latest, greatest, tech, but in practice, I'm just really calling APIs on products that smarter people are building. I feel like I haven't actually flexed my brain muscles in years now, I'm forgetting all the stuff I've learnt at college, and the work itself is incredibly boring to me. Many many days I can barely bring myself to work as the work is so uninteresting, and the bare minimum I put in still somehow impresses my colleagues so there's no real incentive to work hard. I realize how privileged that sounds, I really do, but I do feel kind of unfulfilled and spiritually empty. I feel like if I keep doing this for the rest of my life I will look back with regret. **What I'm trying to do to fix this:** I would like to shift towards more cutting edge and harder data science. Problem here is a lack of qualifications and experience. I have a MS and a BS in Math (from T10 colleges) but no PhD and the math I studied was mostly pure/theoretical, very little to do with ML. I'm trying to do projects in my own time, but it's slow going on my own. I would love to aim for ML/AI research roles, but it feels like an impossible ask without a PhD, without papers, etc etc. I'm not sure that's a feasible goal. Another thing I've been considering is playing a DS/ML role as support in research that's *not* ML. For instance, bioinformatics or biotech, etc. This is also fairly appealing to me. The main issue is here is a complete lack of knowledge about these fields (since there can be so many fields here) and a lack of domain knowledge which I presume is required. I'm still trying, I've been applying for some bioinformatics roles, but yeah, also hard. **Has anyone else felt this way? What did they do about it, and what would you recommend?**",deleted_user,279,0.9,113,2025-09-04 05:32:48,https://www.reddit.com/r/datascience/comments/1n88v2y/almost_2_years_into_my_first_job_and_already/,https://www.reddit.com/r/datascience/comments/1n88v2y/almost_2_years_into_my_first_job_and_already/,True,Discussion,self.datascience,datascience,False,False
1n8a1do,"A portfolio project for Data Scientists looking to add AI Engineering skills (Pytest, Security, Docker).","Hey guys, Like many of us, I'm comfortable in a Jupyter Notebook, but I found there's a huge gap when it comes to building and deploying a real, full-stack AI application. I created a project specifically to bridge that gap. You build a ""GitHub Repo Analyst"" agent, but the real learning is in the production-level engineering skills that often aren't part of a data science workflow: - Automated Testing: Writing Pytest integration tests to verify your agent's security. - Building UIs: Creating an interactive web app with Chainlit. - Deployment: Packaging your entire application with Docker for easy, reproducible deployment. I've turned this into a 10-lesson guide and am looking for 10-15 beta testers. If you're a data scientist who wants to add a serious AI engineering project to your portfolio, I'll give you the complete course for free in exchange for your feedback. Just comment below if you're interested, and I'll send you a DM.",user_727b5fb9,80,0.9,111,2025-09-04 06:24:34,https://www.reddit.com/r/datascience/comments/1n8a1do/a_portfolio_project_for_data_scientists_looking/,https://www.reddit.com/r/datascience/comments/1n8a1do/a_portfolio_project_for_data_scientists_looking/,True,Education,self.datascience,datascience,False,False
1n81chu,"What's up with LinkedIn posts saying ""Excel is dead"", ""dashboards are dead"", ""data science is dead"", ""PPTs are dead"" and so on?","Is this a trend now? I also read somewhere ""SQL is dead"" too. Ffs. What isn't dead anyway for these Linkfluencers? Only LLMs? And then you hear mangers and leadership parrtoting the same LinkedIn bullshit in team meetings... where is all this going?",user_ae37e5e3,136,0.88,101,2025-09-03 22:05:25,https://www.reddit.com/r/datascience/comments/1n81chu/whats_up_with_linkedin_posts_saying_excel_is_dead/,https://www.reddit.com/r/datascience/comments/1n81chu/whats_up_with_linkedin_posts_saying_excel_is_dead/,True,Discussion,self.datascience,datascience,False,False
1n81hrr,How are you liking Positron?,"I’m an undergraduate student double majoring in Data Analytics and Data Engineering and have used VSCode, Jupyter Notebook, Google Colab, and PyCharm Community Edition during my different Python courses. I haven’t used Positron yet, but it looks really appealing since I enjoy the VSCode layout and notebook style programming. Anyone with experience using Position, I’d greatly appreciate any information on how you’ve liked (or not liked) it. Thanks!",user_fbc1579b,26,0.76,21,2025-09-03 22:14:10,https://www.reddit.com/r/datascience/comments/1n81hrr/how_are_you_liking_positron/,https://www.reddit.com/r/datascience/comments/1n81hrr/how_are_you_liking_positron/,True,Discussion,self.datascience,datascience,False,False
1n83iok,Would you volunteer to join the team building AI tooling? If you have what has been your experience?,"I just learned a colleague that was part of the AI tooling team is leaving and I am considering whether to ask to be added to their old project team. I am a data scientist and while I have not had too many ML projects recently, I have some lined up for next quarter. Their team was building the tooling to build agents for use internally and customer facing. That team has obviously gotten a lot of shout out from the CEO. Their early products are well received. I prefer ML over AI tooling but also feel there is a new reality for my next job in that I should be above average in AI usage and development. And thus I feel that being part of the AI team would be beneficial for my career. So my question is. Should I ask to join the AI team? Have others done this - what has been experienced? Anything to look out for/any ways to shape the my potential journey in that team?",user_1d271d12,0,0.4,9,2025-09-04 00:19:47,https://www.reddit.com/r/datascience/comments/1n83iok/would_you_volunteer_to_join_the_team_building_ai/,https://www.reddit.com/r/datascience/comments/1n83iok/would_you_volunteer_to_join_the_team_building_ai/,True,Career | Europe,self.datascience,datascience,False,False
1n7ops6,Freelance search,Any website to work as freelancer besides upwork ?,user_aa833f17,3,0.62,21,2025-09-03 12:39:45,https://www.reddit.com/r/datascience/comments/1n7ops6/freelance_search/,https://www.reddit.com/r/datascience/comments/1n7ops6/freelance_search/,True,Discussion,self.datascience,datascience,False,False
1n6so7m,I built a simulation tool for students to learn causal inference!,"\- Building a good intuition for causal inference methods requires you to play around with assumptions and data, but getting data from a paper and replicating the results takes time. \- **I made a simulation tool to help students quickly build an intuition for these methods (currently only difference-in-difference is available).** This tool is great for the undergraduate level (as I am still a student so the content covered isn't super advanced) This is still a proof-of-concept, but would love your feedback and what other methods you would like to see! Link: [https://causal-buddy.streamlit.app/](https://causal-buddy.streamlit.app/)",user_d21cbda6,166,0.98,26,2025-09-02 12:14:27,https://www.reddit.com/r/datascience/comments/1n6so7m/i_built_a_simulation_tool_for_students_to_learn/,https://www.reddit.com/r/datascience/comments/1n6so7m/i_built_a_simulation_tool_for_students_to_learn/,True,Projects,self.datascience,datascience,False,False
1n70lcz,A/B Testing Overview,Sharing this as a guide on A/B Testing. I hope that it can help those preparing for interviews and those unfamiliar with the wide field of experimentation. Any feedback would be appreciated as we're always on a learning journey.,user_5444d864,37,0.86,8,2025-09-02 17:35:36,https://medium.com/@joshamayo7/continuous-improvement-through-online-experimentation-a72406b0ee3d,https://www.reddit.com/r/datascience/comments/1n70lcz/ab_testing_overview/,False,Analysis,medium.com,datascience,False,False
1n7zgzy,"Per row context understanding is hard for SQL and RAG databases, here's how we solved it with LLMs","Traditional databases rely on RAG and vector databases or SQL-based transformations/analytics. But will they be able to preserve per-row contextual understanding? We’ve released Agents as part of Datatune: [https://github.com/vitalops/datatune](https://github.com/vitalops/datatune) In a single prompt, you can define multiple tasks for data transformations, and Datatune performs the transformations on your data at a per-row level, with contextual understanding. Example prompt: ""Extract categories from the product description and name. Keep only electronics products. Add a column called ProfitMargin = (Total Profit / Revenue) \* 100"" Datatune interprets the prompt and applies the right operation (map, filter, or an LLM-powered agent pipeline) on your data using OpenAI, Azure, Ollama, or other LLMs via LiteLLM. Key Features \- Row-level map() and filter() operations using natural language \- Agent interface for auto-generating multi-step transformations \- Built-in support for Dask DataFrames (for scalability) \- Works with multiple LLM backends (OpenAI, Azure, Ollama, etc.) \- Compatible with LiteLLM for flexibility across providers \- Auto-token batching, metadata tracking, and smart pipeline composition Token & Cost Optimization \- Datatune gives you explicit control over which columns are sent to the LLM, reducing token usage and API cost: \- Use input\_fields to send only relevant columns \- Automatically handles batching and metadata internally \- Supports setting tokens-per-minute and requests-per-minute limits \- Defaults to known model limits (e.g., GPT-3.5) if not specified \- This makes it possible to run LLM-based transformations over large datasets without incurring runaway costs.",user_03f8d172,0,0.31,5,2025-09-03 20:24:05,https://www.reddit.com/r/datascience/comments/1n7zgzy/per_row_context_understanding_is_hard_for_sql_and/,https://www.reddit.com/r/datascience/comments/1n7zgzy/per_row_context_understanding_is_hard_for_sql_and/,True,Projects,self.datascience,datascience,False,False
1n6ez8o,Is it wrong to be specialized in specific DS niche?,"Hello fellows Data Scientists! I’m coming with question/discussion about specialization in specific part of Data Science. For a long time my main duty is time series and predictive projects, mainly around finance but in retail domain. As an example, project where I predict sales per hour for month up front, later I place matrix with amount of staff needed on specific station to minimize number of employees present in the location (lot of savings in labor costs). Lately I attended few interviews, that didn’t go flawlessly from my side - most of questions were around classification problems, where most of my knowledge is in regression problems, of course I’m blaming myself on every attempt where I didn’t receive an offer because of technical interview and there is no discussion that I could prepare myself in more broad knowledge. But here comes my question, is it possible to know deeply every kind of niche knowledge when your main work spins around specific problems? I’m sure there are lot of DS which work for past 10 years or so and because of number of projects they’re familiar with a lot of specific problems, but for someone with 3 yoe is it doable? I feel like I’m very good in tackling time series problems, but as an example, my knowledge in image recognition is very limited, did you face problem like that? What are your thoughts? How did you overcome this in your career?",user_28327cc9,33,0.75,55,2025-09-02 02:33:59,https://www.reddit.com/r/datascience/comments/1n6ez8o/is_it_wrong_to_be_specialized_in_specific_ds_niche/,https://www.reddit.com/r/datascience/comments/1n6ez8o/is_it_wrong_to_be_specialized_in_specific_ds_niche/,True,Discussion,self.datascience,datascience,False,False
1n70y9a,Diffusion models,"What position do Diffusion models take in the spectrum of architectures to AGI like compared to jepa, auto-regressive modelling and others ? are they RL-able ?",user_d6ae43c2,0,0.5,8,2025-09-02 17:52:14,https://www.reddit.com/r/datascience/comments/1n70y9a/diffusion_models/,https://www.reddit.com/r/datascience/comments/1n70y9a/diffusion_models/,True,Discussion,self.datascience,datascience,False,False
1n6cug7,The Hidden Costs of Naive Retrieval,"We often treat Retrieval-Augmented Generation (RAG) as the default solution for knowledge-intensive tasks, but the naive 'retrieve-then-read' paradigm has significant hidden costs that can hurt, rather than help, performance. So, when is it better not to retrieve? This series on **Adaptive RAG** starts by exploring the hidden costs of our default RAG implementations by looking at three key areas: * **The Practical Problems:** These are the obvious unnecessary latency and compute overhead for simple or popular queries where the LLM's parametric memory would have been enough. * **The Hidden Dangers:** There are more subtle risks to quality. Noisy or misleading context can lead to ""External Hallucinations,"" where the retriever itself induces factual errors in an otherwise correct model. * **The Foundational Flaws:** Finally, the ""retrieval advantage"" can shrink as models scale.",user_bf3bb238,0,0.5,0,2025-09-02 00:12:42,https://blog.reachsumit.com/posts/2025/09/problems-with-naive-rag/,https://www.reddit.com/r/datascience/comments/1n6cug7/the_hidden_costs_of_naive_retrieval/,False,ML,blog.reachsumit.com,datascience,False,False
1n5eqdj,"Weekly Entering & Transitioning - Thread 01 Sep, 2025 - 08 Sep, 2025","Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include: * Learning resources (e.g. books, tutorials, videos) * Traditional education (e.g. schools, degrees, electives) * Alternative education (e.g. online courses, bootcamps) * Job search questions (e.g. resumes, applying, career prospects) * Elementary questions (e.g. where to start, what next) While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",user_ac31a110,9,0.75,29,2025-08-31 21:01:46,https://www.reddit.com/r/datascience/comments/1n5eqdj/weekly_entering_transitioning_thread_01_sep_2025/,https://www.reddit.com/r/datascience/comments/1n5eqdj/weekly_entering_transitioning_thread_01_sep_2025/,True,,self.datascience,datascience,False,False
1n4n1qz,How do I prepare for my data science job as a new grad?,"I just graduated from my bachelors in May. Recently, I’ve been fortunate enough to receive an offer as a data scientist I at a unicorn where most of the people on the ds team have PhDs. My job starts in a month and I’m having massive imposter syndrome, especially since my coding skills are kinda shit. I can barely do leetcode mediums. The job description is also super vague, only mentioning ML models and data analysis, so idk what specific things I should brush up on. What can I do in this month to make sure I do a good job?",user_e4a05cfc,102,0.9,36,2025-08-30 22:57:00,https://www.reddit.com/r/datascience/comments/1n4n1qz/how_do_i_prepare_for_my_data_science_job_as_a_new/,https://www.reddit.com/r/datascience/comments/1n4n1qz/how_do_i_prepare_for_my_data_science_job_as_a_new/,True,Discussion,self.datascience,datascience,False,False
1n4rufc,Let’s Build Something Together,"Hey everyone, After my last post about my struggles in finding a remote job, I was honestly blown away. I got over 50 messages not with job offers, but with stories, frustrations, and suggestions. The common theme? Many of us are stuck. Some are trying to break into the market, others are trying to move within it, and many just want to *make something meaningful*. That really got me thinking: since this subreddit is literally about connecting data scientists, engineers, PMs, MLOps folks, researchers, and builders of all kinds why don’t we **actually build something together**? It doesn’t have to be one massive project; it could be multiple smaller ones. The goal wouldn’t just be to pad CVs, but to collaborate, learn, and create something that matters. Think hackathon energy, but async and community-driven with no time limits and frustration. I am personally interested to get involved with things i haven't been yet. Mlops,Deployment,Cloud,Azure,pytorch,Apache for example. Everyone can find their opening and what they want to improve and try and work with other experience people on this that could help them. This would literally need * Data scientists / analysts * Software engineers * MLOps / infra people * Project managers * Researchers / scientists * Anyone who wants to contribute Build something real with others (portfolio > buzzwords) * Show initiative and collaboration on your CV/LinkedIn * Make connections that could lead to opportunities * Turn frustration into creation I’d love to hear your thoughts: * Would you be interested in joining something like this? * What kind of projects would excite you (open-source tools, research collabs, data-for-good, etc.)? * Should we organize a first call/Discord/Slack group to test the waters? I am waiting for connecting with you on Linkedin and here. PS1: Yeah I am not talkig about creating a product or building the new chatgpt. Just communication and brainstorming . Working on some ideas or just simply get to know some people.",user_580bb174,41,0.76,50,2025-08-31 04:02:32,https://www.reddit.com/r/datascience/comments/1n4rufc/lets_build_something_together/,https://www.reddit.com/r/datascience/comments/1n4rufc/lets_build_something_together/,True,Discussion,self.datascience,datascience,False,False
1n4bamu,Advice for DS/AS/MLE interviews,"I am looking for data scientist (ML heavy), applied scientist or ML engineer roles in product based companies. For my interview preperation, I am unsure about which book or resources to pick so that I can cover the rigor of ML rounds in these interviews. I have background in CS and have fair knowledge of ML. Anyone who cracked such roles or have any experience that can help me? PS: I was considering reading Kevin Murphy's ML book but it is too heavy on math so I am not sure if that much of rigor is required for these kind of interviews. I am not looking for research roles.",user_b9e86d83,42,0.9,20,2025-08-30 13:10:15,https://www.reddit.com/r/datascience/comments/1n4bamu/advice_for_dsasmle_interviews/,https://www.reddit.com/r/datascience/comments/1n4bamu/advice_for_dsasmle_interviews/,True,Discussion,self.datascience,datascience,False,False
1n4ecoo,Career Dilemma,,user_7fefbbd8,0,0.45,2,2025-08-30 15:23:29,/r/cscareerquestionsuk/comments/1n4ec3k/career_dilemma/,https://www.reddit.com/r/datascience/comments/1n4ecoo/career_dilemma/,False,Discussion,,datascience,False,False
1n3jnpw,How do you design a test to compare two audience targeting methods?,"So we have two audiences we want to test against each other. The first is one we're currently using and the second is a new audience. We want to know if a campaign using the new audience targeting method can match or exceed an otherwise identical campaign using our current targeting. We're conducting the test on Amazon DSP and the Amazon representative recommended basically intersecting each audience with a randomized set of holdout groups. So for audience A the test cell will be all users in audience A and also in one group of randomized holdouts and similarly for audience B (with a different set of randomized holdouts) Our team's concern is that if each campaign is getting a different set of holdout groups then we wouldn't have the same baseline. My boss is recommending we use the same set of holdout groups for both. My personal concern for that is if we'd have a proper isolation (e.g. if one user sees an ad from the campaign using audience A and also an ad from the campaign using audience B, then which audience targeting method gets credit). I think my boss' approach is probably the better design, but the overlap issue stands out to me as a complication. I'll be honest that I've never designed an A/B test before, much less on audiences, so any help at all is appreciated. I've been trying to understand how other platforms do this because Amazon does seem a bit different - as in, how (in an ideal universe) would you test two audiences against each other?",user_421d0130,22,0.89,13,2025-08-29 14:22:32,https://www.reddit.com/r/datascience/comments/1n3jnpw/how_do_you_design_a_test_to_compare_two_audience/,https://www.reddit.com/r/datascience/comments/1n3jnpw/how_do_you_design_a_test_to_compare_two_audience/,True,Statistics,self.datascience,datascience,False,False
1n2o7c1,"Free 1,000 CPU + 100 GPU hours for testers","I believe it should be dead simple for data scientists, analysts, and researchers to scale their code in the cloud without relying on DevOps. At my last company, whenever the data team needed to scale workloads, we handed it off to DevOps. They wired it up in Airflow DAGs, managed the infrastructure, and quickly became the bottleneck. When they tried teaching the entire data team how to deploy DAGs, it fell apart and we ended up back to queuing work for DevOps. That experience pushed me to build cluster compute software that makes scaling dead simple for any Python developer. With a single function you can deploy to massive clusters (10k vCPUs, 1k GPUs). You can bring your own Docker image, define hardware requirements, run jobs as background tasks you can fire and forget, and kick off a million simple functions in seconds. It’s [open source](https://github.com/Burla-Cloud/burla) and I’m still making install easier, but I also have a few managed versions. Right now I’m looking for test users running embarrassingly parallel workloads like data prep, hyperparameter tuning, batch inference, or Monte Carlo simulations. If you’re interested, email me at [**joe@burla.dev**]() and I’ll set you up with a managed cluster that includes 1,000 CPU hours and 100 GPU hours. Here’s an example of it in action: I spun up 4k vCPUs to screenshot 30k arXiv PDFs and push them to GCS in just a couple minutes: [https://x.com/infra\_scale\_5/status/1938024103744835961](https://x.com/infra_scale_5/status/1938024103744835961?utm_source=chatgpt.com) Would love testers.",user_d20acd83,4,0.67,6,2025-08-28 14:03:04,https://www.reddit.com/r/datascience/comments/1n2o7c1/free_1000_cpu_100_gpu_hours_for_testers/,https://www.reddit.com/r/datascience/comments/1n2o7c1/free_1000_cpu_100_gpu_hours_for_testers/,True,Projects,self.datascience,datascience,False,False
1n1tk23,Rejected after 3rd round live coding OA round,"As the title says, I made it to the 3rd round interview for a Staff DS role. Thought I was doing well, but I bombed the coding portion, I only managed to outline my approach instead of producing actual code. That’s on me, mostly because I’ve gotten used to relying on GPT to crank out code for me over the last two years. Most of what I do is build POCs, check hypotheses, then have GPT generate small snippets that I review for logic before applying it. I honestly haven’t done “live coding” in a while. Before the interview, I prepped with DataLemur for the pandas related questions and brushed up on building simple NNs and GNNs from scratch to cover the conceptual/simple DS side. A little bit on the transformer module as well to have my bases cover if they ask for it. I didn’t expect a LeetCode-style live coding question. I ended up pseudo-coding it, then stumbling hard when I tried to actually implement it. Got the rejection email today. Super heartbreaking to see. Do I go back to live-coding and memorizing syntax and practicing leetcodes for upcoming future DS interview?",user_fa61af0b,94,0.83,65,2025-08-27 14:21:48,https://www.reddit.com/r/datascience/comments/1n1tk23/rejected_after_3rd_round_live_coding_oa_round/,https://www.reddit.com/r/datascience/comments/1n1tk23/rejected_after_3rd_round_live_coding_oa_round/,True,Career | US,self.datascience,datascience,False,False
1n1zo5y,Why is Typescript starting to gain adoption in AI?,"I've noticed that, increasingly, using TypeScript has become more common for AI tools. For example, Langgraph has Langgraph.js for Typescript developers. Same with OpenAI's Agents SDK. I've also seen some AI engineer job openings for roles that use both Python and Typescript. Python still seems to be dominant, but it seems like Typescript is definitely starting to gain traction in the field. So why is this? Why the appeal of building AI apps in Typescript? It wasn't originally like this with more traditional ML / deep learning, where Python was so dominant. Why is it gaining increasing adoption and what's the appeal?",user_71edf8bc,25,0.84,38,2025-08-27 18:48:26,https://www.reddit.com/r/datascience/comments/1n1zo5y/why_is_typescript_starting_to_gain_adoption_in_ai/,https://www.reddit.com/r/datascience/comments/1n1zo5y/why_is_typescript_starting_to_gain_adoption_in_ai/,True,Discussion,self.datascience,datascience,False,False
1n28ukj,I built Runcell - an AI agent for Jupyter that actually understands your notebook context,"I've been working on something called Runcell that I think fills a gap I was frustrated with in existing AI coding tools. **What it is:** Runcell is an AI agent that lives inside JupyterLab (can be used as an extension) and can understand the full context of your notebook - your data, charts, previous code, kernel state, etc. Instead of just generating code, it can actually edit and execute specific cells, read/write files, and take actions on its own. **Why I built it:** I tried Cursor and Claude Code, but they mostly just generate a bunch of cells at once without really understanding what happened in previous steps. When I'm doing data science work, I usually need to look at the results from one cell before deciding what to write next. That's exactly what Runcell does - it analyzes your previous results and decides what code to run next based on that context. **How it's different:** * vs AI IDEs like Cursor: Runcell focuses specifically on building context for Jupyter environments instead of treating notebooks like static files * vs Jupyter AI: Runcell is more of an autonomous agent rather than just a chatbot - it has tools to actually work and take actions You can try it with just `pip install runcell`. I'm looking for feedback from the community. Has anyone else felt this frustration with existing tools? Does this approach make sense for your workflow?",user_a907813a,0,0.48,7,2025-08-28 03:44:16,https://www.reddit.com/r/datascience/comments/1n28ukj/i_built_runcell_an_ai_agent_for_jupyter_that/,https://www.reddit.com/r/datascience/comments/1n28ukj/i_built_runcell_an_ai_agent_for_jupyter_that/,True,Tools,self.datascience,datascience,False,False
1n105of,Airbnb Data,"Hey everyone, I work on the data team at [AirROI](https://www.airroi.com). For a while, we offered free datasets for about **250** cities, but we always wanted to do more for the community. Recently, we just expanded our free public dataset from \~250 to nearly **1000** global Airbnb markets on **properties** and **pricing data**. As far as we know, this makes it the single **largest free Airbnb dataset** ever released on the internet. You can browse the collection and download here, no sign-up required: [Airbnb Data](http://www.airroi.com/data-portal) **What’s in the data?** For each market (cities, regions, etc.), the CSV dumps include: Property Listings: Details like room type, amenities, number of bedrooms/bathrooms, guest capacity, etc. Pricing Data: This is the cool part. We include historical rates, future calendar rates (for investment modeling), and minimum/maximum stay requirements. Host Data: Host ID, superhost status, and other host-level metrics. **What can you use it for?** This is a treasure trove for: Trend Analysis: Track pricing and occupancy trends across the globe. Investment & Rental Arbitrage Analysis: Model potential ROI for properties in new markets. Academic Research: Perfect for papers on the sharing economy, urban development, or tourism. Portfolio Projects: Build a killer dashboard or predictive model for your GitHub. General Data Wrangling Practice: It's real, messy, world-class data. **A quick transparent note**: If you need hyper-specific or real-time data for a region not in the free set, we do have a ridiculously cheap [Airbnb API](https://www.airroi.com/api) to get more customized data. Alternatively, if you are a researcher who wants a larger customized data just reach out to us, we'll try our best to support! If you require something that's not currently in the free dataset please comment below, we'll try to accommodate within reason. Happy analyzing and go building something cool! [Airbnb Data](https://preview.redd.it/vi9bjqphxflf1.png?width=3038&format=png&auto=webp&s=6953d029e8bc9aa21280b411df543d3b5bbc3d66) [Download Airbnb Data](https://preview.redd.it/ydtx5oqjxflf1.png?width=1920&format=png&auto=webp&s=bb4f4dfc361d83734a1c088750d8167e1327bdae)",user_f6d0ce56,334,0.98,41,2025-08-26 15:36:44,https://www.reddit.com/r/datascience/comments/1n105of/airbnb_data/,https://www.reddit.com/r/datascience/comments/1n105of/airbnb_data/,True,Discussion,self.datascience,datascience,False,False
1n035we,Is the market really like this? The reality for a recent graduate looking for opportunities.,"Hello . I’m a recent Master of Science in Analytics graduate from Georgia Tech (GPA 3.91, top 5% of my class). I completed a practicum with Sandia Labs and I’m currently in discussions about further research with GT and SANDIA. I’m originally from Greece and I’ve built a strong portfolio of projects, ranging from classic data analysis and machine learning to a Resume AI chatbot. I entered the job market feeling confident, but I’ve been surprised and disappointed by how tough things are here. The Greek market is crazy: I’ve seen openings that attract 100 applicants and still offer very low pay while expecting a lot. I’m applying to junior roles and have gone as far as seven interview rounds that tested pandas, PyTorch, Python, LeetCode-style problems, SQL, and a lot of behavioral and technical assessments. Remote opportunities seem rare on EUROPE or US. I may be missing something, but I can’t find many remote openings. This isn’t a complaint so much as an expression of frustration. It’s disheartening that a master’s from a top university, solid skills, hands-on projects, and a real practicum can still make landing a junior role so difficult. I’ve also noticed many job listings now list deep learning and PyTorch as mandatory, or rebrand positions as “AI engineer,” even when it doesn’t seem necessary. On a positive note, I’ve had strong contacts reach out via LinkedIn though most ask for relocation, which I can’t manage due to family reasons. I’m staying proactive: building new projects, refining my interviewing skills, and growing my network. I’d welcome any advice, referrals, or remote-friendly opportunities. Thank you! PS. If you comment your job experience state your country to get a picture of the worldwide problem. PS2. Started as an attempt for networking and opportunities, came down to an interesting realistic discussion. Still sad to read, what's the future of this job? What will happen next? What recent grads and on university juniors should be doing? Ps3. If anyone wants to connect send me a message",user_580bb174,207,0.92,133,2025-08-25 14:24:24,https://www.reddit.com/r/datascience/comments/1n035we/is_the_market_really_like_this_the_reality_for_a/,https://www.reddit.com/r/datascience/comments/1n035we/is_the_market_really_like_this_the_reality_for_a/,True,Discussion,self.datascience,datascience,False,False
1mzzzu7,"We are back with many Data science jobs in Soccer, NFL, NHL, Formula1 and more sports! 2025-08","Hey guys, I've been silent here lately but many opportunities keep appearing and being posted. These are a few from the last 10 days or so * [Quantitative Analyst Associate (Spring/Summer 2026) - Philadelphia Phillies](http://www.sportsjobs.online/jobs/9015-quantitative-analyst-associate-spring-summer-2026?utm_source=sportsjobs-online.beehiiv.com&utm_medium=newsletter&utm_campaign=new-jobs-in-sports-analytics-how-to-learn-analytics-quickly-from-a-youtube-sports-channel&_bhlid=24b4748bef795f9a693e2911693d223c99632356) * [Senior Sports Data Scientist - ESPN](http://www.sportsjobs.online/jobs/9018-senior-sports-data-scientist?utm_source=sportsjobs-online.beehiiv.com&utm_medium=newsletter&utm_campaign=new-jobs-in-sports-analytics-how-to-learn-analytics-quickly-from-a-youtube-sports-channel&_bhlid=58166f06c2cb14a5f60c555a80e63eff791ece6a) * [Baseball Analyst/Data Scientist - Miami Marlins](http://www.sportsjobs.online/jobs/9014-baseball-analyst-data-scientist?utm_source=sportsjobs-online.beehiiv.com&utm_medium=newsletter&utm_campaign=new-jobs-in-sports-analytics-how-to-learn-analytics-quickly-from-a-youtube-sports-channel&_bhlid=7d5181c9bd523683761c79ffcd23fafab8877728) * [Data Engineer, Athletics - University of Pittsburgh](http://www.sportsjobs.online/jobs/8992-data-engineer-athletics?utm_source=sportsjobs-online.beehiiv.com&utm_medium=newsletter&utm_campaign=new-jobs-in-sports-analytics-how-to-learn-analytics-quickly-from-a-youtube-sports-channel&_bhlid=90aede97e283411c5e9a31b34a982299320cc5e6) * [Senior Data Scientist - Tottenham Hotspur](http://www.sportsjobs.online/jobs/8997-senior-data-scientist?utm_source=sportsjobs-online.beehiiv.com&utm_medium=newsletter&utm_campaign=new-jobs-in-sports-analytics-how-to-learn-analytics-quickly-from-a-youtube-sports-channel&_bhlid=e35ef1aeb7939cd356689d46e49afdff95535e1a) * [Sports Scientist - Human Data Science - McLaren Racing](http://www.sportsjobs.online/jobs/8996-sports-scientist-human-data-science?utm_source=sportsjobs-online.beehiiv.com&utm_medium=newsletter&utm_campaign=new-jobs-in-sports-analytics-how-to-learn-analytics-quickly-from-a-youtube-sports-channel&_bhlid=e40bd45b1f6178064b5c7cf165f65e5821c8ad0d) * [Lead Engineer - Phoenix Suns](http://www.sportsjobs.online/jobs/8981-lead-engineer?utm_source=sportsjobs-online.beehiiv.com&utm_medium=newsletter&utm_campaign=new-jobs-in-sports-analytics-how-to-learn-analytics-quickly-from-a-youtube-sports-channel&_bhlid=841248c85b1774cec3812e308b803fbcaa9b570e) * [Business Intelligence Intern - Houston Texans](http://www.sportsjobs.online/jobs/8967-business-intelligence-intern?utm_source=sportsjobs-online.beehiiv.com&utm_medium=newsletter&utm_campaign=new-jobs-in-sports-analytics-how-to-learn-analytics-quickly-from-a-youtube-sports-channel&_bhlid=35c476cde3ddf380fbd3d5f4beccd3424bdcb356) * [Technical Data Analyst - Portland Timbers](http://www.sportsjobs.online/jobs/8953-technical-staff-data-analyst-mls?utm_source=sportsjobs-online.beehiiv.com&utm_medium=newsletter&utm_campaign=new-jobs-in-sports-analytics-how-to-learn-analytics-quickly-from-a-youtube-sports-channel&_bhlid=14f0d07bcd9a80d670a7cc018bb6d16d6e2e9c2b) I run www.sportsjobs(.)online, a job board in that niche. In the last month I added around 300 jobs. For the ones that already saw my posts before, I've added more sources of jobs lately. I'm open to suggestions to prioritize the next batch. It's a niche, there aren't thousands of jobs as in Software in general but my commitment is to **keep improving a simple metric, jobs per month.** We always need some metric in DS.. I run also a newsletter to receive emails with jobs and interesting content on sports analytics (next edition tomorrow!) [https://sportsjobs-online.beehiiv.com/subscribe](https://sportsjobs-online.beehiiv.com/subscribe) Finally, I've created also a [reddit community](https://www.reddit.com/r/sports_jobs/) where I post recurrently the openings if that's easier to check for you. I hope this helps someone!",user_e7a0329a,117,0.94,22,2025-08-25 12:23:56,https://www.reddit.com/r/datascience/comments/1mzzzu7/we_are_back_with_many_data_science_jobs_in_soccer/,https://www.reddit.com/r/datascience/comments/1mzzzu7/we_are_back_with_many_data_science_jobs_in_soccer/,True,Career | US,self.datascience,datascience,False,False
1n0ep0g,How do I make the most of this opportunity,"Hello everyone, I’m a senior studying data science at a large state school. Recently, through some networking, I got to interview with a small real estate and financial data aggregator company with around \~100 employees. I met with the CEO for my interview. As far as I know, they haven’t had an engineering or science intern before, mainly marketing and business interns. The firm has been primarily a more traditional real estate company for the last 150 years. Many tasks are done through SQL queries and Excel. Much of the product team at the company has been there for over 20 years and is resistant to change. The ceo wants to make the company more efficient and modern, and implement some statistical and ML models and automated workflows with their large amounts of data. He has given me some of the ideas that he and others at the company have considered. I will list those at the end. But I am starting to feel that I’m a bit in over my head here as he hinted towards using my work as a proof of concept to show the board that these new technologies and techniques r what the company needs to stay relevant and competitive. As someone who is just wrapping up their undergrad, some of it feels beyond my abilities if I’m mainly going to be implementing a lot of these things solo. These are some of the possible projects I would work on: # Chatbot Knowledge Base Enhancement **Background**: The Company is deploying AI-powered chatbots (HubSpot/CoPilot) for customer engagement and internal knowledge access. Current limitations include incomplete coverage of FAQs and inconsistent performance tracking. **Objective**: Enhance chatbot functionality through improved training, monitoring, and analytics. **Scope**: * Automate FAQ training using internal documentation. * Log and classify failed responses for continuous improvement. * Develop a performance dashboard. **Deliverables**: * Enhanced training process. * Error classification system. * Prototype dashboard. **Value**: Improves customer engagement, reduces staff workload, and provides analytics on chatbot usage. # Automated Data Quality Scoring **Background**: Clients demand AI-ready datasets, and the company must ensure high data quality standards. **Objective**: Prototype an automated scoring system for dataset quality. **Scope**: * Metrics: completeness, duplicates, anomalies, missing metadata. * Script to evaluate any dataset. **Intern Fit**: Candidate has strong Python/Pandas skills and experience with data cleaning. **Deliverables**: * Reusable script for scoring. * Sample reports for selected datasets. **Value**: Positions the company as a provider of AI-ready data, improving client trust. Entity Resolution Prototype **Background**: The company datasets are siloed (deeds, foreclosures, liens, rentals) with no shared key. **Objective**: Prototype entity resolution methods for cross-dataset linking. **Scope**: * Fuzzy matching, probabilistic record linkage, ML-based classifiers. * Apply to limited dataset subset. **Intern Fit**: Candidate has ML and data cleaning experience but limited production-scale exposure. **Deliverables**: * Prototype matching algorithms. * Confidence scoring for matches. * Report on results. **Value**: Foundation for the company's long-term, unique master identifier initiative. Predictive Micro-Models **Background**: Predictive analytics represents an untapped revenue stream for the company. **Objective**: Build small predictive models to demonstrate product potential. **Scope**: * Predict foreclosure or lien filing risk. * Predict churn risk for subscriptions. **Intern Fit**: Candidate has built credit risk models using XGBoost and regression. **Deliverables**: * Trained models with evaluation metrics. * Prototype reports showcasing predictions. **Value**: Validates feasibility of predictive analytics as a company product. # Generative Summaries for Court/Legal Documents **Background**: Processing court filings is time-intensive, requiring manual metadata extraction. **Objective**: Automate structured metadata extraction and summary generation using NLP/LLM. **Scope**: * Extract entities (names, dates, amounts). * Generate human-readable summaries. **Intern Fit**: Candidate has NLP and ML experience through research work. **Deliverables**: * Prototype NLP pipeline. * Example structured outputs. * Evaluation of accuracy. **Value**: Reduces operational costs and increases throughput. Automation of Customer Revenue Analysis **Background**: The company currently runs revenue analysis scripts manually, limiting scale. **Objective**: Automate revenue forecasting and anomaly detection. **Scope**: * Extend existing forecasting models. * Build anomaly detection. * Dashboard for finance/sales. **Intern Fit**: Candidate’s statistical background aligns with forecasting work. **Deliverables**: * Automated pipeline. * Interactive dashboard. **Value**: Improves financial planning and forecasting accuracy. Data Product Usage Tracking **Background**: Customer usage patterns are not fully tracked, limiting upsell opportunities. **Objective**: Prototype a product usage analytics system. **Scope**: * Track downloads, API calls, subscriptions. * Apply clustering/churn prediction models. **Intern Fit**: Candidate’s experience in clustering and predictive modeling fits well. **Deliverables**: * Usage tracking prototype. * Predictive churn model. **Value**: Informs sales strategies and identifies upsell/cross-sell opportunities. AI Policy Monitoring Tool **Background**: The company has implemented an AI Use Policy, requiring compliance monitoring. **Objective**: Build a prototype tool that flags non-compliant AI usage. **Scope**: * Detect unapproved file types or sensitive data. * Produce compliance dashboards. **Intern Fit**: Candidate has built automation pipelines before, relevant experience. **Deliverables**: * Monitoring scripts. * Dashboard with flagged activity. **Value**: Protects the company against compliance and cybersecurity risks.",user_3573c73f,6,0.63,17,2025-08-25 23:44:33,https://www.reddit.com/r/datascience/comments/1n0ep0g/how_do_i_make_the_most_of_this_opportunity/,https://www.reddit.com/r/datascience/comments/1n0ep0g/how_do_i_make_the_most_of_this_opportunity/,True,Career | US,self.datascience,datascience,False,False
1mzwdws,"""The Vibes are Off..."" *server logs filling with errors*",,user_662c7639,61,0.82,15,2025-08-25 10:09:56,https://i.redd.it/dcz0qwbk67lf1.png,https://www.reddit.com/r/datascience/comments/1mzwdws/the_vibes_are_off_server_logs_filling_with_errors/,False,Monday Meme,i.redd.it,datascience,False,False
1mzxmx3,Looking to transition to experimentation,"Hi all, I am looking to transition from ml analytics generalized roles to more experimentation focused roles. Where to start looking for experimentation heavy roles. I know the market is trash right now, but are there any specific portals that can help find such roles. Also usually faang is very popular for such roles, but are there any other companies which would be a good step to make a transition to.",user_aafe7447,14,0.89,10,2025-08-25 10:55:36,https://www.reddit.com/r/datascience/comments/1mzxmx3/looking_to_transition_to_experimentation/,https://www.reddit.com/r/datascience/comments/1mzxmx3/looking_to_transition_to_experimentation/,True,Analysis,self.datascience,datascience,False,False
1mzlzsp,"First time writing a technical article, would love constructive feedback","Hi everyone, I recently wrote my first blog post where I share a method I’ve been using to get good results on a fine-grained classification benchmark. This is something I’ve worked on for a while and wanted to put my thoughts together in an article. I’m sharing it here **not as a promo** but because I’m genuinely looking to improve my writing and make sure my explanations are clear and useful. If you have a few minutes to read and share your thoughts (on structure, clarity, tone, level of detail, or anything else), I’d really appreciate it. Here’s the link: [https://towardsdatascience.com/a-refined-training-recipe-for-fine-grained-visual-classification/](https://towardsdatascience.com/a-refined-training-recipe-for-fine-grained-visual-classification/) Thanks a lot for your time and feedback!",user_a1f9433f,11,0.71,10,2025-08-25 02:39:51,https://www.reddit.com/r/datascience/comments/1mzlzsp/first_time_writing_a_technical_article_would_love/,https://www.reddit.com/r/datascience/comments/1mzlzsp/first_time_writing_a_technical_article_would_love/,True,ML,self.datascience,datascience,False,False
1mz2jgn,Day to day work at lead/principal data scientist,"Hi, I have 9 years of experience in ml/dl. I have been looking for a role in lead/principal ds. Can you tell me what expectations do you guys face at the role. Data science knowledge? Ml ops knowledge? Team management?",user_cf982dea,66,0.9,22,2025-08-24 10:56:46,https://www.reddit.com/r/datascience/comments/1mz2jgn/day_to_day_work_at_leadprincipal_data_scientist/,https://www.reddit.com/r/datascience/comments/1mz2jgn/day_to_day_work_at_leadprincipal_data_scientist/,True,Discussion,self.datascience,datascience,False,False
1mzgkc7,"Weekly Entering & Transitioning - Thread 25 Aug, 2025 - 01 Sep, 2025","Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include: * Learning resources (e.g. books, tutorials, videos) * Traditional education (e.g. schools, degrees, electives) * Alternative education (e.g. online courses, bootcamps) * Job search questions (e.g. resumes, applying, career prospects) * Elementary questions (e.g. where to start, what next) While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",user_ac31a110,7,0.82,25,2025-08-24 21:01:38,https://www.reddit.com/r/datascience/comments/1mzgkc7/weekly_entering_transitioning_thread_25_aug_2025/,https://www.reddit.com/r/datascience/comments/1mzgkc7/weekly_entering_transitioning_thread_25_aug_2025/,True,,self.datascience,datascience,False,False
1mxyprj,Anyone Using Search APIs as a Data Source?,"I've been working on a research project recently and have encountered a frustrating issue: the amount of time spent cleaning scraped web results is insane. Half of the pages I collect are: * Ads disguised as content * Keyword-stuffed SEO blogs * Dead or outdated links While it's possible to write filters and regex pipelines, it often feels like I spend more time cleaning the data than actually analyzing it. This got me thinking: instead of scraping, has anyone here tried using structured search APIs as a data acquisition step? In theory, the benefits could be significant: * Fewer junk pages since the API does some filtering already * Results delivered in structured JSON format instead of raw HTML * Built-in citations and metadata, which could save hours of wrangling However, I haven't seen many researchers discuss this yet. I'm curious if APIs like these are actually good enough to replace scraping or if they come with their own issues (such as coverage, rate limits, cost, etc.). If you've used a search API in your pipeline, how did it compare to scraping in terms of: * Data quality * Preprocessing time * Flexibility for different research domains I would love to hear if this is a viable shortcut or just wishful thinking on my part.",user_202a8b21,48,0.95,15,2025-08-23 04:14:25,https://www.reddit.com/r/datascience/comments/1mxyprj/anyone_using_search_apis_as_a_data_source/,https://www.reddit.com/r/datascience/comments/1mxyprj/anyone_using_search_apis_as_a_data_source/,True,Projects,self.datascience,datascience,False,False
1mxpyef,When do we really need an Agent instead of just ChatGPT?,"I’ve been diving into the whole “Agent” space lately, and I keep asking myself a simple question: *when does it actually make sense to use an Agent, rather than just a ChatGPT-like interface?* Here’s my current thinking: * Many user needs are **low-frequency, one-off, low-risk**. For those, opening a ChatGPT window is usually enough. You ask a question, get an answer, maybe copy a piece of code or text, and you’re done. No Agent required. * Agents start to make sense only when certain conditions are met: 1. **High-frequency or high-value tasks** → worth automating. 2. **Horizontal complexity** → need to pull in information from multiple external sources/tools. 3. **Vertical complexity** → decisions/actions today depend on context or state from previous interactions. 4. **Feedback loops** → the system needs to check results and retry/adjust automatically. In other words, if you don’t have multi-step reasoning + tool orchestration + memory + feedback, an “Agent” is often just a chatbot with extra overhead. I feel like a lot of “Agent products” right now haven’t really thought through what incremental value they add compared to a plain ChatGPT dialog. Curious what others think: * Do you agree that most low-frequency needs are fine with just ChatGPT? * What’s your personal checklist for deciding when an Agent is *actually* worth building? * Any concrete examples from your work where Agents clearly beat a plain chatbot? Would love to hear how this community thinks about it.",user_476dbb1a,54,0.76,16,2025-08-22 19:41:33,https://www.reddit.com/r/datascience/comments/1mxpyef/when_do_we_really_need_an_agent_instead_of_just/,https://www.reddit.com/r/datascience/comments/1mxpyef/when_do_we_really_need_an_agent_instead_of_just/,True,Discussion,self.datascience,datascience,False,False
1mxhji7,"DS/DA Recruiters, do you approve of my plan","Pivoting away from lab research after I finish my PhD, I'm thinking of taking this approach to landing a DS/DA job: - Spot an ideal job and study it's requirements. - Develop all (or most of) the skills associated with that job. - Compensate for wet-lab-heavy experiences by undertaking projects (even if hypothetical) in said job domain and learn to think like an analyst. I want to read from recruiters to know what they look for so I can.... Be that 😅",user_56d750c9,4,0.54,25,2025-08-22 13:30:03,https://www.reddit.com/r/datascience/comments/1mxhji7/dsda_recruiters_do_you_approve_of_my_plan/,https://www.reddit.com/r/datascience/comments/1mxhji7/dsda_recruiters_do_you_approve_of_my_plan/,True,Discussion,self.datascience,datascience,False,False
1mwchp8,[Hiring] MLE Position - Enterprise-Grade LLM Solutions,"Hey all, I'm the founder of Analytics Depot, and we're looking for a talented Machine Learning Engineer to join our team. We have a premium brand name and are positioned to deliver a product to match. The Home depot of Analytics if you will. We've built a solid platform that combines LLMs, LangChain, and custom ML pipelines to help enterprises actually understand their data. Our stack is modern (FastAPI, Next.js), our approach is practical, and we're focused on delivering real value, not chasing buzzwords. We need someone who knows their way around production ML systems and can help us push our current LLM capabilities further. You'll be working directly with me and our core team on everything from prompt engineering to scaling our document processing pipeline. If you have experience with Python, LangChain, and NLP, and want to build something that actually matters in the enterprise space, let's talk. We offer competitive compensation, equity, and a remote-first environment. DM me if you're interested in learning more about what we're building.",user_ca1962de,27,0.71,11,2025-08-21 07:28:35,https://www.reddit.com/r/datascience/comments/1mwchp8/hiring_mle_position_enterprisegrade_llm_solutions/,https://www.reddit.com/r/datascience/comments/1mwchp8/hiring_mle_position_enterprisegrade_llm_solutions/,True,Career | US,self.datascience,datascience,False,False
1mu3c6j,MIT report: 95% of generative AI pilots at companies are failing,,user_7c5e47a0,2302,0.99,153,2025-08-18 17:19:28,https://fortune.com/2025/08/18/mit-report-95-percent-generative-ai-pilots-at-companies-failing-cfo/,https://www.reddit.com/r/datascience/comments/1mu3c6j/mit_report_95_of_generative_ai_pilots_at/,False,Discussion,fortune.com,datascience,False,False
1mumd4y,Causal Inference Tech Screen Structure,"This will be my first time administering a tech screen for this type of role. The HM and I are thinking about formatting this round as more of a verbal case study on DoE within our domain since LC questions and take homes are stupid. The overarching prompt would be something along the lines of ""marketing thinks they need to spend more in XYZ channel, how would we go about determining whether they're right or not?"", with a series of broad, guided questions diving into DoE specifics, pitfalls, assumptions, and touching on high level domain knowledge. I'm sure a few of you out there have either conducted or gone through these sort of interviews, are there any specific things we should watch out for when structuring a round this way? If this approach is wrong, do you have any suggestions for better ways to format the tech screen for this sort of role? My biggest concern is having an objective grading scale since there are so many different ways this sort of interview can unfold.",user_d41f2750,35,0.93,20,2025-08-19 08:52:55,https://www.reddit.com/r/datascience/comments/1mumd4y/causal_inference_tech_screen_structure/,https://www.reddit.com/r/datascience/comments/1mumd4y/causal_inference_tech_screen_structure/,True,Discussion,self.datascience,datascience,False,False
1mv5ojf,Asking for feedback on databases course content,,user_b65b9798,1,0.57,10,2025-08-19 22:01:35,/r/Database/comments/1mth4ru/asking_for_feedback_on_databases_course_content/,https://www.reddit.com/r/datascience/comments/1mv5ojf/asking_for_feedback_on_databases_course_content/,False,Discussion,,datascience,False,False
1mtehzk,Curious to know about people who switched from DS to DE or SWE or Solutions Architect,"Hello, I was just curious to know about people who have switched from DS to DE or SWE or Solutions Architect. If you have done it, what was your rationale behind doing it, what pushed or motivated you for it and how has been your experience after you did it?",user_efe3dd18,44,0.86,36,2025-08-17 23:37:55,https://www.reddit.com/r/datascience/comments/1mtehzk/curious_to_know_about_people_who_switched_from_ds/,https://www.reddit.com/r/datascience/comments/1mtehzk/curious_to_know_about_people_who_switched_from_ds/,True,Discussion,self.datascience,datascience,False,False
1mtbra1,"Weekly Entering & Transitioning - Thread 18 Aug, 2025 - 25 Aug, 2025","Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include: * Learning resources (e.g. books, tutorials, videos) * Traditional education (e.g. schools, degrees, electives) * Alternative education (e.g. online courses, bootcamps) * Job search questions (e.g. resumes, applying, career prospects) * Elementary questions (e.g. where to start, what next) While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",user_ac31a110,4,0.75,27,2025-08-17 21:01:38,https://www.reddit.com/r/datascience/comments/1mtbra1/weekly_entering_transitioning_thread_18_aug_2025/,https://www.reddit.com/r/datascience/comments/1mtbra1/weekly_entering_transitioning_thread_18_aug_2025/,True,,self.datascience,datascience,False,False
1mtmvuc,Scared of AI,I have been working with a principal data scientist on a project. Although I am the sole data scientist working on this project and discussing stuff with him but I am so impressed at his articulate way of thinking. Literally putting his suggestions in chatgpt gives me the code I need. Honestly I am a little scare about AI now. Am I falling behind ?? Just to beat my own drum. I am probably asking the right questions.,user_7fefbbd8,0,0.44,32,2025-08-18 07:00:53,https://www.reddit.com/r/datascience/comments/1mtmvuc/scared_of_ai/,https://www.reddit.com/r/datascience/comments/1mtmvuc/scared_of_ai/,True,Discussion,self.datascience,datascience,False,False
1mqlp7d,Suspicious ad,"Describe the results you want and then have ai manufacture those results for you... who's going to tell them that's not how science works 🤣 Disclosure: I did not read about their tool at all,I just that the advert sounded terribly bad.",user_3ec6dd25,76,0.9,9,2025-08-14 20:01:59,https://i.redd.it/7xhknwjsm3jf1.jpeg,https://www.reddit.com/r/datascience/comments/1mqlp7d/suspicious_ad/,False,Monday Meme,i.redd.it,datascience,False,False
1mq737g,"Overfitting on training data time series forecasting on commodity price, test set fine. XGBclassifier. Looking for feedback","Good morning nerds, I’m looking for some feedback I’m sure is rather obvious but I seem to be missing. I’m using XGBclassifier to predict the direction of commodity x price movement one month the the future. ~60 engineered features and 3500 rows. Target = one month return > 0.001 Class balance is 0.52/0.48. Backtesting shows an average accuracy of 60% on the test with a lot of variance through testing periods which I’m going to accept given the stochastic nature of financial markets. I know my back test isn’t leaking, but my training performance is too high, sitting at >90% accuracy. Not particularly relevant, but hyperparameters were selected with Optuna. Does anything jump out as the obvious cause for the training over performance?",user_c99168fb,101,0.94,40,2025-08-14 10:25:09,https://www.reddit.com/r/datascience/comments/1mq737g/overfitting_on_training_data_time_series/,https://www.reddit.com/r/datascience/comments/1mq737g/overfitting_on_training_data_time_series/,True,ML,self.datascience,datascience,False,False
1mq4ai4,Would you jump jobs if you're in fear of a layoff?,"EDIT: Just looked and this new company has 2.5 stars out of 600 reviews on Glassdoor. Oof. Currently based in the U.S., working remote, medium cost of living area. I make 90k a year and I'm the lead (and only) data scientist / frontend software dev for our area in the company. On top of data science/analyst stuff, I maintain/build our training website for around 500 employees (solo dev as well using React). The down side? I work for Medicaid, and if you know what's going on in the United States you know Medicaid is having major cuts, and especially for 2026. We have laid off 300 people this year (so far). I was told ""You have nothing to worry about because your role is so niche"" but I still feel worried. New job: - Pay raise to 115k a year - Still remote - I would be working under my current boss who is transitioning to this new company (I have worked with him for 8 years, and the fact that my boss left this current job says something). - 401k is comparable (3% match), health insurance is better and less cost, PTO is comparable. - What I'm worried about: He is starting this new department from the ground up. I would be the only data/front-end website guy basically doing what I do in my current role. I'm worried the workload will be too much, or I'm not good enough to start from scratch. Feeling some imposter syndrome here. Thanks for any insight here! This job I am currently at is fun, productive, and I love my team. But I am scared to death of layoffs. The company I am going to now has been around for 25 years, is growing a lot, and has much more ""lasting power"" in my opinion.",user_2dfeaefc,98,0.95,43,2025-08-14 08:44:35,https://www.reddit.com/r/datascience/comments/1mq4ai4/would_you_jump_jobs_if_youre_in_fear_of_a_layoff/,https://www.reddit.com/r/datascience/comments/1mq4ai4/would_you_jump_jobs_if_youre_in_fear_of_a_layoff/,True,Discussion,self.datascience,datascience,False,False
1mqfubv,Time series with value dependent lag,"I build models of factories that process liquids. Liquid flows through the factory in various steps and sits in tanks. A tank will have a flow rate in and a flow rate out, a level, and a volume so I can calculate the residence time. It takes ~3 days for liquid to get from the start of the process to the end and it goes through various temperatures, separations, and various other things get added to it along the way. If the factory is in a steady state the residence times and lags are relatively easy to calculate. The problem is I am looking at 6 months worth of data and during that time the rate of the whole facility varies and therefore the residence times vary. If the flow rate goes up residence time goes down. How would you adjust the lags based on the flow rates? Chunk the data into months and calculate the lags for each month then concaténate everything? Vary the lags and just drop the overlaps and gaps?",user_67e7d08b,16,1.0,19,2025-08-14 15:44:42,https://www.reddit.com/r/datascience/comments/1mqfubv/time_series_with_value_dependent_lag/,https://www.reddit.com/r/datascience/comments/1mqfubv/time_series_with_value_dependent_lag/,True,ML,self.datascience,datascience,False,False
1mq4sfp,Copy-pasting jupyter notebooks is memory heavy on VSCode,"Currently for most of my work, I found out that copy-pasting jupyter notebooks and slightly modifying them is the most effective way to do my work. So basically I have a ipynb for every project I do every day. However, some issues is that they can sometimes get a pretty big memory footprint especially when I have a lot of plots. Like around 1GB per notebook. So sometimes it takes several seconds to a minute to open some files on vscode. I was wondering if there's a way to optimize this? I saw there's marimo and stuff. Wondering what you guys do.",user_8281e5b7,43,0.98,20,2025-08-14 09:02:41,https://www.reddit.com/r/datascience/comments/1mq4sfp/copypasting_jupyter_notebooks_is_memory_heavy_on/,https://www.reddit.com/r/datascience/comments/1mq4sfp/copypasting_jupyter_notebooks_is_memory_heavy_on/,True,Tools,self.datascience,datascience,False,False
1mpkk2n,Job market getting any better or nah?,I’ve been staying in my role and refusing to leave for the last several years. I’m wondering if there’s any signs yet the job market is coming back yet or if we’re still stuck in the slog,user_38b2c359,89,0.89,81,2025-08-13 16:41:45,https://www.reddit.com/r/datascience/comments/1mpkk2n/job_market_getting_any_better_or_nah/,https://www.reddit.com/r/datascience/comments/1mpkk2n/job_market_getting_any_better_or_nah/,True,Discussion,self.datascience,datascience,False,False
1mpei2b,How can I gain business acumen as a data scientist?,"I can build models, but can I build profits? That’s the gap I’m trying to close. I’m doing my Master’s in Data Science with a BSc in Computer Science. My technical skills are strong, but I lack business acumen. In interviews, I’ve noticed many questions aren’t just about models or algorithms, but about how those translate into profits or measurable business value. Senior data scientists seem to connect their work to revenue, retention, or strategy with ease, while I still default to thinking in terms of accuracy and technical metrics. How did you learn to bridge that gap? Did you focus on general business knowledge, industry-specific skills, or hands-on projects? I want to speak the “language of the business” so my work is not just technically solid but strategically impactful.",user_536779a0,106,0.93,53,2025-08-13 12:44:58,https://www.reddit.com/r/datascience/comments/1mpei2b/how_can_i_gain_business_acumen_as_a_data_scientist/,https://www.reddit.com/r/datascience/comments/1mpei2b/how_can_i_gain_business_acumen_as_a_data_scientist/,True,Discussion,self.datascience,datascience,False,False
1mpa610,"Research Data Scientists without heavy coding backgrounds (stats, econ, etc), has LLM's improved your workflow?","I remember for a while there were many CS folks saying that Data Science has become software engineering, and that if you aren't fluent in software engineering fundamentals then you're going to fall behind. It became enough of a popular rhetoric that people said they preferred to hire a coder with some math knowledge than a math person with some coding knowledge. As a Statistician that works in Research Data Science with an average level of coding experience, enough to write my own code in notebooks, but translating it into a fully fleshed Python module with classes and functions was much more difficult for me. For a while I thought my lack of advanced software engineering knowledge would become a crutch in my career and as someone with a busy personal life I didn't want to spend that much time learning these fundamentals. Then, my company rolled out LLM's integrated into the software we use, like Visual Studio. Suddenly I'm able to create fully fleshed out modules from my notebooks in a flash. I can ask the LLM to write unit tests to test out how my code processes data or test its various subfunctions. I can use it to code up various types of models quickly to compare results. Handing off my code to engineering in the form of a Python package wasn't such a pain anymore. Sure the LLM produces some weird results sometimes, and I do have to spend time making sure I ask it the correct things and/or cleaning up the code so that it works properly. But now I feel like that crutch I had is no longer present.",user_8a872e88,148,0.93,33,2025-08-13 10:05:02,https://www.reddit.com/r/datascience/comments/1mpa610/research_data_scientists_without_heavy_coding/,https://www.reddit.com/r/datascience/comments/1mpa610/research_data_scientists_without_heavy_coding/,True,Tools,self.datascience,datascience,False,False
1mpp8sv,What should my job title be,"I’ve been in my current role for ~5 months after finishing up my masters in geospatial data science. My official title is Energy Analyst, so essentially a data analyst role in the energy industry. I feel like the work I do is potentially beyond what is meant for the position (though I’m happy to be told otherwise if that’s not true) and am planning on asking for a title change and raise in the next few months. We have a weird set-up where we have a central IT team that supports ~12 implementation contractor teams that work with various utilities. The central IT team owns all of our data and does not allow any sort of read access or api to access data, and only exposes anything through SSRS reports. In theory, the IT team is meant to support a lot of our analytics, but historically they’ve done a pretty bad job at that so I was hired into one of the distributed teams to run their analytics and build out an internal IT capacity. So far that has included the following: - Recreating a database from the SSRS extracts. So far this is only a few tables in a sqlite3 db so nothing crazy. - Developing optimization models in pyomo to inform program design. - Lots of ad hoc analysis and reporting. Most of this can be done with some filtering and group-bys but has also included some iterative proportional fitting and other kind of ‘medium difficulty’ methods. - creating power bi dashboards as well as a couple java script maplibre-gl-js maps with complex symbology. - we accept applications to our program via an online intake, where applicants fill out forms one by one. Most of these applicants submit tens to hundreds of these applications at once. I am working in parallel on a few different potential solutions to this: templates for batch uploading is the easy one, and a potential api integration to pull applications directly from applicant systems is another. - looking into creating some llm-agents to automate very simply data extraction. I have already tried automating these processes via dom ids and such but haven’t gotten it to work reliably enough yet. My manager specifically asked for me to try agentic approaches to appease higher ups that we are implementing AI. I’m not entirely sure where I fall in the landscape of data titles and would appreciate input. I mostly use python with a bit of power query and vanilla excel as well. Very little Java script (just for certain visualizations). Power bi. Edit to add- I also manage an intern-turned-part-time-employee that supports me in the above tasks basically at my own discretion",user_99f9a6bd,12,0.8,10,2025-08-13 20:16:29,https://www.reddit.com/r/datascience/comments/1mpp8sv/what_should_my_job_title_be/,https://www.reddit.com/r/datascience/comments/1mpp8sv/what_should_my_job_title_be/,True,Career | US,self.datascience,datascience,False,False
1mq78jd,Getting Master's worth it with T5 Bachelor's?,"As a bit of background, I have 2 years of work experience as a Data Scientist, and I have a Bachelor's Degree in Mathematics from a 'top' University: think MIT/Harvard/Princeton. I'm currently employed. Making about $105k in total comp. I have a feeling I could be doing better compensation wise and even task wise so I've been considering applying to more jobs. I've noticed a lot of job postings seem to have a minimum requirement of at least a Master's degree, but I'm sort of hesitant to pursue this route right now for a few reasons. For one, master's are expensive, and I don't want to quit my job and go into debt. Secondly, if I were to pursue an online Master's degree, I'm not sure the available options would increase my signal. For example, does a MIT Math Bachelor's -> Texas AM Master's Data Science really boost the resume? The only reason I'd get a Master's is for my love of learning, and I'd pursue something theoretical ML oriented and maybe transition into a more research-heavy or even quant role. But I'm not feeling this is an imminent or necessary next step for me. I'm not trying to be cocky; I'm just trying to get insight from more seasoned people in the field who might be closer to hiring expectations.",user_89205f43,0,0.4,17,2025-08-14 10:30:25,https://www.reddit.com/r/datascience/comments/1mq78jd/getting_masters_worth_it_with_t5_bachelors/,https://www.reddit.com/r/datascience/comments/1mq78jd/getting_masters_worth_it_with_t5_bachelors/,True,Career | US,self.datascience,datascience,False,False
1mo6ofm,Using Experiment Tracking For Backtests,"I’ve used MLFlow as a data scientist, but here it’s being used for managing algo trading backtests and I thought this was an awesome use case. (And these aren’t ML runs, this is testing a momentum strategy).",user_dbcdec76,3,0.62,6,2025-08-12 04:56:42,https://www.reddit.com/r/datascience/comments/1mo6ofm/using_experiment_tracking_for_backtests/,https://www.reddit.com/r/datascience/comments/1mo6ofm/using_experiment_tracking_for_backtests/,True,Tools,self.datascience,datascience,False,False
1mnhsx7,"When you edit the massive query someone sent you, forgot where you deleted something, and left a comma behind...",,user_662c7639,141,0.9,9,2025-08-11 09:32:12,https://i.redd.it/9sri1xwz2fif1.png,https://www.reddit.com/r/datascience/comments/1mnhsx7/when_you_edit_the_massive_query_someone_sent_you/,False,Monday Meme,i.redd.it,datascience,False,False
1mniapg,Databricks Freea course Recs,Can anyone recommend a great free databricks catalog or otherwise course to level up as a DS using databricks itself?,user_cbc73794,6,1.0,3,2025-08-11 09:50:18,https://www.reddit.com/r/datascience/comments/1mniapg/databricks_freea_course_recs/,https://www.reddit.com/r/datascience/comments/1mniapg/databricks_freea_course_recs/,True,Discussion,self.datascience,datascience,False,False
1mmzk4s,"Catch-22: Learning R through ""hands on"" Projects","I often get told ""learn data science by doing hands-on projects"" and then I get all fired up and motivated to learn, and then I open up R.... And then I stare at a blank screen because I don't know the syntax from memory. And then I tell myself I'm going to learn the syntax so that I can do projects, but then I get caught up creating folders for each function of dplyr and the subfunctions of that and cheat sheets for this. And then I come across the advice that I shouldn't learn syntax for the sake of learning syntax - I should do hands on projects. I need projects to learn syntax and I need syntax to start doing projects. ________ Edit - Thank you so much to all of you who have replied and I would respond to each one of you but I don't want to sound like a parrot. The reassurance that you don't have to have absorbed every R cheat sheet before being a professional Data Scientist/Analyst is very much appreciated. My assumption was these data analyst/scientist roles had coding-exams as part of the interview process, which is what stressed me out. Seeing some of you here as experienced analysts who still Google code is very relieving. I am very grateful for each response, and I read each one carefully.",user_56d750c9,48,0.76,33,2025-08-10 18:06:42,https://www.reddit.com/r/datascience/comments/1mmzk4s/catch22_learning_r_through_hands_on_projects/,https://www.reddit.com/r/datascience/comments/1mmzk4s/catch22_learning_r_through_hands_on_projects/,True,Discussion,self.datascience,datascience,False,False
1mn3338,"Weekly Entering & Transitioning - Thread 11 Aug, 2025 - 18 Aug, 2025","Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include: * Learning resources (e.g. books, tutorials, videos) * Traditional education (e.g. schools, degrees, electives) * Alternative education (e.g. online courses, bootcamps) * Job search questions (e.g. resumes, applying, career prospects) * Elementary questions (e.g. where to start, what next) While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",user_ac31a110,6,0.81,37,2025-08-10 21:01:33,https://www.reddit.com/r/datascience/comments/1mn3338/weekly_entering_transitioning_thread_11_aug_2025/,https://www.reddit.com/r/datascience/comments/1mn3338/weekly_entering_transitioning_thread_11_aug_2025/,True,,self.datascience,datascience,False,False
1mlmwk0,AI isn't taking your job. Executives are.,"If AI is ready to replace developers, why aren't developers replacing themselves with AI and just taking it easy at work? I'm a Director at my company. I'm in the meetings and helping set up the tools that cost people their jobs. Here's how they work: 1. Claude AI writes some code 2. The code gets passed to a developer for validation 3. Since the developer's ""just validating"", he can be replaced with an overseas contractor that'll work for a fraction of the pay We've tracked the tools, and we haven't seen any evidence that having Claude take a crack at the code saves anybody any time - but it does let us justify replacing expensive employees with cheap overseas contractors. You're not getting replaced by AI. Your job's being outsourced overseas.",user_67d6549f,1828,0.95,183,2025-08-09 04:13:29,https://www.reddit.com/r/datascience/comments/1mlmwk0/ai_isnt_taking_your_job_executives_are/,https://www.reddit.com/r/datascience/comments/1mlmwk0/ai_isnt_taking_your_job_executives_are/,True,Discussion,self.datascience,datascience,False,False
1mluc12,"Burnout, disillusionment, and imposter syndrome after 1 year in DS. Am I just an API monkey? Reality check needed.","Hey folks, I am about a year into my first data science job. It took roughly a year and more than 400 applications to land it, so the idea of another long search is scary. Early on I worked with an internally built causal AI model that captures relationships for further analysis. I did not build the model. I ran experiments to make it more explainable and easier for others to use. I also built data orchestration pipelines using third party tools that are common in industry and cloud providers like AWS and GCP. The last six months have shifted to LLM and NLP work. A lot of API calls, large text analysis. The next six months look even more LLM heavy since I am leading an internal tool build. On paper there are wins: - I have led projects and designed tools from scratch. - My communication and client skills have improved. My concerns: - I am not doing much classical DS or rigorous modeling. - LLM work often feels like API wrangling rather than technical depth. - Work life balance is rough with frequent weekends. - Even with a possible 5 to 10 percent raise (possibly within the next 6 months), the work likely stays the same. I feel imposter syndrome and worry I am behind my peers on fundamentals and interview depth. I’m so burned out and honestly can’t tell if I’m just being a negative Nancy or if my concerns are legit. Am I shortchanging myself by thinking that I'm just not skilled enough? Idk What I would love input on: Am I building valuable skills for the DS market, or am I narrowing myself too much? What types of companies or industries might value this mix of causal modeling, LLM work, and consulting style analysis? If I want to keep doors open for more traditional DS or ML roles, what should I focus on learning now? Portfolio ideas I can ship from my current work that would impress a hiring manager? Would you ride out six months to finish the tool and try for a promotion, or start looking sooner? Honest takes are very welcome.",user_68b3d20c,116,0.9,45,2025-08-09 09:56:51,https://www.reddit.com/r/datascience/comments/1mluc12/burnout_disillusionment_and_imposter_syndrome/,https://www.reddit.com/r/datascience/comments/1mluc12/burnout_disillusionment_and_imposter_syndrome/,True,Career | US,self.datascience,datascience,False,False
1mly9hm,Business focused data science,"As a microbiology researcher, I'm far away from the business world. I do more -omics and growth curves and molecular techniques, but I want to move away from biology. I believe the bridge that can help me do that is data. I have got experience with R and excel. I'm looking at learning SQL and PowerBI. But I want to do it away from biology. The problem is, if I was to go from the UK, as a PhD microbiologist, and approach GCC consulting/business analyst recruiters, I get the sense that they'd scoff at me for thinking too highly of my ""transferrable skills"" and tell me that I don't have experience in the world of business. How would I get myself job-ready for GCC business-focused data science roles. Is there anyone out there that has made the switch that can share some advice? Thanks in advance",user_56d750c9,40,0.93,31,2025-08-09 12:40:16,https://www.reddit.com/r/datascience/comments/1mly9hm/business_focused_data_science/,https://www.reddit.com/r/datascience/comments/1mly9hm/business_focused_data_science/,True,Discussion,self.datascience,datascience,False,False
1ml6fxs,Just bombed a technical interview. Any advice?,"I've been looking for a new job because my current employer is re-structuring and I'm just not a big fan of the new org chart or my reporting line. It's not the best market, so I've been struggling to get interviews. But I finally got an interview recently. The first round interview was a chat with the hiring manager that went well. Today, I had a technical interview (concept based, not coding) and I really flubbed it. I think I generally/eventually got to what they were asking, but my responses weren't sharp.* It just sort of felt like I studied for the wrong test. How do you guys rebound in situations like this? How do you go about practicing/preparing for interviews? And do I acknowledge my poor performance in a thank you follow up email? *Example (paraphrasing): They built a model that indicated that logging into a system was predictive of some outcome and management wanted to know how they might incorporate that result into their business processes to drive the outcome. I initially thought they were asking about the effect of requiring/encouraging engagement with this system, so I talked about the effect of drift and self selection on would have on model performance. Then they rephrased the question and it became clear they were talking about causation/correlation, so I talked about controlling for confounding variables and natural experiments.",user_ecec73a7,80,0.9,59,2025-08-08 13:40:52,https://www.reddit.com/r/datascience/comments/1ml6fxs/just_bombed_a_technical_interview_any_advice/,https://www.reddit.com/r/datascience/comments/1ml6fxs/just_bombed_a_technical_interview_any_advice/,True,Discussion,self.datascience,datascience,False,False
1mkzhvp,Resources/tips for someone brand new to model building and deployment in Azure?,"Context: my current company is VERY (VERY) far behind, technologically. Our data isn't that big and currently resides in SQL Server databases, which I query directly via SSMS. Whenever a project requires me to build models, my workflow would generally look like: 1. Query the data I need, make features, etc. from SQL Server. 2. Once I have the data, use Jupyter Notebooks to train/build models. 3. Use best model to score dataset. 4. Send dataset/results to stakeholder as a file. My company doesn't have a dedicated Dev team (on-shore, at least) nor a DE team. And this workflow works to make ends meet. Now my company has opened up Azure accounts for me and my manager, but neither one of us have developed anything in it before. Microsoft has PLENTY of documentation, but the more I read, the more questions I have, and I feel like my time will be spent reading articles rather than getting anything done. It seems like quite a shift from doing everything ""locally"" like what we have been doing to actually using cloud resources. So does anyone have any tips/guides that are beginner-friendly where I can do my entire workflow in the cloud?",user_1821ffa2,23,0.88,7,2025-08-08 09:14:20,https://www.reddit.com/r/datascience/comments/1mkzhvp/resourcestips_for_someone_brand_new_to_model/,https://www.reddit.com/r/datascience/comments/1mkzhvp/resourcestips_for_someone_brand_new_to_model/,True,Tools,self.datascience,datascience,False,False
1mkmjje,How would you visualize or analyze movements across a categorical grid over time?,"I’m working with a dataset where each entity is assigned to one of N categories that form a NxN grid. Over time, entities move between positions (e.g., from “N1” to “N2”). Has anyone tackled this kind of problem before? I’m curious how you’ve visualized or even clustered trajectory types when working with time-series data on a discrete 2D space.",user_fbe99468,15,0.94,10,2025-08-07 22:12:22,https://www.reddit.com/r/datascience/comments/1mkmjje/how_would_you_visualize_or_analyze_movements/,https://www.reddit.com/r/datascience/comments/1mkmjje/how_would_you_visualize_or_analyze_movements/,True,Discussion,self.datascience,datascience,False,False
1mkdy7a,How do you analyse unbalanced data you get in A/B testing?,"Hi I have two questions related unbalanced data in A/B testing. Would appreciate resources or thoughts. 1. Usually when we perform A/B testing, we have 5-10% in treatment, after doing power analysis we get the sample size needed, we run tge experiment, by the time we get required sample size for treatment we get way more control samples, so now when we analyse, which samples do we keep in control group? For example by the time we collect 10k samples from treatment we might get 100k samples of control. So what to do now before performing t-test or any kinds of test? (In ML we can downsample or over sample but what to do in causal side) 2. Again similar question Lets say we are performing test on 50/50 but if one variant get way more samples as more ppl come through that channel and common for users, hiw do we segment users such as way? And again which samples we keep once we get way more sample than needed? I want to know how it is tackeled in day to day, and this thing happen frequently right? Or am i wrong? Also, what if you get sample size before expected time? (Like was thinking to run them for 2 weeks but got the required size in 10 days) Do you stop the experiment and start analyzing? Sorry for this dumb question but i could not find good answers and honestly don’t trust chat gpt much as many time it hallucinates in this topic. Thanks!",user_d2481f01,30,0.89,27,2025-08-07 15:21:21,https://www.reddit.com/r/datascience/comments/1mkdy7a/how_do_you_analyse_unbalanced_data_you_get_in_ab/,https://www.reddit.com/r/datascience/comments/1mkdy7a/how_do_you_analyse_unbalanced_data_you_get_in_ab/,True,Discussion,self.datascience,datascience,False,False
1mk7lpa,What elective course should I take,"Hey all, About to start my last semester for my masters in computer science, with a concentration in AI. I’m a veteran data scientist, this is more of a vanity degree and an ability to say “yes I do have a masters degree” on a job application, but I have enjoyed the studying overall. I have room for one elective class, and I’m trying to decide what I should take. None of them that fit my schedule seem particularly appealing: - data analysis: hyper redundant given my background - computer networks: possibly useful, but I’d much rather learn something like distributed systems - intro to cybersecurity: maybe good, but seems like it would be mostly terminology and not so much a deep dive on anything - object oriented design: could be nice for refining my actual design choices, but programming seems like the least valuable skill to upskill on in computer science now (as compared to, say, cloud computing, which is and will continue to be good to know). It’s not exactly the most pressing choice, but I thought I’d throw it to Reddit, and see if anyone has a strong opinion on what’s good to learn to augment my ML/AI background Edit: okay I think you people convinced me. Object oriented design it is! Which sounds a whole lot better than computer networks, that’s for sure.",user_838ae7bb,7,0.82,19,2025-08-07 11:15:23,https://www.reddit.com/r/datascience/comments/1mk7lpa/what_elective_course_should_i_take/,https://www.reddit.com/r/datascience/comments/1mk7lpa/what_elective_course_should_i_take/,True,Discussion,self.datascience,datascience,False,False
1mkov0u,"""SemiAuto"" Fully Automated Machine Learning Lifecycle by Just API Calling","So for the last 4 months I have been working on this project which was first supposed to be a upgrade of AutoML, but I later recognised it's potential. This project could be one of the best things in ML reasearch, This project is just that good. For context, I have the knowledge around ML for about 1.5 years now and thanks to the tools available, I have been able to build a grand project like this, The Project's or you can say the Tool name is 'SemiAuto', A full fledged ML lifecycle Automation tool. It has 3 microservice, Regression, Classification, and Clustering. I have completely build the Version 1 of this project. It has 6 parts, First ingest the Data.csv file and the target column. Second choose whatever preprocessing you want to and apply them. Third use feature tools to build new features and then SHAP to select the amount of features you want. Fourth choose any algorithm you want with the hyper params and build the model. Fifth choose the optimization technique and get an optimised model. At last, get the report, model.pkl, and processor.pkl and use them wherever you want. As of why this project would be extremely good in research as researchers needs to test with different techniques and different models to get the best thing out and this tool provides that, This tool will in a semiautomatic way can fully do each and everything by itself, no coding required. The version 2 of this project is in production and I are introducing much more than the previous version, For example, Parallel model building, Simple Ensemble design and Staged Ensemble design. And also the thing that no one as of today has ever implemented in their ML automation tool, Meta-Heuristics Algorithms for feature selection. Version 2 will be one of the most mind blowingly incredible release of the SemiAuto",user_e3f622c6,0,0.31,6,2025-08-08 00:32:35,https://www.reddit.com/r/datascience/comments/1mkov0u/semiauto_fully_automated_machine_learning/,https://www.reddit.com/r/datascience/comments/1mkov0u/semiauto_fully_automated_machine_learning/,True,Tools,self.datascience,datascience,False,False
1mizivg,"Seeking Meaningful, Non-Profit Data Volunteering Projects",,user_feb663b0,30,0.92,9,2025-08-06 01:56:31,/r/dataengineering/comments/1mix8g7/seeking_meaningful_nonprofit_data_volunteering/,https://www.reddit.com/r/datascience/comments/1mizivg/seeking_meaningful_nonprofit_data_volunteering/,False,Discussion,,datascience,False,False
1mhikh4,How can I *give* a good data science/machine learning interview?,"I'm around 6 months into my first non intern job and am the only data scientist/MLE in my company. My company has decided they want to bring on some much needed help (thank god) and want me to do ""the more technical side"" of the interview (with others taking care of the behavioral etc) I do have some questions in mind specific to my job for what I want in a colleague but I still feel a bit underprepared. My plan is to ask the 'basic' questions that I got asked in every interview (classification vs clustering, what is r^2, etc) before asking them how they would solve some of the problems I'm actually working on But like that's all I have in the pipeline at the moment, and I'd really like to avoid this becoming the blind interviewing the blind moment. Does anyone have any good tips on how to do the interviews, what to look for or what to include? Thank you!!!! EDIT: In reply to the DMs, we are not accepting any new applicants at this time 😅",user_61a7af71,175,0.96,39,2025-08-04 09:42:37,https://www.reddit.com/r/datascience/comments/1mhikh4/how_can_i_give_a_good_data_sciencemachine/,https://www.reddit.com/r/datascience/comments/1mhikh4/how_can_i_give_a_good_data_sciencemachine/,True,Discussion,self.datascience,datascience,False,False
1miresg,Share your thought on open source alternative for data robot,Data robot is the market leader when it comes to enterprises data science project life cycle management. But there is no open source alternative available in the market right now. What are the chances of getting a good adoption if I can build the open source alternative of data robot?,user_62c72028,0,0.31,10,2025-08-05 18:21:40,https://www.reddit.com/r/datascience/comments/1miresg/share_your_thought_on_open_source_alternative_for/,https://www.reddit.com/r/datascience/comments/1miresg/share_your_thought_on_open_source_alternative_for/,True,Discussion,self.datascience,datascience,False,False
1miccmb,How I built and deployed a GenAI app in minutes using open‑source tools + Azure,"Hey everyone building AI apps always felt like a massive undertaking. So much code, setup, server stuff. I recently tried something different and launched a working GenAI app in just under 15 minutes. I used Dify AI (an open‑source platform) to design the app and Microsoft Azure to deploy it. What I learned: • No heavy DevOps or managing servers • Very user‑friendly interface—just plug in your AI logic • Scales automatically via Azure cloud resources Would love to hear if anyone’s tried Dify AI or other open‑source builders for AI—and what challenges you faced! Full details in this write‑up: https://medium.com/@techlatest.net/launch-genai-apps-in-minutes-with-techlatest-dify-ai-on-azure-cloud-platform-8307bccf4aed Happy to answer questions or breakdown steps if interested 😊",user_0c453588,0,0.25,4,2025-08-05 08:30:16,https://www.reddit.com/r/datascience/comments/1miccmb/how_i_built_and_deployed_a_genai_app_in_minutes/,https://www.reddit.com/r/datascience/comments/1miccmb/how_i_built_and_deployed_a_genai_app_in_minutes/,True,Discussion,self.datascience,datascience,False,False
1mh3i7n,"Weekly Entering & Transitioning - Thread 04 Aug, 2025 - 11 Aug, 2025","Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include: * Learning resources (e.g. books, tutorials, videos) * Traditional education (e.g. schools, degrees, electives) * Alternative education (e.g. online courses, bootcamps) * Job search questions (e.g. resumes, applying, career prospects) * Elementary questions (e.g. where to start, what next) While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",user_ac31a110,7,1.0,57,2025-08-03 21:01:42,https://www.reddit.com/r/datascience/comments/1mh3i7n/weekly_entering_transitioning_thread_04_aug_2025/,https://www.reddit.com/r/datascience/comments/1mh3i7n/weekly_entering_transitioning_thread_04_aug_2025/,True,,self.datascience,datascience,False,False
1mgsshu,Personal projects and skill set,"Hi everyone, I was just wondering how do you guys specify personal acquired skills from your personal projects in your CV. I’m in the midst of a pretty large project - end to end pipeline for predicting real time probabilities of winning chances in a game. This includes a lot of tools, from scraping, database management (mostly tables creations, indexing, nothing DBA-like), scheduling, training, prediction and data drift pipelines, cloud hosting, etc. and I was wondering how I can specify those skills after I finish my project, because I do learn tons from this project. To say I’m using some of those tools in my current job is not entirely right so… What would you say? Cheers.",user_064ae56a,25,0.94,11,2025-08-03 12:56:10,https://www.reddit.com/r/datascience/comments/1mgsshu/personal_projects_and_skill_set/,https://www.reddit.com/r/datascience/comments/1mgsshu/personal_projects_and_skill_set/,True,Projects,self.datascience,datascience,False,False
1mgfcke,Built this out of pure laziness for all my Feature engineering/model training jobs,"Built this out of pure laziness A lightweight Telegram bot that lets me: - Get Databricks job alerts - Check today’s status - Repair failed runs - Pause/reschedule , All from my phone. No laptop. No dashboard. Just / Commands.",user_f79deb0f,59,0.94,10,2025-08-03 02:50:17,https://i.redd.it/jh3mhg0p0sgf1.jpeg,https://www.reddit.com/r/datascience/comments/1mgfcke/built_this_out_of_pure_laziness_for_all_my/,False,Tools,i.redd.it,datascience,False,False
1mgxgpl,Is there a term for internal processing vs data that needs to be stakeholding/customer facing?,"For example I had my physical credit card stolen. I was trying to get information from the CC company about when the card was used so that the local PD could check security cameras. (We thought it was particular person so they made a little bit more effort). When I called the credit card company, the customer service person started telling me these random times that made no sense and I realized he was reading the wrong column which were basically the time the charge was converted from “?” to an actual money transfer. I assume to him it gave insight into how to refund each charge so “relvant” just not “relvant” information I would ever need to know. Two years later, I am setting up a model with my team and we batting around terms to differentiate between data like these dates & times that are relvant but are not relvant un-manipulated or laid bare for the stakeholder to see visualized or be discussed outside of our team. You can hear the inevitable pause from a team member every time the concept comes up as they attempt a new word. While it was amusing it’s starting to eat at me. Any ideas?",user_297b825d,4,0.7,3,2025-08-03 16:08:55,https://www.reddit.com/r/datascience/comments/1mgxgpl/is_there_a_term_for_internal_processing_vs_data/,https://www.reddit.com/r/datascience/comments/1mgxgpl/is_there_a_term_for_internal_processing_vs_data/,True,Challenges,self.datascience,datascience,False,False
1mh9tvo,What would be a better job Position ? Data Scientist or AI/ML Engineer.,,user_a6355e92,0,0.38,19,2025-08-04 03:31:54,/r/careerguidance/comments/1mh97i5/what_would_be_a_better_job_position_data/,https://www.reddit.com/r/datascience/comments/1mh9tvo/what_would_be_a_better_job_position_data/,False,Discussion,,datascience,False,False
1mgxbio,Algorithm Idea,This sudden project has fallen on my lap where I have a lot of survey results and I have to identify how many of those are actually done by bots. I haven’t see what kind of data the survey holds but I was wondering how can I accomplish this task. A quick search points me towards anomaly detections algorithms like isolation forest and dbscan clusters. Just wanted to know if I am headed in the right direction or can I use any LLM tools. TIA :),user_7fefbbd8,1,0.53,18,2025-08-03 16:02:26,https://www.reddit.com/r/datascience/comments/1mgxbio/algorithm_idea/,https://www.reddit.com/r/datascience/comments/1mgxbio/algorithm_idea/,True,Projects,self.datascience,datascience,False,False
1mgrvsh,Hi! i am a junior dev need advice regarding fraud/risk scoring (not credit) on my rules based fraud detection system.,so i our team has developed a rules based fraud detecton system....now we have received a new requirement that we have to score every transaction as how much risky or if flagged as fraud how much fraud it is. i did some research and i found out its easier if it is a supervisied operation but in my case i wont be able to access prod transaction data due to policy. now i have 2 problems data which i guess i have to make a fake one. 2nd how to score i was thinking of going witb regression if i keep my target value bete 0 and 1 but realised that the model can predict above that then thought of classification and use predict_proba() to get prediction probability. or isolation forest till now thats what i bave you thought what else shoudl i consider any advices or guidance to set me in the right path so i dont get any rework,deleted_user,0,0.38,5,2025-08-03 12:19:25,https://www.reddit.com/r/datascience/comments/1mgrvsh/hi_i_am_a_junior_dev_need_advice_regarding/,https://www.reddit.com/r/datascience/comments/1mgrvsh/hi_i_am_a_junior_dev_need_advice_regarding/,True,Discussion,self.datascience,datascience,False,False
1mf44ek,Using a hybrid role in job title (Data Science and Engineer),"I have an BS and MS in data science and got hired as a data analyst for a small ish scale company for about a year now as my first job. I'm the only data person in the entire company and I've been wanting to transition into a data science focused role for awhile, so I have been using DS and DE principles at every opportunity to boost my resume. This has ended up extending far beyond the typical DA responsibilities as I have been utilizing a lot of stats modeling and predictive analytics over company data/KPIs, using MLOps occasionally, as well as building ETL pipelines, managing the internal DBMS and streamlining data acquisition through RESTful APIs with contracted third parties. I still do excel monkey work/tableau dashboards along with this. Management ended up taking notice and since nobody in the building has any familiarity with data science/tech, they have asked me to rewrite my job description including my job title as a semi promotion. Since I have been working as a bit of a hybrid between DS and DE I am wondering if I should put the new contracted job title as a hybrid role (e.g. Data Science Engineer) or just pick one? My department head has suggested the title of Data Architect but I don't really think that aligns with my job responsibilities and it's also a senior sounding position which feels strange to take on considering I've only been in the industry for a year.",user_eaaad13c,54,0.91,17,2025-08-01 11:22:53,https://www.reddit.com/r/datascience/comments/1mf44ek/using_a_hybrid_role_in_job_title_data_science_and/,https://www.reddit.com/r/datascience/comments/1mf44ek/using_a_hybrid_role_in_job_title_data_science_and/,True,Discussion,self.datascience,datascience,False,False
1mets4m,How to convert data to conceptual models,"I am not sure if I am in the right subreddit, so please by patient with me. I am working on a tool to reverse-engineer conceptual models from existing data. The idea is you take a legacy system, collect sample data (for example JSON messages communicated by the system), and get a precise model from them. The conceptual model can be then used to develop new parts of the system, component replacements, build documentation, tests, etc... One of the open issues I struggle with is the fully-automated conversion from 'packaging' model to conceptual model. When some data is uploaded, it's model reflects the packaging mechanism, rather than the concepts itself. For example. if I upload JSON-formatted data, the model initially consists of objects, arrays, and values. For XML, it is elements and attributes. And so on. [JSON messages consist of objects, arrays, and values](https://preview.redd.it/rq6k13ej2egf1.png?width=737&format=png&auto=webp&s=415800ea39e0b408f91124f5d03fab02b631e75e) I can convert the keys, levels, paths to detect concepts and their relationships. It can look something like this: [Data structures converted to concepts](https://preview.redd.it/r1d2ti683egf1.png?width=695&format=png&auto=webp&s=0927e6222a90412d7dd5b722fdb43ad07b49e027) The issue I am struggling with is that this conversion is not straightforward. Sometimes, it helps to use keys, other times it is better to use paths. For some YAML files, I need to treat the keys as values (typically package.yaml samples). Did anyone tried to convert data to conceptual models before? Any real-word use cases? Is there any theory at least about the reverse direction - use conceptual model and map it into XML schema / JSON schema / YAML ... ? Thanks in advance.",user_d224d0d1,10,0.92,5,2025-08-01 04:19:20,https://www.reddit.com/r/datascience/comments/1mets4m/how_to_convert_data_to_conceptual_models/,https://www.reddit.com/r/datascience/comments/1mets4m/how_to_convert_data_to_conceptual_models/,True,Discussion,self.datascience,datascience,False,False
1mem3t5,Generative AI shell interface for browsing and processing data?,"So vibe coding is a thing, and I'm not super into it. However, I often need to write little scripts and parsers and things to collect and analyze data in a shell environment for various code that I've written. It might be for debugging, or just collecting production science data. Writing that shit is a real pain, because you need to be careful about exceptions and errors and folder names and such. Is there a way to do ""vibe data gathering"" where I can ask some LLM to write me a script that does a number of things like open up a couple thousand files that fit various properties in various folders, parse them for specific information, then draw say a graph? ChatGPT can of course do that, but it needs to know the folder structure and examine the files to see what issues there are in collecting this information. Any way I can do this without having to roll my sleeves up?",user_b7a148b1,2,0.6,9,2025-07-31 20:37:46,https://www.reddit.com/r/datascience/comments/1mem3t5/generative_ai_shell_interface_for_browsing_and/,https://www.reddit.com/r/datascience/comments/1mem3t5/generative_ai_shell_interface_for_browsing_and/,True,Discussion,self.datascience,datascience,False,False
1me934o,Why is there no Cursor/Windsurf for Notebooks or Google Collab?,"Last week, I tried Windsurf to build a web application and OMG my world was changed. I have used AI tools before but having an agent that implements the code for you is a game changer, my productivity probably went up x5 or x10 times. This made me think why is there nothing like this for a data scientist workflow? I know you can do notebook markdown but it is still not the same because Cursor cannot see outputs of your graphs. Also, this tool wouldn’t work on Google Collab where I have access to powerful GPUs. Now, imagine if you have a tool that goes from a prompt “make the predictive model to predict customer churn” and instead of something like Chatgpt giving you one slob of generic BS that will definitely give out an error, an agent goes and executes each cell one by one: making plots, studying the data, modifying the outliers etc. and adjusting the plan as it goes before finally making a few models and testing them. Basically, the standard data science workflow. I would like to build something this (I have no idea how yet lol) if there is interest in this community. What do you guys think? Those of you who are working in the field, would you actually use it? Also, if someone wants to build it with me, DM me.",user_c978c939,10,0.61,42,2025-07-31 11:16:29,https://www.reddit.com/r/datascience/comments/1me934o/why_is_there_no_cursorwindsurf_for_notebooks_or/,https://www.reddit.com/r/datascience/comments/1me934o/why_is_there_no_cursorwindsurf_for_notebooks_or/,True,Discussion,self.datascience,datascience,False,False
1mdf6fn,My take on the Microsoft paper,"I read the paper myself (albeit pretty quickly) and tried to analyze the situation for us Data Scientists. The jobs on the list, as you can intuitively see (and it is also explicitly mentioned in the paper), are mostly jobs that require writing reports and gathering information because, as the paper claims, AI is good at it. If you check the chart present in the paper (which I linked in this post), you can see that the clear winner in terms of activities done by AI is “Gathering Information”, while “Analyzing Data” instead is much less impacted and also most of it is people asking AI to help with analysis, not AI doing them as an agent (red bar represents the former, blue bar the latter). It seems that our beloved occupation is in the list mainly because it involves gathering information and writing reports. However, the data analysis part is much less affected and that’s just data analysis, let alone the more advanced tasks that separate a Data Scientist from a Data Analyst. So, from what I understand, Data Scientists are not at risk. The things that AI does do not represent the actual core of the job at all, and are possibly even activities that a Data Scientist wants to get rid of. If you’ve read the paper too, I’d appreciate your feedback. Thanks!",user_b7a887ca,170,0.94,21,2025-07-30 11:57:25,https://imgur.com/a/Ba5m1Po,https://www.reddit.com/r/datascience/comments/1mdf6fn/my_take_on_the_microsoft_paper/,False,Discussion,imgur.com,datascience,False,False
1md5gvk,Microsoft just dropped a study showing the 40 jobs most affected by Al and the 40 that Al can't touch (yet).,,user_d0222c95,428,0.87,168,2025-07-30 05:37:47,https://www.reddit.com/gallery/1mcup6s,https://www.reddit.com/r/datascience/comments/1md5gvk/microsoft_just_dropped_a_study_showing_the_40/,False,Discussion,reddit.com,datascience,False,False
1mdaa40,Working remote,"hey all i’ve been a data scientist for a while now, and i’ve noticed my social anxiety has gotten worse since going fully remote since covid. i love the work itself - building models, finding insights etc, but when it comes to presenting those insights, i get really anxious. it’s easily the part of the job i dread most. i think being remote makes it harder. less day-to-day interaction, fewer casual chats - and it just feels like the pressure is higher when you do have to speak. imposter syndrome also sneaks in at time. tech is constantly evolving, and sometimes i feel like i’m barely keeping up, even though i’m doing the work. i guess i’m wondering: • does anyone else feel this way? • have you found ways to make communications feel less overwhelming? would honestly just be nice to hear from others in the same boat. thanks for reading.",user_9b43647b,118,0.92,41,2025-07-30 08:53:52,https://www.reddit.com/r/datascience/comments/1mdaa40/working_remote/,https://www.reddit.com/r/datascience/comments/1mdaa40/working_remote/,True,Discussion,self.datascience,datascience,False,False
1me91rq,FIGMA? Is the tech industry back?,Have you guys heard of this IPO? Stock tripled on debut. What does this company do? I feel like you tech bros might have a come back soon fyi,user_ad676fd1,0,0.24,6,2025-07-31 11:15:05,https://www.reddit.com/r/datascience/comments/1me91rq/figma_is_the_tech_industry_back/,https://www.reddit.com/r/datascience/comments/1me91rq/figma_is_the_tech_industry_back/,True,Analysis,self.datascience,datascience,False,False
1mdan3p,Model Governance Requests - what is normal?,"I’m looking for some advice. I work at a company that provides inference as a service to other customers, specifically we have model outputs in an API. This is used across industries, but specifically when working with Banks, the amount of information they request through model governance is staggering. I am trying to understand if my privacy team is keeping things too close to the chest, because I find that what is in our standard governance docs, vs the details we are asked, is hugely lacking. It ends up being this ridiculous back and forth and is a huge burn on time and resources. Here are some example questions: * specific features used in the model * specific data sources we use * detailed explanations of how we arrived at our modeling methodology, what other models we considered, the results of those other models, and the rationale for our decision with a comparative analysis * a list of all metrics used to evaluate model performance, and why we chose those metrics * time frame for train/test/val sets, to the day I really want to understand if this is normal, and if my org needs to improve how we report these out to customers that are very concerned about these kinds of things (banks). Are there any resources out there showing what is industry standard? How does your org do it? Thanks",user_df888aed,6,1.0,11,2025-07-30 09:07:20,https://www.reddit.com/r/datascience/comments/1mdan3p/model_governance_requests_what_is_normal/,https://www.reddit.com/r/datascience/comments/1mdan3p/model_governance_requests_what_is_normal/,True,Discussion,self.datascience,datascience,False,False
1mcngiy,Python Summer Party (free!): 15-day coding challenge for Data folks,"I’ve been cooking up something fun for the summer.. A Python-themed challenge to help Data Scientists & Data Analysts practice and level up their Python skills. Totally free to play! It’s called **Python Summer Party**, and it runs for 15 days, starting August 1. Here’s what to expect: * One Python challenge + 3 parts per day * Focused on Data skills using *NumPy*, *Pandas*, and regular Python * All questions based on real companies, so you can practice working with real problems * Beginner to intermediate to advanced questions * AI chat to help you if you get stuck * Discord community (if you still need more help) * A chance to win 5 free annual Data Camp subscriptions if you complete the challenges * Totally free I built this because I know how hard it can be to stay consistent when you’re learning alone. Plus, when I was learning Python I couldn't find questions that allowed me to apply Python to realistic business problems. So this is meant to be a light, motivating way to practice and have fun with others. *I even tried to design it such that it's cute & fun.* Would love to have you join us (and hear your feedback if you have any!) [www.interviewmaster.ai/python-party](http://www.interviewmaster.ai/python-party)",user_31198914,85,0.93,25,2025-07-29 14:02:07,https://www.reddit.com/r/datascience/comments/1mcngiy/python_summer_party_free_15day_coding_challenge/,https://www.reddit.com/r/datascience/comments/1mcngiy/python_summer_party_free_15day_coding_challenge/,True,Challenges,self.datascience,datascience,False,False
1mcd3n5,Since when did “meets” expectations become a bad thing in this industry?,"I work at a pretty big named company on west coast. It is pretty shocking to see that in my company anyone who gets “meets” expectations have not been getting any salary increments, not even a dollar each year. I’d think if you are meeting expectations, it means you are holding up your end of the deal and it shouldn’t be a bad thing. But now, you actually have to exceeds expectations to get measly 1% salary raises and sometimes to just keep your job. Did this used to happen pre covid as well?",user_d528b440,227,0.98,53,2025-07-29 07:35:17,https://www.reddit.com/r/datascience/comments/1mcd3n5/since_when_did_meets_expectations_become_a_bad/,https://www.reddit.com/r/datascience/comments/1mcd3n5/since_when_did_meets_expectations_become_a_bad/,True,Career | US,self.datascience,datascience,False,False
1mc2zaz,Does a Data Scientist need to learn all these skills?,"* Strong knowledge of Machine Learning, Deep Learning, NLP, and LLMs. * Experience with Python, PyTorch, TensorFlow. * Familiarity with Generative AI frameworks: Hugging Face, LangChain, MLFlow, LangGraph, LangFlow. * Cloud platforms: AWS (SageMaker, Bedrock), Azure AI, and GCP * Databases: MongoDB, PostgreSQL, Pinecone, ChromaDB. * MLOps tools, Kubernetes, Docker, MLflow. I have been browsing many jobs and noticed they all are asking for all these skills.. is it the new norm? Looks like I need to download everything and subscribe to a platform that teaches all these lol (cries in pain).",user_7b806ccf,353,0.97,181,2025-07-28 22:18:53,https://www.reddit.com/r/datascience/comments/1mc2zaz/does_a_data_scientist_need_to_learn_all_these/,https://www.reddit.com/r/datascience/comments/1mc2zaz/does_a_data_scientist_need_to_learn_all_these/,True,Discussion,self.datascience,datascience,False,False
1mbk933,Why are none of my reports refreshing this morning?,,user_662c7639,254,0.96,9,2025-07-28 09:04:50,https://i.redd.it/kect7eypzmff1.png,https://www.reddit.com/r/datascience/comments/1mbk933/why_are_none_of_my_reports_refreshing_this_morning/,False,Monday Meme,i.redd.it,datascience,False,False
1mb49xm,New Grad Data Scientist feeling overwhelmed and disillusioned at first job,"Hi all, I recently graduated with a degree in Data Science and just started my first job as a data scientist. The company is very focused on staying ahead/keeping up with the AI hype train and wants my team (which has no other data scientists except myself) to explore deploying AI agents for specific use cases. The issue is, my background, both academic and through internships, has been in more traditional machine learning (regression, classification, basic NLP, etc.), not agentic AI or LLM-based systems. The projects I’ve been briefed on, have nothing to do with my past experiences and are solely concerned with how we can infuse AI into our workflows and within our products. I’m feeling out of my depth and worried about the expectations being placed on me so early in my career. I was wondering if anyone had advice on how to quickly get up to speed with newer techniques like agentic AI, or how I should approach this situation overall. Any learning resources, mindset tips, or career advice would be greatly appreciated.",user_40e091fd,386,0.96,102,2025-07-27 19:14:45,https://www.reddit.com/r/datascience/comments/1mb49xm/new_grad_data_scientist_feeling_overwhelmed_and/,https://www.reddit.com/r/datascience/comments/1mb49xm/new_grad_data_scientist_feeling_overwhelmed_and/,True,Discussion,self.datascience,datascience,False,False
1mbqiix,Best framework for internal tools,"I need frameworks to build standalone internal tools that don’t require spinning up a server. Most of the time I am delivering to non technical users and having them install Python to run the tool is so cumbersome if you don’t have a clue what you are doing. Also, I don’t want to spin up a server for a process that users run once a week, that feels like a waste. PowerBI isn’t meant to execute actions when buttons are clicked so that isn’t really an option. I don’t need anything fancy, just something that users click, it opens up asks them to put in 6 files, runs various logic and exports a report comparing various values across all of those files. Tkinter would be a great option besides the fact that it looks like it was last updated in 2000 which while it sounds silly doesn’t inspire confidence for non technical people to use a new tool. I love Streamlit or Shiny but that would require it to be running 24/7 on a server or me remembering to start it up every morning and monitor it for errors. What other options are out there to build internal tools for your colleagues? I don’t need anything enterprise grade anything, just something simple that less than 30 people would ever use.",user_c17210f9,9,0.84,9,2025-07-28 12:55:10,https://www.reddit.com/r/datascience/comments/1mbqiix/best_framework_for_internal_tools/,https://www.reddit.com/r/datascience/comments/1mbqiix/best_framework_for_internal_tools/,True,Tools,self.datascience,datascience,False,False
1mbmnkz,Why autoencoders aren't the answer for image compression,"I just finished my engineering thesis comparing different lossy compression methods and thought you might find the results interesting. **What I tested:** * Principal Component Analysis (PCA) * Discrete Cosine Transform (DCT) with 3 different masking variants * Convolutional Autoencoders All methods were evaluated at 33% compression ratio on MNIST dataset using SSIM as the quality metric. **Results:** * **Autoencoders: 0.97 SSIM** \- Best reconstruction quality, maintained proper digit shapes and contrast * **PCA: 0.71 SSIM** \- Decent results but with grayer, washed-out digit tones * **DCT variants: \~0.61 SSIM** \- Noticeable background noise and poor contrast **Key limitations I found:** * Autoencoders and PCA require dataset-specific training, limiting universality * DCT works out-of-the-box but has lower quality * Results may be specific to MNIST's simple, uniform structure * More complex datasets (color images, multiple objects) might show different patterns **Possible optimizations:** * Autoencoders: More training epochs, different architectures, advanced regularization * Linear methods: Keeping more principal components/DCT coefficients (trading compression for quality) * DCT: Better coefficient selection to reduce noise **My takeaway:** While autoencoders performed best on this controlled dataset, the training requirement is a significant practical limitation compared to DCT's universal applicability. **Question for you:** What would you have done differently in this comparison? Any other methods worth testing or different evaluation approaches I should consider for future work? The post with more details about implementation and **visual comparisons** if anyone's interested in the technical details: [https://dataengineeringtoolkit.substack.com/p/autoencoders-vs-linear-methods-for](https://dataengineeringtoolkit.substack.com/p/autoencoders-vs-linear-methods-for)",user_d4223e3c,9,0.66,13,2025-07-28 10:32:16,https://dataengineeringtoolkit.substack.com/p/autoencoders-vs-linear-methods-for,https://www.reddit.com/r/datascience/comments/1mbmnkz/why_autoencoders_arent_the_answer_for_image/,False,ML,dataengineeringtoolkit.substack.com,datascience,False,False
1mc8w7g,How to use AI effectively and efficiently to code,Any tips on how to teach beginners on how to use AI effectively and efficiently to code?,user_65a563a2,0,0.25,12,2025-07-29 04:28:51,https://www.reddit.com/r/datascience/comments/1mc8w7g/how_to_use_ai_effectively_and_efficiently_to_code/,https://www.reddit.com/r/datascience/comments/1mc8w7g/how_to_use_ai_effectively_and_efficiently_to_code/,True,Coding,self.datascience,datascience,False,False
1mb6ch8,"Weekly Entering & Transitioning - Thread 28 Jul, 2025 - 04 Aug, 2025","Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include: * Learning resources (e.g. books, tutorials, videos) * Traditional education (e.g. schools, degrees, electives) * Alternative education (e.g. online courses, bootcamps) * Job search questions (e.g. resumes, applying, career prospects) * Elementary questions (e.g. where to start, what next) While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",user_ac31a110,6,0.88,38,2025-07-27 21:01:39,https://www.reddit.com/r/datascience/comments/1mb6ch8/weekly_entering_transitioning_thread_28_jul_2025/,https://www.reddit.com/r/datascience/comments/1mb6ch8/weekly_entering_transitioning_thread_28_jul_2025/,True,,self.datascience,datascience,False,False
1maxkht,Anomoly detection with only categorical variables,"Hello everyone, I have an anomoly detection project but all of my data is categorical. I suppose I could try and ask them to change it prediction but does anyone have any advice. The goal is to there are groups within the data and and do an analysis to see anomlies. This is all unsupervised the dataset is large in terms of rows (500k) and I have no gpus.",user_c1790433,6,0.8,12,2025-07-27 14:05:36,https://www.reddit.com/r/datascience/comments/1maxkht/anomoly_detection_with_only_categorical_variables/,https://www.reddit.com/r/datascience/comments/1maxkht/anomoly_detection_with_only_categorical_variables/,True,Projects,self.datascience,datascience,False,False
1makoge,"Can LLMs Reason - I don't know, depends on the definition of reasoning. Denny Zhou - Founder/Lead of Google Deepmind LLM Reasoning Team","AI influencers: LLMs can think given this godly prompt bene gesserit oracle of the world blahblah, hence xxx/yyy/zzz is dead. See more below. Meanwhile, literally the founder/lead of the reasoning team: https://preview.redd.it/z9uwnummqeff1.png?width=652&format=png&auto=webp&s=c84727d328d059504adf64768b8badac45d20611 Reference: [https://www.youtube.com/watch?v=ebnX5Ur1hBk](https://www.youtube.com/watch?v=ebnX5Ur1hBk) good lecture!",user_f34181e4,17,0.64,33,2025-07-27 05:08:24,https://www.reddit.com/r/datascience/comments/1makoge/can_llms_reason_i_dont_know_depends_on_the/,https://www.reddit.com/r/datascience/comments/1makoge/can_llms_reason_i_dont_know_depends_on_the/,True,Discussion,self.datascience,datascience,False,False
1mabzuf,Hyperparameter and prompt tuning via agentic CLI tools like Claude Code,"Has anyone used Claude Code as way to automate the improvement of their ML/AI solution? In traditional ML, there’s the notion of hyperparameter tuning, whereby you search the source of all possible hyperparameter values to see which combination yields the best result on some outcome metric. In LLM systems, the thing that gets tuned is the prompt and the outcome being evaluated is the output of some eval framework. And some systems incorporate both ML and LLM All of this iteration can be super time consuming and, in the case of the LLM prompt optimization, quite costly if you are constantly changing the prompt and having to rerun the eval framework. The process can be manual or operated automatically by some heuristic. It occurred to me the other day that it might be a great idea to get CC to do this iteration instead. If we arm it with the context and a CLI for running experiments with different configs), then it could do the following: - ⁠Run its own experiments via CLI - Log the results - Analyze the results against historical results - Write down its thoughts - Come up with ideas for future experiments - Iterate! Just wondering if anyone has pulled this off successfully in the past and would care to share :)",user_240ba603,2,0.57,4,2025-07-26 20:17:20,https://www.reddit.com/r/datascience/comments/1mabzuf/hyperparameter_and_prompt_tuning_via_agentic_cli/,https://www.reddit.com/r/datascience/comments/1mabzuf/hyperparameter_and_prompt_tuning_via_agentic_cli/,True,AI,self.datascience,datascience,False,False
1m9e3vg,Stuck not doing DS work as a DS,"I have been working at a pharma for 5 years. In that time I got my MSDS and did some good work. Issue is, despite stellar yearly reviews I never ever get promoted. Each year I ask for a plan, for a goal to hit , for a reason why, but I always get met with “it just is not in the cards” kind of answer. I spent 6 months applying for other jobs but the issue is my work does not translate well. I built dashboards and an r shiny apps that had some business impact. Unfortunately despite the manager and director talking a big game about how we will use Ai and do a ton of DS and ML work, we never do and I often get stuck with the crappy work. When I interview I kill it during behaviorals and I often get far into the process but then I get asked about my lack of AB testing, or ML experience and I am quite honest. I simply have not been assigned those tasks and the company does not do them. Boom I’m out. I’m stuck and I don’t know what to do or how to proceed. Doing projects seems like a decent move but I’ve heard people say that it does not matter. I’m also not great at coding interviews on the spot. I’ve studied a bunch but can’t perform or often get mind wiped when asked a coding question. Anyone else been here? How did you get out? Any help would be appreciated. I really want to be a better DS and get out of pharma and into product or analytics.",user_c71dc1dd,142,0.96,54,2025-07-25 16:20:41,https://www.reddit.com/r/datascience/comments/1m9e3vg/stuck_not_doing_ds_work_as_a_ds/,https://www.reddit.com/r/datascience/comments/1m9e3vg/stuck_not_doing_ds_work_as_a_ds/,True,Discussion,self.datascience,datascience,False,False
1m8zjnq,Can a PhD be harmful for your career?,"I have my MS degree in a Data Science adjacent field. I currently work in a Data Science / Software Engineering hybrid role, but I also work a second job as an adjunct professor in data science/analytics. I find teaching unbelievably rewarding, but I could make more money being a cashier at Target. That's no exaggeration. Part of me thinks teaching is my calling. My workplace will pay for my PhD, however, if I receive my PhD, and discover that I may not want to be a professor... would this result in a hard time finding data science jobs that aren't solely research based? I try to think of the recruiter perspective, and if I applied to a job with a PhD they may think I will be asking for too much money or be too overqualified. I'm just wondering if anyone has been in the same scenario, or had thoughts on this. Thank you for your time!",user_2dfeaefc,93,0.81,119,2025-07-25 06:43:56,https://www.reddit.com/r/datascience/comments/1m8zjnq/can_a_phd_be_harmful_for_your_career/,https://www.reddit.com/r/datascience/comments/1m8zjnq/can_a_phd_be_harmful_for_your_career/,True,Discussion,self.datascience,datascience,False,False
1m8jaeh,Highest ROI math you’ve had?,"Curious if there is a type of math / project that has saved or generated tons of money for your company. For example, I used Bayesian inference to figure out what insurance policy we should buy. I would consider this my highest ROI project. Machine Learning so far seems to promise a lot but delivers quite little. Causal inference is starting to pick up the speed.",user_722f69fa,240,0.97,113,2025-07-24 16:10:33,https://www.reddit.com/r/datascience/comments/1m8jaeh/highest_roi_math_youve_had/,https://www.reddit.com/r/datascience/comments/1m8jaeh/highest_roi_math_youve_had/,True,Discussion,self.datascience,datascience,False,False
1m8da2j,Are your traditional Data Science projects still getting supported?,"My managers are consumed by AI hype. It was interesting initially when AI was chatbots and coding assistants, but once the idea of Agents entered their mind, it all went off a cliff. We've had conversations that might as well have been conversations about magic. I am proposing sensible projects with modest budgets that are getting no interest.",user_dcc10937,130,0.99,41,2025-07-24 12:07:22,https://www.reddit.com/r/datascience/comments/1m8da2j/are_your_traditional_data_science_projects_still/,https://www.reddit.com/r/datascience/comments/1m8da2j/are_your_traditional_data_science_projects_still/,True,Discussion,self.datascience,datascience,False,False
1m7z6un,How do you know someone's got a data science background?,They know of only 3 species of iris flower. PS: we need a flair for stupid jokes,user_da289fbe,339,0.97,51,2025-07-24 01:49:48,https://www.reddit.com/r/datascience/comments/1m7z6un/how_do_you_know_someones_got_a_data_science/,https://www.reddit.com/r/datascience/comments/1m7z6un/how_do_you_know_someones_got_a_data_science/,True,Discussion,self.datascience,datascience,False,False
1m7qbd9,SHAP values with class weights,"I’m trying to understand which marketing channels are driving conversion. Approximately 2% of customers convert. I utilize an XGBoost model and as features have: 1. For converters, the count of various touchpoints in the 8 weeks prior to conversion date. 2. For non-converters, the count of various touchpoints in the 8 weeks prior to a dummy date selected from the distribution of true conversion dates. Because of how rare conversion is, I use class weighing in my XGBoost model. When I interpret SHAP values, I then get that every predictor is negative, which contextually and numerically is contradictory. Does changing class weights impact the baseline probability, and mean that SHAP values reflect deviation from the over-weighed baseline probability and not true baseline? If so, what is the best way to correct for this if I still want to use weighing?",user_73dd5ff1,20,0.92,13,2025-07-23 17:42:10,https://www.reddit.com/r/datascience/comments/1m7qbd9/shap_values_with_class_weights/,https://www.reddit.com/r/datascience/comments/1m7qbd9/shap_values_with_class_weights/,True,ML,self.datascience,datascience,False,False
1m7jbpk,Is my side gig worth the effort?,"I’ve been doing some freelance data analysis (regression, visuals, clustering) for a mid-sized company over the past couple months. The first project paid OK, and the work itself is pretty open-ended and intellectually engaging. I initially expected access to their internal data, but it turned out I had to source and prep everything myself. The setup is very hands-off—minimal guidance, so I end up doing a lot of research and exploration on my own. Right now, I’ve had a lot of free time at my full-time job, so I’ve been able to fit this in without much sacrifice. But I’m anticipating a job change soon, and I’m starting to wonder if this work is worth the effort. Realistically, I probably earn around (or slightly below) my hourly rate once you factor in how open-ended the work is. That wasn’t what I expected going in. I keep asking myself if my time would be better spent: * Practicing Python, SQL, or ML skills for future interviews * Studying things I actually enjoy (causal inference, classical stats) * Working on personal projects I control * Or just spending time on non-data hobbies Curious to hear how others have thought about this tradeoff. Is it better to lean into these kinds of freelance projects for experience and cash, or to use that energy more intentionally elsewhere?",deleted_user,23,0.82,25,2025-07-23 12:52:36,https://www.reddit.com/r/datascience/comments/1m7jbpk/is_my_side_gig_worth_the_effort/,https://www.reddit.com/r/datascience/comments/1m7jbpk/is_my_side_gig_worth_the_effort/,True,Career | US,self.datascience,datascience,False,False
1m70fk3,Where is Data Science interviews going?,"As a data scientist myself, I’ve been working on a lot of RAG + LLM things and focused mostly on SWE related things. However, when I interview at jobs I notice every single data scientist job is completely different and it makes it hard to prepare for. Sometimes I get SQL questions, other times I could get ML, Leetcode, pandas data frames, probability and Statistics etc and it makes it a bit overwhelming to prepare for every single interview because they all seem very different. Has anyone been able to figure out like some sort of data science path to follow? I like how things like Neetcode are very structured to follow, but fail to find a data science equivalent.",user_c796cc10,187,0.93,52,2025-07-22 22:00:19,https://www.reddit.com/r/datascience/comments/1m70fk3/where_is_data_science_interviews_going/,https://www.reddit.com/r/datascience/comments/1m70fk3/where_is_data_science_interviews_going/,True,Discussion,self.datascience,datascience,False,False
1m825ra,"After Many Failed Attempts, I Finally Built a Workflow for Generating Beautiful Ink Painting","I've always wanted to build a workflow for my blog that can quickly and affordably generate high-quality artistic covers. After dozens of days of effort, I finally succeeded. Here's what the output looks like: https://preview.redd.it/lus6nn9i7tef1.png?width=1792&format=png&auto=webp&s=4bf86969f63512c2b223fe0382f85096f8805e87 Let me briefly share my solution: First, I set a clear goal—this workflow should understand the Eastern artistic concepts in users' drawing intentions, generate prompts suitable for the DALL-E-3 model, and ultimately produce high-quality ink painting illustrations. https://preview.redd.it/rvttfx5m7tef1.png?width=1792&format=png&auto=webp&s=d0dd035d9138fe5427aa84de39d714082aa47adf It should also allow users to refine the generated prompts through multi-turn conversations and adjust prompts based on the final generated images. This would significantly reduce costs in terms of tokens and time. Initially, I tried using Dify to build the workflow, but I faced painful failures in user feedback and workflow loops. I couldn't use coding frameworks like LangChain or CrewAI either because their abstraction levels were too high, making it hard to meet my customization needs. Finally, I found LlamaIndex Workflow, which provides a low-abstraction, event-driven architecture for building workflows. Using this framework along with Context Engineering, I successfully decoupled the workflow loops, making the entire workflow easy to understand, maintain, and adjust as needed. https://preview.redd.it/vp55460p7tef1.jpg?width=1792&format=pjpg&auto=webp&s=97f9ba642c79400b369437e0bf0a52d954da104c This flowchart reflects my overall workflow design: https://preview.redd.it/wjkcel5s7tef1.png?width=658&format=png&auto=webp&s=e69448489b428524bb03be2aa5ab6218359a76c1 https://preview.redd.it/raqqmngt7tef1.png?width=974&format=png&auto=webp&s=9a6eb4e02f71542a17adfff22522bb972be8d327 Due to length constraints, I can't explain my implementation in detail here, but you can read [my full tutorial](https://www.dataleadsfuture.com/use-llamaindex-workflow-to-create-an-ink-painting-style-image-generation-workflow/) to learn about my complete solution.",user_eb3254d5,0,0.28,3,2025-07-24 04:44:44,https://www.reddit.com/r/datascience/comments/1m825ra/after_many_failed_attempts_i_finally_built_a/,https://www.reddit.com/r/datascience/comments/1m825ra/after_many_failed_attempts_i_finally_built_a/,True,Challenges,self.datascience,datascience,False,False
1m70hqg,Probably and Stats interview questions?,Is there like a Neetcode equivalent to be able to do those (where you start understanding the different patterns in questions)? I want to get better at problem solving probability and stats questions.,user_c796cc10,15,0.83,10,2025-07-22 22:03:33,https://www.reddit.com/r/datascience/comments/1m70hqg/probably_and_stats_interview_questions/,https://www.reddit.com/r/datascience/comments/1m70hqg/probably_and_stats_interview_questions/,True,Discussion,self.datascience,datascience,False,False
1m6jx39,Stuck in defense contracting not doing Data Science but have a data science title,"Title says it all…. Been here for 3 years, doing a lot of database/data architecting but not really any real data science work. My previous job was at a big 4 consulting but I was doing real data science for 2 years, but hated consulting part with a passion. Any advice? Edit forgot to add: I’m also currently doing my masters in data science (part-time), and my company is flexible letting me do it. I see a lot more job opportunities elsewhere but feel like I should just stay until I finish next year.",user_8d9ea375,109,0.91,36,2025-07-22 10:12:11,https://www.reddit.com/r/datascience/comments/1m6jx39/stuck_in_defense_contracting_not_doing_data/,https://www.reddit.com/r/datascience/comments/1m6jx39/stuck_in_defense_contracting_not_doing_data/,True,Career | US,self.datascience,datascience,False,False
1m6h3f0,I wrote 2000 LLM test cases so you don't have to: LLM feature compatibility grid,"This is a quick story of how a focus on usability turned into 2000 LLM tests cases (well 2631 to be exact), and why the results might be helpful to you. # The problem: too many options I've been building [Kiln AI](https://github.com/kiln-ai/kiln): an open tool to help you find the best way to run your AI workload. Part of Kiln’s goal is testing various different models on your AI task to see which ones work best. We hit a usability problem on day one: too many options. We supported hundreds of models, each with their own parameters, capabilities, and formats. Trying a new model wasn't easy. If evaluating an additional model is painful, you're less likely to do it, which makes you less likely to find the best way to run your AI workload. Here's a sampling of the many different options you need to choose: structured data mode (JSON schema, JSON mode, instruction, tool calls), reasoning support, reasoning format (`...`), censorship/limits, use case support (generating synthetic data, evals), runtime parameters (logprobs, temperature, top\_p, etc), and much more. # How a focus on usability turned into over 2000 test cases I wanted things to ""just work"" as much as possible in Kiln. You should be able to run a new model without writing a new API integration, writing a parser, or experimenting with API parameters. To make it easy to use, we needed reasonable defaults for every major model. That's no small feat when new models pop up every week, and there are dozens of AI providers competing on inference. The solution: a whole bunch of test cases! 2631 to be exact, with more added every week. We test every model on every provider across a range of functionality: structured data (JSON/tool calls), plaintext, reasoning, chain of thought, logprobs/G-eval, evals, synthetic data generation, and more. The result of all these tests is a detailed configuration file with up-to-date details on which models and providers support which features. # Wait, doesn't that cost a lot of money and take forever? **Yes it does!** Each time we run these tests, we're making thousands of LLM calls against a wide variety of providers. There's no getting around it: we want to know these features work well on every provider and model. The only way to be sure is to test, test, test. We regularly see providers regress or decommission models, so testing once isn't an option. Our blog has some details on the [Python pytest setup we used to make this manageable](https://getkiln.ai/blog/i_wrote_2000_llm_test_cases_so_you_dont_have_to#cost-and-time). # The Result The end result is that it's much easier to rapidly evaluate AI models and methods. It includes * The model selection dropdown is aware of your current task needs, and will only show models known to work. The filters include things like structured data support (JSON/tools), needing an uncensored model for eval data generation, needing a model which supports logprobs for G-eval, and many more use cases. * Automatic defaults for complex parameters. For example, automatically selecting the best JSON generation method from the many options (JSON schema, JSON mode, instructions, tools, etc). However, you're in control. You can always override any suggestion. # Next Step: A Giant Ollama Server I can run a decent sampling of our Ollama tests locally, but I lack the \~1TB of VRAM needed to run things like Deepseek R1 or Kimi K2 locally. I'd love an easy-to-use test environment for these without breaking the bank. Suggestions welcome! # How to Find the Best Model for Your Task with Kiln All of this testing infrastructure exists to serve one goal: making it easier for you to find the best way to run your specific use case. The 2000+ test cases ensure that when you use Kiln, you get reliable recommendations and easy model switching without the trial-and-error process. Kiln is a free open tool for finding the best way to build your AI system. You can rapidly compare models, providers, prompts, parameters and even fine-tunes to get the optimal system for your use case — all backed by the extensive testing described above. To get started, check out the tool or our guides: * [Kiln AI on Github - over 3900 stars](https://getkiln.ai/) * [Quickstart Guide](https://docs.getkiln.ai/docs/quickstart) * [Kiln Discord](https://getkiln.ai/discord) * [Blog post with more details on our LLM testing (more detailed version of above)](https://getkiln.ai/blog/i_wrote_2000_llm_test_cases_so_you_dont_have_to#cost-and-time) I'm happy to answer questions if anyone wants to dive deeper on specific aspects!",user_cf37a366,9,0.74,5,2025-07-22 08:26:27,https://www.reddit.com/r/datascience/comments/1m6h3f0/i_wrote_2000_llm_test_cases_so_you_dont_have_to/,https://www.reddit.com/r/datascience/comments/1m6h3f0/i_wrote_2000_llm_test_cases_so_you_dont_have_to/,True,Tools,self.datascience,datascience,False,False
1m5nkwe,Wouldn't be the first time I've seen an entire org propped up by a 80MB Excel file,"Oh yeah, I started a meme sub r/AnalyticsMemes if anyone wants every day to be meme Monday",user_662c7639,454,0.91,39,2025-07-21 09:29:06,https://i.redd.it/19xz40qp79ef1.png,https://www.reddit.com/r/datascience/comments/1m5nkwe/wouldnt_be_the_first_time_ive_seen_an_entire_org/,False,Monday Meme,i.redd.it,datascience,False,False
1m5xn63,Looking for MMM / Marketing Data Science specialist,"Hi All, Hope this is okay to post in this sub. I am looking to hire for a role here in the DFW metro area and looking for a hard to find specialty of media mix marketing. Willing to train recent graduates with the right statistical and academic background. Currently hybrid 3 days a week in office. Compensation depends on skill set and experience, but can be between $95k-150k. Please DM for more details and to send resumes.",user_282af3ed,21,0.76,18,2025-07-21 15:51:14,https://www.reddit.com/r/datascience/comments/1m5xn63/looking_for_mmm_marketing_data_science_specialist/,https://www.reddit.com/r/datascience/comments/1m5xn63/looking_for_mmm_marketing_data_science_specialist/,True,Career | US,self.datascience,datascience,False,False
1m5odiz,Data Science MSc 1 year Full time or 2 year Part time?,"Hi, I'm funding my own MSc in Applied Data Science (intended for non computer/maths background) I have a 6 year healthcare background (Nuclear medicine and CT). I have taken python and SQL introduction courses to build a foundation. My question is: Would a 1 year MSc be intensive learning for 1 year with dissertation and realistically result in a 18month study? Does a 2 year MSc offer more room, resulting in a realistic 24 month timeline, with some room for job ""volunteering"" to get some experience? I have completed a 3 year MSc before and can't comprehend how intense a 1 year MSc would be. Thanks!",user_465f750a,11,0.87,18,2025-07-21 09:58:29,https://www.reddit.com/r/datascience/comments/1m5odiz/data_science_msc_1_year_full_time_or_2_year_part/,https://www.reddit.com/r/datascience/comments/1m5odiz/data_science_msc_1_year_full_time_or_2_year_part/,True,Discussion,self.datascience,datascience,False,False
1m5m5pn,Maintenance of clustered data over time,"With LLM-generated data, what are the best practices for handling downstream maintenance of clustered data? E.g. for conversation transcripts, we extract things like the topic. As the extracted strings are non-deterministic, they will need clustering prior to being queried by dashboards. What are people doing for their daily/hourly ETLs? Are you similarity-matching new data points to existing clusters, and regularly assessing cluster drift/bloat? How are you handling historic assignments when you determine clusters have drifted and need re-running? Any guides/books to help appreciated!",user_a7319afc,13,1.0,7,2025-07-21 08:35:52,https://www.reddit.com/r/datascience/comments/1m5m5pn/maintenance_of_clustered_data_over_time/,https://www.reddit.com/r/datascience/comments/1m5m5pn/maintenance_of_clustered_data_over_time/,True,ML,self.datascience,datascience,False,False
1m5i5dj,Data Snooping Resources,"Simple question: Do you guys have any resources/papers about data snooping and how to limits its influence when making predictive models? I understand to maintain a testing dataset, but I am hoping someone knows any good high-level introductions to the topic that is not overly technical. Something like this, but about data snooping specifically, is what I am hoping to find: https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/ES13-00160.1",user_4f1ecc2c,10,0.82,2,2025-07-21 05:55:16,https://www.reddit.com/r/datascience/comments/1m5i5dj/data_snooping_resources/,https://www.reddit.com/r/datascience/comments/1m5i5dj/data_snooping_resources/,True,Discussion,self.datascience,datascience,False,False
1m58yyn,"Weekly Entering & Transitioning - Thread 21 Jul, 2025 - 28 Jul, 2025","Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include: * Learning resources (e.g. books, tutorials, videos) * Traditional education (e.g. schools, degrees, electives) * Alternative education (e.g. online courses, bootcamps) * Job search questions (e.g. resumes, applying, career prospects) * Elementary questions (e.g. where to start, what next) While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",user_ac31a110,7,0.89,38,2025-07-20 21:01:31,https://www.reddit.com/r/datascience/comments/1m58yyn/weekly_entering_transitioning_thread_21_jul_2025/,https://www.reddit.com/r/datascience/comments/1m58yyn/weekly_entering_transitioning_thread_21_jul_2025/,True,,self.datascience,datascience,False,False
1m4d64h,Company Killed University Programs,"Normally, I would have a post around this time hyping up fall recruiting and trying to provide pointers. The company I work for has decided to hire no additional entry level data scientists this year outside of intern return offers. They have also cut the number of intern positions in half for 2026. Part of the reasoning given by the CEO was that it is easy to hire early to mid level data scientist with project specific skills rather than training new hires. Money can also be saved by not having a university recruiting team and saving time interviewing by only going to target universities. Are any other data scientists seeing this change in their companies?",deleted_user,178,0.96,38,2025-07-19 18:56:38,https://www.reddit.com/r/datascience/comments/1m4d64h/company_killed_university_programs/,https://www.reddit.com/r/datascience/comments/1m4d64h/company_killed_university_programs/,True,Career | US,self.datascience,datascience,False,False
1m45pmq,Generating random noise for media data,"Hey everyone - I work on an ML team in the industry, and I’m currently building a predictive model to catch signals in live media data to sense when potential viral moments or crises are happening for brands. We have live media trackers at my company that capture all articles, including their sentiment (positive, negative, neutral). I currently am using ARIMA to predict out a certain amount of time steps, then using an LSTM to determine whether the volume of articles is anomalous given historical data trends. However, the nature of media is there’s so much randomness, so just taking the ARIMA projection is not enough. Because of that, I’m using Monte Carlo simulation to run an LSTM on a bunch of different forecasts that incorporate an added noise signal for each simulation. Then, that forces a probability of how likely it is that a crisis/viral moment will happen. I’ve been experimenting with a bunch of methods on how to generate a random noise signal, and while I’m close to getting something, I still feel like I’m missing a method that’s concrete and backed by research/methodology. Does anyone know of approaches on how to effectively generate random noise signals for PR data? Or know of any articles on this topic? Thank you!",user_fb3a2b68,12,0.93,9,2025-07-19 13:07:54,https://www.reddit.com/r/datascience/comments/1m45pmq/generating_random_noise_for_media_data/,https://www.reddit.com/r/datascience/comments/1m45pmq/generating_random_noise_for_media_data/,True,Projects,self.datascience,datascience,False,False
1m49rai,How would you structure a project (data frame) to scrape and track listing changes over time?,"I’m working on a project where I want to scrape data daily (e.g., real estate listings from a site like RentFaster or Zillow) and track how each listing changes over time. I want to be able to answer questions like: When did a listing first appear? How long did it stay up? What changed (e.g., price, description, status)? What’s new today vs yesterday? My rough mental model is: 1. Scrape today’s data into a CSV or database. 2. Compare with previous days to find new/removed/updated listings. 3. Over time, build a longitudinal dataset with per-listing history (kind of like slow-changing dimensions in data warehousing). I’m curious how others would structure this kind of project: How would you handle ID tracking if listings don’t always have persistent IDs? Would you use a single master table with change logs? Or snapshot tables per day? How would you set up comparisons (diffing rows, hashing)? Any Python or DB tools you’d recommend for managing this type of historical tracking? I’m open to best practices, war stories, or just seeing how others have solved this kind of problem. Thanks!",user_fbe99468,6,0.75,5,2025-07-19 16:08:06,https://www.reddit.com/r/datascience/comments/1m49rai/how_would_you_structure_a_project_data_frame_to/,https://www.reddit.com/r/datascience/comments/1m49rai/how_would_you_structure_a_project_data_frame_to/,True,Projects,self.datascience,datascience,False,False
1m4s0vw,AI In Data Engineering,,user_51854acf,0,0.29,5,2025-07-20 08:41:10,/r/dataengineering/comments/1m4rxwf/ai_in_data_engineering/,https://www.reddit.com/r/datascience/comments/1m4s0vw/ai_in_data_engineering/,False,Discussion,,datascience,False,False
1m3gy6m,Are headhunters still a thing in 2025?,"Curious what the current consensus is on headhunters these days. A few years ago they seemed to be everywhere, both big-name firms like Michael Page and boutique ones, but lately I don’t hear much about them. Do companies still rely on them or have internal recruiting teams and LinkedIn taken over completely?",user_48d03593,60,0.93,37,2025-07-18 16:12:31,https://www.reddit.com/r/datascience/comments/1m3gy6m/are_headhunters_still_a_thing_in_2025/,https://www.reddit.com/r/datascience/comments/1m3gy6m/are_headhunters_still_a_thing_in_2025/,True,Discussion,self.datascience,datascience,False,False
1m10uku,What question from recruiters do you absolutely hate to answer? How do you answer it elegantly?,"Pretty much the title. Recruiters are not technically adepts in most of the cases. They go about asking some questions which is routine for them but hardly make sense in the real world. Not trying to be idealistic but, which questions do you hate the most? How would you answer them in a polite way?",user_ae37e5e3,63,0.96,57,2025-07-15 19:19:08,https://www.reddit.com/r/datascience/comments/1m10uku/what_question_from_recruiters_do_you_absolutely/,https://www.reddit.com/r/datascience/comments/1m10uku/what_question_from_recruiters_do_you_absolutely/,True,Discussion,self.datascience,datascience,False,False
1m0wx9l,Hoping for a review.,"I want to clarify the reason I'm not using the main thread is because I'm posting an image, which can't be used for replies. I've been searching for a while without as much as a call back. I've been a data scientist for a while now and I'm not sure if it's the market or if there's something glaringly bad with my resume. Thanks for your help.",user_f4634b41,33,0.64,73,2025-07-15 16:15:22,https://i.redd.it/9gcv99xve4df1.png,https://www.reddit.com/r/datascience/comments/1m0wx9l/hoping_for_a_review/,False,Discussion,i.redd.it,datascience,False,False
1m0b9f9,Is it normal to be scared for the future finding a job,"I am a rising senior at a large state school studying data science. I am currently working an internship as a software engineer for the summer. And I get my tickets done for the most part albeit with some help from ai. But deep down I feel a pit in my stomach that I won’t be able to end up employed after all of this. I plan to go for a masters in applied statistics or data science after my bachelors. Thought I definitely don’t have great math grades from my first few semesters of college. But after those semesters all my upper division math/stats/cs/data science courses have been A’s and B’s. And I feel like ik enough python, R, and SAS to work through and build models for most problems I run into, as well as tableau, sql and alteryx. But I can’t shake the feeling that it won’t be enough. Also that my rough math grades in my first few semesters will hold me back from getting into a masters programs. I have tried to supplement this by doing physics and applied math research. But I’m just not sure I’m doing enough and I’m scared for like after I finish my education. Im just venting here but I’m hoping there r others in this sub who have been in similar positions and gotten employed. Or r currently in my same shoes I just need to hear from other people that it’s not as hopeless as it feels. I just want to get a job as a data analyst, scientist, or statistician working on interesting problems and have a decent career.",user_3573c73f,240,0.93,102,2025-07-15 00:18:35,https://www.reddit.com/r/datascience/comments/1m0b9f9/is_it_normal_to_be_scared_for_the_future_finding/,https://www.reddit.com/r/datascience/comments/1m0b9f9/is_it_normal_to_be_scared_for_the_future_finding/,True,Discussion,self.datascience,datascience,False,False
1lzx0la,I have people skills... I am good at dealing with people. Can't you understand that? What the hell is wrong with you people?,,user_662c7639,315,0.94,14,2025-07-14 13:07:07,https://i.redd.it/dwghyhz8cwcf1.png,https://www.reddit.com/r/datascience/comments/1lzx0la/i_have_people_skills_i_am_good_at_dealing_with/,False,Monday Meme,i.redd.it,datascience,False,False
1m0n56g,"""Harnessing the Universal Geometry of Embeddings"" - Breakthroughs and Security Implications",,user_a6355e92,4,0.83,0,2025-07-15 09:55:59,/r/AI_Community_Gurgaon/comments/1m0n4gn/harnessing_the_universal_geometry_of_embeddings/,https://www.reddit.com/r/datascience/comments/1m0n56g/harnessing_the_universal_geometry_of_embeddings/,False,Discussion,,datascience,False,False
1m0dxsm,How does your organization label data?,"I'm curious to hear how your organization labels data for use in modeling. We use a combination of SMEs who label data, simple rules that flag cases (it's rare that we can use these because they're generally no unambiguous), and an ML model to find more labels. I ask because my organization doesn't think it's valuable to have SMEs labeling data. In my domain area (fraud), we need SMEs to be labeling data because fraud evolves over time, and we need to identify the evoluation. Also, identifying fraud in the data isn't cut and dry.",user_03b74ec1,7,0.89,15,2025-07-15 03:12:44,https://www.reddit.com/r/datascience/comments/1m0dxsm/how_does_your_organization_label_data/,https://www.reddit.com/r/datascience/comments/1m0dxsm/how_does_your_organization_label_data/,True,Discussion,self.datascience,datascience,False,False
1lzgfhq,I suck at these interviews.,"I'm looking for a job again and while I have had quite a bit of hands-on practical work that has a lot of business impacts - revenue generation, cost reductions, increasing productivity etc But I keep failing at ""Tell the assumptions of Linear regression"" or ""what is the formula for Sensitivity"". While I'm aware of these concepts, and these things are tested out in model development phase, I never thought I had to mug these stuff up. The interviews are so random - one could be hands on coding (love these), some would be a mix of theory, maths etc, and some might as well be in Greek and Latin.. Please give some advice to 4 YOE DS should be doing. The ""syllabus"" is entirely too vast.🥲 Edit: Wow, ok i didn't expect this to blow up. I did read through all the comments. This has been definitely enlightening for me. Yes, i should have prepared better, brushed up on the fundamentals. Guess I'll have to go the notes/flashcards way.",user_520ead06,535,0.97,135,2025-07-14 00:50:27,https://www.reddit.com/r/datascience/comments/1lzgfhq/i_suck_at_these_interviews/,https://www.reddit.com/r/datascience/comments/1lzgfhq/i_suck_at_these_interviews/,True,Discussion,self.datascience,datascience,False,False
1lzlrlu,Fine-tuning for tabular foundation models (TabPFN),"Hi everyone - wanted to share that you can now fine-tune tabular foundation models as well, specifically TabPFN! With the latest 2.1 package release, you can now build your own fine-tuned models. A community member put together a practical walkthrough! How to Fine-Tune TabPFN on Your Data: [https://medium.com/@iivalchev/how-to-fine-tune-tabpfn-on-your-data-a831b328b6c0](https://medium.com/@iivalchev/how-to-fine-tune-tabpfn-on-your-data-a831b328b6c0) The tutorial covers: * Running TabPFN in batched mode * Handling preprocessing and inference-time transformations * Fine-tuning the transformer backbone on your dataset If you're working with highly domain specific data and looking to boost performance, this is a great place to start. You can also check out the example files directly at these links: 🧪 [Fine-tune classifier](https://github.com/PriorLabs/TabPFN/blob/main/examples/finetune_classifier.py) 📈 [Fine-tune regressor](https://github.com/PriorLabs/TabPFN/blob/main/examples/finetune_regressor.py) Would love to hear how it goes if you try it! There’s also a community Discord where folks are sharing experiments and helping each other out - worth checking out if you're playing around with TabPFN [https://discord.com/invite/VJRuU3bSxt](https://discord.com/invite/VJRuU3bSxt)",user_bb720034,21,0.96,4,2025-07-14 06:00:27,https://www.reddit.com/r/datascience/comments/1lzlrlu/finetuning_for_tabular_foundation_models_tabpfn/,https://www.reddit.com/r/datascience/comments/1lzlrlu/finetuning_for_tabular_foundation_models_tabpfn/,True,ML,self.datascience,datascience,False,False
1lzo89g,Do employers see volunteer experience as “real world experience”?,,user_1568ab44,13,1.0,22,2025-07-14 07:42:27,/r/analytics/comments/1lzo7lq/do_employers_see_volunteer_experience_as_real/,https://www.reddit.com/r/datascience/comments/1lzo89g/do_employers_see_volunteer_experience_as_real/,False,Career | US,,datascience,False,False
1m07l5m,Need mentorship on climbing the ladder or transitioning,,user_553a9b86,0,0.25,2,2025-07-14 20:45:37,/r/analytics/comments/1m07jow/need_mentorship_on_climbing_the_ladder_or/,https://www.reddit.com/r/datascience/comments/1m07l5m/need_mentorship_on_climbing_the_ladder_or/,False,Discussion,,datascience,False,False
1lzkso0,Site Selection Model - Subjective Feature,"I have been working on a site selection model, and the one I created is performing quite well in out of sample testing. I was also able to reduce the model down to just 5 features. But, one of those features is a ""Visibility Score"" (how visible the building is from the road). I had 3 people independently score all of our existing sites and I averaged their scores, and this has proven to work well so far. But if we actually put the model into production, I am concerned about standardized those scores. The model predictiction can vary by 18% just from a visibility score change from 3.5 to 4.0 so the model is heavily dependent on that subjective score. Any tips?",user_96de6876,7,1.0,5,2025-07-14 05:14:56,https://www.reddit.com/r/datascience/comments/1lzkso0/site_selection_model_subjective_feature/,https://www.reddit.com/r/datascience/comments/1lzkso0/site_selection_model_subjective_feature/,True,ML,self.datascience,datascience,False,False
1lzcn4y,"Weekly Entering & Transitioning - Thread 14 Jul, 2025 - 21 Jul, 2025","Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include: * Learning resources (e.g. books, tutorials, videos) * Traditional education (e.g. schools, degrees, electives) * Alternative education (e.g. online courses, bootcamps) * Job search questions (e.g. resumes, applying, career prospects) * Elementary questions (e.g. where to start, what next) While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",user_ac31a110,9,0.91,36,2025-07-13 21:01:26,https://www.reddit.com/r/datascience/comments/1lzcn4y/weekly_entering_transitioning_thread_14_jul_2025/,https://www.reddit.com/r/datascience/comments/1lzcn4y/weekly_entering_transitioning_thread_14_jul_2025/,True,,self.datascience,datascience,False,False
